<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[usbcamera android 4kæ”¯æŒ]]></title>
    <url>%2F2023%2F09%2F04%2Fusbcamera-android-4k%E6%94%AF%E6%8C%81%2F</url>
    <content type="text"><![CDATA[usbcameraandroid å¤–æŽ¥ usbcameraï¼Œå·²ç»æœ‰æ¯”è¾ƒæˆç†Ÿçš„æŠ€æœ¯æ–¹æ¡ˆUVCCamera,å‚è€ƒè¿™ä¸ªåº“ï¼Œé…ç½®Andoirdå·¥ç¨‹ï¼Œä¾èµ–åº“æŽ¥å…¥ï¼ŒæŠŠå¤–æŽ¥usbcamera æµç¨‹è·‘é€šä¸éš¾ã€‚ æ‰‹å¤´è®¾å¤‡æ˜¯æµ·åº·å¨è§†çš„4Kæ‘„åƒå¤´ï¼Œrunèµ·ç«‹ cameraç”»é¢ä¹Ÿæ­£å¸¸å‡ºæ¥äº†ã€‚ å¦‚æžœéƒ½è¿™ä¹ˆé¡ºåˆ©çš„è¯ï¼Œé‚£å°±æ²¡è¿™ç¯‡æ–‡ç« äº† ðŸ˜‚ðŸ˜‚ðŸ˜‚ 4kç”»é¢æ˜¯å‡ºæ¥äº†ï¼Œå‘çŽ°åˆ†è¾¨çŽ‡æœ€å¤šåªæ‹‰åˆ°2kï¼ˆ2560 x 1440ï¼‰ï¼Œå®Œå…¨æ²¡æœ‰å‘æŒ¥å‡º4kçš„èƒ½åŠ›ã€‚ æ¯”è¾ƒå®¹æ˜“æƒ³åˆ°çš„æ˜¯ çº¿ æˆ–è€… hub ç”¨çš„æ˜¯usb2.0çš„ï¼ˆ480Mbit/sï¼‰ï¼Œä¼ è¾“é€Ÿåº¦ä¸å¤Ÿï¼Œæ‰€ä»¥å‡ºä¸äº†4Kã€‚æžä¸€æ ¹3.0çš„çº¿ ç¡®å®šå£å­ä¹Ÿæ˜¯3.0çš„ä¹‹åŽï¼Œå†æ¬¡è·‘èµ·æ¥ï¼Œå‘çŽ°4kç”»é¢èŠ±äº†ï¼Œåªæœ‰é¡¶ä¸Šä¸€ç‚¹ç‚¹å†…å®¹ï¼Œç»å¤§éƒ¨åˆ†æ˜¯ç°çš„ï¼Œæ‡µé€¼å¼€å§‹â€¦ libXXXæ‡µé€¼æ²¡ç”¨ è¿˜æ˜¯è¦è§£å†³é—®é¢˜çš„ ç®€å•æ¢³ç†ä¹‹åŽï¼Œé—®é¢˜åº”è¯¥ä¸æ˜¯androidä¾§çš„ï¼Œå¹¶æ²¡æœ‰ä»€ä¹ˆjavaå±‚çš„å¼‚å¸¸æ—¥å¿—ã€‚ ä¹Ÿæ˜¯å› ä¸ºåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬çš„å·¥ä½œä¹Ÿåªæ˜¯åœ¨androidä¾§ï¼Œå„ç§lib æŽ¥å…¥ä¹‹åŽï¼Œç›®å‰ä¸çŸ¥é“å…·ä½“åœ¨åšä»€ä¹ˆã€‚ å¼€å§‹äº†è§£åº•å±‚ native jniã€‚ jni è¿›æ¥å¯¹æŽ¥çš„å°±æ˜¯libuvcï¼Œlibuvc åº•å±‚å°±æ˜¯libusb è¿™ä¸¤åº§å¤§å±±å…¨æ˜¯Cå†™çš„ï¼Œæ‡µé€¼å‡çº§â€¦ é—ªçƒc/c++ è¿˜ç»™è€å¸ˆäº†, ä½†æ˜¯ ctrl+c/v é‚£æ˜¯ä¸å¯èƒ½è¿˜çš„ å¾ˆå¿«å‘çŽ° UVCCamera éƒ½å·²ç»åœç•™åœ¨5-6å¹´å‰äº†ï¼Œèµ¶ç´§ctrl+c/v æŠŠä¸¤åº§å¤§å±±å‡çº§ä¸‹ï¼ŒæŠ¥é”™å¤„ç†ä¸‹ã€å†æ¬¡runèµ·æ¥ã€‚ å‡ºæ¥äº†4kå‡ºæ¥äº†ï¼Œé«˜å…´ä¸åˆ°3sï¼Œç”»é¢æ˜¯å‡ºæ¥äº†ï¼Œæ–°çš„é—®é¢˜å‡ºçŽ°äº† ç”»é¢é—ªçƒï¼Œä¸æ˜¯ä¸€ç›´é—ªçƒ å¶å°”é—ªé‚£ä¹ˆå‡ ä¸‹ã€‚ å‡ ç•ªæ¥å›žå®žéªŒä¸‹æ¥ï¼Œä¸å•4ké—ªçƒï¼Œè¿žå‡çº§ä¹‹å‰æ­£å¸¸çš„2kä¹Ÿå¼€å§‹é—ªäº†ã€‚ æ‡µé€¼ç»§ç»­â€¦ é—ªçƒçš„ä¸€å¸§ç”»é¢å¦‚ä¸‹ï¼š logç¡¬ç€å¤´çš®çœ‹ä»£ç äº†ï¼Œå¤§æ¦‚äº†è§£äº†è°ƒç”¨æµç¨‹ä¹‹åŽï¼ˆuvc usbçš„è°ƒç”¨æµç¨‹ï¼Œå®˜æ–¹çš„readme è·Ÿ demo ä¹Ÿæåˆ°äº†ï¼‰ï¼Œå¼€å§‹æŠŠä¸€äº›æ—¥å¿—å¼€å…³æ‰“å¼€ï¼Œè‡ªå·±åŠ ä¸€äº›logï¼Œmjpegæ ¼å¼æ•°æ®ä¿å­˜æœ¬åœ°çœ‹çœ‹ï¼ŒæŠŠä¸€äº›æ¶‰åŠåˆ°ä»€ä¹ˆbuffer_size ã€timeoutã€payload ã€lensç­‰ å¯ä»¥è°ƒæ•´å‚æ•°çš„åœ°æ–¹ æ”¹å¤§ æˆ–è€… æ”¹å°ã€‚ ä¸€é¡¿çžŽæ“ä½œä¹‹åŽï¼ŒåŸºæœ¬éƒ½æ˜¯æ²¡ç”¨çš„ã€‚ ä¸è¿‡å€’æ˜¯å‘çŽ°äº†ä¸€ä¸ªæ—¥å¿—ï¼Œä¼¼ä¹Žè·Ÿé—ªçƒæœ‰å…³ç³» â€œunrecognised urb status -1â€ï¼Œå› ä¸ºè¿™ä¸ªæ—¥å¿—ä¹Ÿæ˜¯æ—¶ä¸æ—¶çš„å‡ºçŽ°ã€‚ å®˜æ–¹è¿˜çœŸæœ‰è¿™ä¸ªissue ä¸Šé¢å¹¶æ²¡æœ‰è¯´é—ªçƒï¼Œä¹Ÿæœ‰æƒ³è¿‡æ˜¯ä¸æ˜¯æ‰‹ä¸Šçš„æµ·åº·4Kæ‘„åƒå¤´æœ‰é—®é¢˜ï¼Œé©±åŠ¨æˆ–è€…å›ºä»¶æœ‰é—®é¢˜ã€‚ã€‚ã€‚æ‰‹ä¸Šåˆæ²¡æœ‰å…¶ä»–çš„4kæ‘„åƒå¤´æ¥æµ‹è¯•ã€‚ã€‚ã€‚ ä½†æ˜¯è¯´åˆ° æœ‰æ²¡æœ‰åœ¨linuxç³»ç»Ÿä¸Šè¯•è¿‡ï¼Œæ¯•ç«Ÿandroidä¸æ˜¯çœŸlinuxâ€¦. æ­£å¥½å›¢é˜Ÿæœ‰ä¸€å°ubuntu ï¼Œé‚£å°±åœ¨linuxä¸Šè¯•è¯•å‘—ï¼Œ ç…§ç€readme æŠŠlibuvcçš„example demo è·‘èµ·æ¥ï¼Œè°ƒæ•´å‚æ•°ä¿æŒè·Ÿandroidä¸€ç›´ï¼Œä¿å­˜mjpegæ•°æ®åˆ°æœ¬åœ°ã€‚ æœ¬åœ°å‡ ç™¾å¼ å›¾åƒæ²¡æœ‰ä¸€å¼ æ˜¯é—ªçƒç”»é¢ã€‚ã€‚ã€‚ æµ·åº·ä¸èƒŒé”…ã€‚ã€‚ã€‚ example demo ç¨å¾®åšäº†å†™æ”¹é€ ï¼ˆé…ç½®makefileã€opencvæŽ¥å…¥ï¼‰ï¼ŒæŠŠ libusb debug logå¼€å…³æ‰“å¼€äº†ï¼Œä½¿ç”¨ opencv æŠŠç”»é¢æ˜¾ç¤ºå‡ºæ¥äº†ï¼Œå‚è€ƒä¸‹ demo issue é‡Œå’¨è¯¢ä¸‹ï¼Œ åªè¯´æ˜¯android å†…æ ¸é—®é¢˜ï¼Œè·Ÿlibusbæ²¡å…³ç³»â€¦. æ‡µé€¼å‡çº§â€¦. uvc/usbå¤§æ¦‚äº†è§£è°ƒç”¨è¿‡ç¨‹æ˜¯ä¸å¤Ÿçš„ï¼Œé‚£å°±ç»§ç»­äº†è§£ã€‚ã€‚ã€‚å¼€å§‹googleå¤§æ³•ã€‚ã€‚ã€‚ usb2.0usb3.0uvc æ— ä»–ï¼Œå”¯æ‰‹ç†Ÿå°” uvc usbçš„è°ƒç”¨æµç¨‹ï¼Œå®˜æ–¹çš„readme è·Ÿ demo éƒ½æåˆ°äº† ã€‚ å¯¹ç€ä»£ç ã€åè®®ã€æ–‡æ¡£ï¼Œ ç†Ÿæ‚‰ uvcã€usbã€descriptorã€transferã€urb ã€ioctl ç­‰ç­‰ æ…¢æ…¢å¼€å§‹ç†Ÿæ‚‰ æ¯ä¸ªå‡½æ•°éƒ½åœ¨å¹²å˜›äº† å„ä¸ªå‚æ•°çš„æ„ä¹‰äº† çŸ¥é“ â€œunrecognised urb status -1â€ã€â€bad packet:xxxâ€ã€â€submiturb failed, errno=-12â€ è¿™äº›æ—¥å¿—çš„å‡ºå¤„äº†ï¼Œä¹Ÿå°±å¤§æ¦‚æŠŠèŒƒå›´ç¼©å°åˆ°å‡ ä¸ªå…³é”®çš„å‡½æ•°äº† happyåœ¨é’ˆå¯¹è¿™å‡ ä¸ªå‡½æ•° ï¼Œå¯¹æ¯”ä¸‹libusbã€libuvc æ–°è€ä»£ç çš„ä»£ç å®žçŽ°ï¼Œå¾ˆå¿«å°±å‘çŽ°äº†å‡ å¤„æ ¸å¿ƒä¸åŒã€‚ åœ¨æ–°ç‰ˆæœ¬çš„libuvc (0.0.7)ä¸­, æœ‰é’ˆå¯¹usb3.1 superspeed ç«¯å£çš„å¤„ç†é€»è¾‘ï¼Œè€ç‰ˆæœ¬æ²¡æœ‰ 1234567891011121314151617181920212223//steam.c uvc_error_t uvc_stream_start( uvc_stream_handle_t *strmh, uvc_frame_callback_t *cb, void *user_ptr, uint8_t flags) &#123;... struct libusb_ss_endpoint_companion_descriptor *ep_comp = 0; libusb_get_ss_endpoint_companion_descriptor(NULL, endpoint, &amp;ep_comp); if (ep_comp) &#123; UVC_DEBUG("packets_per_transfer = %d,config_bytes_per_packet=%d",ep_comp-&gt;wBytesPerInterval,config_bytes_per_packet); endpoint_bytes_per_packet = ep_comp-&gt;wBytesPerInterval; libusb_free_ss_endpoint_companion_descriptor(ep_comp); break; &#125;...&#125; æ–°ç‰ˆæœ¬çš„libusb (1.0.26), å•ä¸ªurb packet lenæ›´å¤§ 123456789101112131415161718192021222324252627282930313233343536373839//linux_usbfs.cstatic int submit_iso_transfer(struct usbi_transfer *itransfer)&#123; ... for (i = 0; i &lt; num_packets; i++) &#123; packet_len = transfer-&gt;iso_packet_desc[i].length; if (packet_len &gt; max_iso_packet_len) &#123; usbi_warn(TRANSFER_CTX(transfer), "iso packet length of %u bytes exceeds maximum of %u bytes", packet_len, max_iso_packet_len); return LIBUSB_ERROR_INVALID_PARAM; &#125; total_len += packet_len; &#125; ...&#125;static int op_init(struct libusb_context *ctx)&#123; ... if (!max_iso_packet_len) &#123; if (kernel_version_ge(&amp;kversion, 5, 2, 0)) max_iso_packet_len = 98304; else if (kernel_version_ge(&amp;kversion, 3, 10, 0)) max_iso_packet_len = 49152; else max_iso_packet_len = 8192; &#125; usbi_dbg("max iso packet length is (likely) %u bytes", max_iso_packet_len); ...&#125; è€ç‰ˆæœ¬çš„libusbä¸­ ï¼Œæ¯”æ–°ç‰ˆæœ¬æœ‰æ›´å¤šçš„urbè¯·æ±‚ 123456789101112131415161718192021222324//linux_usbfs.c#define MAX_ISO_BUFFER_LENGTH 32768 //32k...static int submit_iso_transfer(struct usbi_transfer *itransfer)&#123; ... /* calculate how many URBs we need */ for (i = 0; i &lt; num_packets; i++) &#123; unsigned int space_remaining = MAX_ISO_BUFFER_LENGTH - this_urb_len; packet_len = transfer-&gt;iso_packet_desc[i].length; if (packet_len &gt; space_remaining) &#123; num_urbs++; this_urb_len = packet_len; &#125; else &#123; this_urb_len += packet_len; &#125; &#125; usbi_err(TRANSFER_CTX(transfer),"need %d of 32k URBs for transfer", num_urbs); ...&#125; é¦–å…ˆè€çš„libuvc æ²¡æœ‰é’ˆå¯¹ ss ç«¯å£åšå¤„ç†ï¼Œè‚¯å®šæ˜¯æœ‰é—®é¢˜çš„ ï¼Œä¹Ÿå°±è§£é‡Šäº†æ‡µé€¼çš„å¼€å§‹ ä¸ºä»€ä¹ˆ4kç”»é¢èŠ±äº†ï¼Œåªæœ‰é¡¶ä¸Šä¸€ç‚¹ç‚¹å†…å®¹ï¼Œç»å¤§éƒ¨åˆ†æ˜¯ç°çš„ï¼Œå› ä¸º usb 2.0ç®—å‡ºæ¥ ä¼ è¾“ urbå°‘äº†ï¼Œåªæ‹¿åˆ°å‰é¢çš„urbæ•°æ®ï¼Œä¹Ÿå°±æ˜¯é¡¶éƒ¨çš„ç”»é¢ã€‚ æ–°ç‰ˆæœ¬çš„libusbä¸­ï¼Œurb size æ¯”è¾ƒå¤§ï¼Œ4kå‚æ•° ç®—ä¸‹æ¥åªéœ€è¦ä¸€ä¸ªurb ï¼Œä¹Ÿå°±æ˜¯å‡ºçŽ° â€œbad packet:xxxâ€ã€â€submiturb failed, errno=-12â€è¿™äº›å¼‚å¸¸æ—¥å¿—çš„åŽŸå› ã€‚ä¸ºä»€ä¹ˆlinuxä¸Šæ­£å¸¸ï¼Œè€Œandoirdæœ‰é—®é¢˜ï¼ŒçŒœæµ‹ æ‰‹æœºçš„å†…å­˜ã€å¸¦å®½ç­‰ç­‰è·Ÿpcè¿˜æ˜¯æ²¡æ³•æ¯”çš„ã€‚ã€‚ åˆ°è¿™é‡Œèƒ½æƒ³åˆ°çš„å¯å°è¯•æ–¹æ¡ˆ åŸºæœ¬å°±å‡ºæ¥äº† è€çš„uvc å¢žåŠ å¯¹ss çš„å¤„ç†é€»è¾‘ æ–°çš„usb å‡å°‘urb packet sizeï¼Œå‡ºæ›´å¤šçš„urb æœ€ç»ˆ ä¸¤ç§æ–¹æ¡ˆ å°è¯•ä¸‹ éƒ½å¯ä»¥è§£å†³é—®é¢˜ã€‚ã€‚ happy â€¦ otheré’ˆå¯¹è¿™ä¸¤ç‚¹ å®˜æ–¹ä»£ç çš„æäº¤åŽ†å² 12345libuvc Updating LibUVC; Adds support SS USB, Modify to support MSFT UVC metadata, Fix hang during stop, Add NV12 support, Remove debug message in release build86ad9640 Wes Barcalow &lt;wesbarc@microsoft.com&gt; on 2019/5/10 at 07:34 1234567891011121314151617181920libusblinux_usbfs: Improve isochronous transfer submission and error reportingThe Linux kernel has changed the maximum allowed packet length perisochronous packet numerous times, which can create difficulties intrying to report appropriate errors back to the user when submitting toolarge of a packet on older kernels.In an attempt to improve this situation, this commit adds logic thatwill use different per-packet limits based on the detected kernelversion. Additionally, the logic has been improved to split URBs basedon the number of isochronous packets per URB, which is currently (andhas been forever) limited to 128.Finally, the error reporting during URB submission has been improved tocatch and report errors relating to the transfer length being too large.8aad7fd1 Chris Dickens &lt;christopher.a.dickens@gmail.com&gt; on 2017/12/27 at 11:15]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>camera</tag>
        <tag>android</tag>
        <tag>usb</tag>
        <tag>uvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc videoæµç¨‹åˆ†æž]]></title>
    <url>%2F2023%2F03%2F01%2Fwebrtc-video%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[videoæ”¶é›†candidateä¹‹åŽï¼Œå°±å¯ä»¥å»ºç«‹å¥½æ•°æ®ä¼ è¾“çš„é€šé“äº†ï¼ŒçŽ°åœ¨é€šè¿‡æºç èµ°è¯»ä¸‹è§†é¢‘æ•°æ®æ˜¯å¦‚ä½• é‡‡é›† &amp; ç¼–ç  &amp; ä¼ è¾“çš„ videosource &amp;&amp; videotrack123456789101112131415_localVideoTrack = [self createLocalVideoTrack];if (_localVideoTrack) [_peerConnection addTrack:_localVideoTrack streamIds:@[ kARDMediaStreamId ]];``` ```c++- (RTC_OBJC_TYPE(RTCVideoTrack) *)createLocalVideoTrack &#123; if ([_settings currentAudioOnlySettingFromStore]) &#123; return nil; &#125; RTC_OBJC_TYPE(RTCVideoSource) *source = [_factory videoSource]; return [_factory videoTrackWithSource:source trackId:kARDVideoTrackId];&#125; è¿™é‡Œçš„ videosource è·Ÿ videotrack å°±æ˜¯ åŽé¢ captureçš„è¿‡ç¨‹çš„ delegate capture123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687RTC_OBJC_TYPE(RTCCameraVideoCapturer) *capturer = [[RTC_OBJC_TYPE(RTCCameraVideoCapturer) alloc] initWithDelegate:source];ARDSettingsModel *settingsModel = [[ARDSettingsModel alloc] init]; _captureController = [[ARDCaptureController alloc] initWithCapturer:localCapturer settings:settingsModel]; [_captureController startCapture];- (void)startCapture &#123; [self startCapture:nil];&#125;- (void)startCapture:(void (^)(NSError *))completion &#123; AVCaptureDevicePosition position = _usingFrontCamera ? AVCaptureDevicePositionFront : AVCaptureDevicePositionBack; AVCaptureDevice *device = [self findDeviceForPosition:position]; AVCaptureDeviceFormat *format = [self selectFormatForDevice:device]; if (format == nil) &#123; RTCLogError(@"No valid formats for device %@", device); NSAssert(NO, @""); return; &#125; NSInteger fps = [self selectFpsForFormat:format]; [_capturer startCaptureWithDevice:device format:format fps:fps completionHandler:completion];&#125;- (void)stopCapture &#123; [_capturer stopCapture];&#125;- (void)switchCamera &#123; _usingFrontCamera = !_usingFrontCamera; [self startCapture:nil];&#125;- (void)switchCamera:(void (^)(NSError *))completion &#123; _usingFrontCamera = !_usingFrontCamera; [self startCapture:completion];&#125;#pragma mark - Private- (AVCaptureDevice *)findDeviceForPosition:(AVCaptureDevicePosition)position &#123; NSArray&lt;AVCaptureDevice *&gt; *captureDevices = [RTC_OBJC_TYPE(RTCCameraVideoCapturer) captureDevices]; for (AVCaptureDevice *device in captureDevices) &#123; if (device.position == position) &#123; return device; &#125; &#125; return captureDevices[0];&#125;- (AVCaptureDeviceFormat *)selectFormatForDevice:(AVCaptureDevice *)device &#123; NSArray&lt;AVCaptureDeviceFormat *&gt; *formats = [RTC_OBJC_TYPE(RTCCameraVideoCapturer) supportedFormatsForDevice:device]; int targetWidth = [_settings currentVideoResolutionWidthFromStore]; int targetHeight = [_settings currentVideoResolutionHeightFromStore]; AVCaptureDeviceFormat *selectedFormat = nil; int currentDiff = INT_MAX; for (AVCaptureDeviceFormat *format in formats) &#123; CMVideoDimensions dimension = CMVideoFormatDescriptionGetDimensions(format.formatDescription); FourCharCode pixelFormat = CMFormatDescriptionGetMediaSubType(format.formatDescription); int diff = abs(targetWidth - dimension.width) + abs(targetHeight - dimension.height); if (diff &lt; currentDiff) &#123; selectedFormat = format; currentDiff = diff; &#125; else if (diff == currentDiff &amp;&amp; pixelFormat == [_capturer preferredOutputPixelFormat]) &#123; selectedFormat = format; &#125; &#125; return selectedFormat;&#125;- (NSInteger)selectFpsForFormat:(AVCaptureDeviceFormat *)format &#123; Float64 maxSupportedFramerate = 0; for (AVFrameRateRange *fpsRange in format.videoSupportedFrameRateRanges) &#123; maxSupportedFramerate = fmax(maxSupportedFramerate, fpsRange.maxFrameRate); &#125; return fmin(maxSupportedFramerate, kFramerateLimit);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121- (void)startCaptureWithDevice:(AVCaptureDevice *)device format:(AVCaptureDeviceFormat *)format fps:(NSInteger)fps completionHandler:(nullable void (^)(NSError *_Nullable error))completionHandler &#123; _willBeRunning = YES; [RTC_OBJC_TYPE(RTCDispatcher) dispatchAsyncOnType:RTCDispatcherTypeCaptureSession block:^&#123; RTCLogInfo("startCaptureWithDevice %@ @ %ld fps", format, (long)fps);#if TARGET_OS_IPHONE dispatch_async(dispatch_get_main_queue(), ^&#123; if (!self-&gt;_generatingOrientationNotifications) &#123; [[UIDevice currentDevice] beginGeneratingDeviceOrientationNotifications]; self-&gt;_generatingOrientationNotifications = YES; &#125; &#125;);#endif self.currentDevice = device; NSError *error = nil; if (![self.currentDevice lockForConfiguration:&amp;error]) &#123; RTCLogError(@"Failed to lock device %@. Error: %@", self.currentDevice, error.userInfo); if (completionHandler) &#123; completionHandler(error); &#125; self.willBeRunning = NO; return; &#125; [self reconfigureCaptureSessionInput]; [self updateOrientation]; [self updateDeviceCaptureFormat:format fps:fps]; [self updateVideoDataOutputPixelFormat:format]; [self.captureSession startRunning]; [self.currentDevice unlockForConfiguration]; self.isRunning = YES; if (completionHandler) &#123; completionHandler(nil); &#125; &#125;];&#125;#pragma mark AVCaptureVideoDataOutputSampleBufferDelegate- (void)captureOutput:(AVCaptureOutput *)captureOutput didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection &#123; NSParameterAssert(captureOutput == _videoDataOutput); if (CMSampleBufferGetNumSamples(sampleBuffer) != 1 || !CMSampleBufferIsValid(sampleBuffer) || !CMSampleBufferDataIsReady(sampleBuffer)) &#123; return; &#125; CVPixelBufferRef pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer); if (pixelBuffer == nil) &#123; return; &#125;#if TARGET_OS_IPHONE // Default to portrait orientation on iPhone. BOOL usingFrontCamera = NO; // Check the image's EXIF for the camera the image came from as the image could have been // delayed as we set alwaysDiscardsLateVideoFrames to NO. AVCaptureDevicePosition cameraPosition = [AVCaptureSession devicePositionForSampleBuffer:sampleBuffer]; if (cameraPosition != AVCaptureDevicePositionUnspecified) &#123; usingFrontCamera = AVCaptureDevicePositionFront == cameraPosition; &#125; else &#123; AVCaptureDeviceInput *deviceInput = (AVCaptureDeviceInput *)((AVCaptureInputPort *)connection.inputPorts.firstObject).input; usingFrontCamera = AVCaptureDevicePositionFront == deviceInput.device.position; &#125; switch (_orientation) &#123; case UIDeviceOrientationPortrait: _rotation = RTCVideoRotation_90; break; case UIDeviceOrientationPortraitUpsideDown: _rotation = RTCVideoRotation_270; break; case UIDeviceOrientationLandscapeLeft: _rotation = usingFrontCamera ? RTCVideoRotation_180 : RTCVideoRotation_0; break; case UIDeviceOrientationLandscapeRight: _rotation = usingFrontCamera ? RTCVideoRotation_0 : RTCVideoRotation_180; break; case UIDeviceOrientationFaceUp: case UIDeviceOrientationFaceDown: case UIDeviceOrientationUnknown: // Ignore. break; &#125;#else // No rotation on Mac. _rotation = RTCVideoRotation_0;#endif RTC_OBJC_TYPE(RTCCVPixelBuffer) *rtcPixelBuffer = [[RTC_OBJC_TYPE(RTCCVPixelBuffer) alloc] initWithPixelBuffer:pixelBuffer]; int64_t timeStampNs = CMTimeGetSeconds(CMSampleBufferGetPresentationTimeStamp(sampleBuffer)) * kNanosecondsPerSecond; RTC_OBJC_TYPE(RTCVideoFrame) *videoFrame = [[RTC_OBJC_TYPE(RTCVideoFrame) alloc] initWithBuffer:rtcPixelBuffer rotation:_rotation timeStampNs:timeStampNs]; [self.delegate capturer:self didCaptureVideoFrame:videoFrame];&#125;@implementation RTCObjCVideoSourceAdapter@synthesize objCVideoTrackSource = _objCVideoTrackSource;- (void)capturer:(RTC_OBJC_TYPE(RTCVideoCapturer) *)capturer didCaptureVideoFrame:(RTC_OBJC_TYPE(RTCVideoFrame) *)frame &#123; _objCVideoTrackSource-&gt;OnCapturedFrame(frame);&#125;@end 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687void ObjCVideoTrackSource::OnCapturedFrame(RTC_OBJC_TYPE(RTCVideoFrame) * frame) &#123; const int64_t timestamp_us = frame.timeStampNs / rtc::kNumNanosecsPerMicrosec; const int64_t translated_timestamp_us = timestamp_aligner_.TranslateTimestamp(timestamp_us, rtc::TimeMicros()); int adapted_width; int adapted_height; int crop_width; int crop_height; int crop_x; int crop_y; if (!AdaptFrame(frame.width, frame.height, timestamp_us, &amp;adapted_width, &amp;adapted_height, &amp;crop_width, &amp;crop_height, &amp;crop_x, &amp;crop_y)) &#123; return; &#125; rtc::scoped_refptr&lt;VideoFrameBuffer&gt; buffer; if (adapted_width == frame.width &amp;&amp; adapted_height == frame.height) &#123; // No adaption - optimized path. buffer = rtc::make_ref_counted&lt;ObjCFrameBuffer&gt;(frame.buffer); &#125; else if ([frame.buffer isKindOfClass:[RTC_OBJC_TYPE(RTCCVPixelBuffer) class]]) &#123; // Adapted CVPixelBuffer frame. RTC_OBJC_TYPE(RTCCVPixelBuffer) *rtcPixelBuffer = (RTC_OBJC_TYPE(RTCCVPixelBuffer) *)frame.buffer; buffer = rtc::make_ref_counted&lt;ObjCFrameBuffer&gt;([[RTC_OBJC_TYPE(RTCCVPixelBuffer) alloc] initWithPixelBuffer:rtcPixelBuffer.pixelBuffer adaptedWidth:adapted_width adaptedHeight:adapted_height cropWidth:crop_width cropHeight:crop_height cropX:crop_x + rtcPixelBuffer.cropX cropY:crop_y + rtcPixelBuffer.cropY]); &#125; else &#123; // Adapted I420 frame. // TODO(magjed): Optimize this I420 path. rtc::scoped_refptr&lt;I420Buffer&gt; i420_buffer = I420Buffer::Create(adapted_width, adapted_height); buffer = rtc::make_ref_counted&lt;ObjCFrameBuffer&gt;(frame.buffer); i420_buffer-&gt;CropAndScaleFrom(*buffer-&gt;ToI420(), crop_x, crop_y, crop_width, crop_height); buffer = i420_buffer; &#125; // Applying rotation is only supported for legacy reasons and performance is // not critical here. VideoRotation rotation = static_cast&lt;VideoRotation&gt;(frame.rotation); if (apply_rotation() &amp;&amp; rotation != kVideoRotation_0) &#123; buffer = I420Buffer::Rotate(*buffer-&gt;ToI420(), rotation); rotation = kVideoRotation_0; &#125; OnFrame(VideoFrame::Builder() .set_video_frame_buffer(buffer) .set_rotation(rotation) .set_timestamp_us(translated_timestamp_us) .build());&#125;void AdaptedVideoTrackSource::OnFrame(const webrtc::VideoFrame&amp; frame) &#123; rtc::scoped_refptr&lt;webrtc::VideoFrameBuffer&gt; buffer( frame.video_frame_buffer()); /* Note that this is a "best effort" approach to wants.rotation_applied; apply_rotation_ can change from false to true between the check of apply_rotation() and the call to broadcaster_.OnFrame(), in which case we generate a frame with pending rotation despite some sink with wants.rotation_applied == true was just added. The VideoBroadcaster enforces synchronization for us in this case, by not passing the frame on to sinks which don't want it. */ if (apply_rotation() &amp;&amp; frame.rotation() != webrtc::kVideoRotation_0 &amp;&amp; buffer-&gt;type() == webrtc::VideoFrameBuffer::Type::kI420) &#123; /* Apply pending rotation. */ webrtc::VideoFrame rotated_frame(frame); rotated_frame.set_video_frame_buffer( webrtc::I420Buffer::Rotate(*buffer-&gt;GetI420(), frame.rotation())); rotated_frame.set_rotation(webrtc::kVideoRotation_0); broadcaster_.OnFrame(rotated_frame); &#125; else &#123; broadcaster_.OnFrame(frame); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839.../webrtc/src/media/base/video_broadcaster.ccvoid VideoBroadcaster::OnFrame(const webrtc::VideoFrame&amp; frame) &#123; webrtc::MutexLock lock(&amp;sinks_and_wants_lock_); bool current_frame_was_discarded = false; for (auto&amp; sink_pair : sink_pairs()) &#123; if (sink_pair.wants.rotation_applied &amp;&amp; frame.rotation() != webrtc::kVideoRotation_0) &#123; // Calls to OnFrame are not synchronized with changes to the sink wants. // When rotation_applied is set to true, one or a few frames may get here // with rotation still pending. Protect sinks that don't expect any // pending rotation. RTC_LOG(LS_VERBOSE) &lt;&lt; "Discarding frame with unexpected rotation."; sink_pair.sink-&gt;OnDiscardedFrame(); current_frame_was_discarded = true; continue; &#125; if (sink_pair.wants.black_frames) &#123; webrtc::VideoFrame black_frame = webrtc::VideoFrame::Builder() .set_video_frame_buffer( GetBlackFrameBuffer(frame.width(), frame.height())) .set_rotation(frame.rotation()) .set_timestamp_us(frame.timestamp_us()) .set_id(frame.id()) .build(); sink_pair.sink-&gt;OnFrame(black_frame); &#125; else if (!previous_frame_sent_to_all_sinks_ &amp;&amp; frame.has_update_rect()) &#123; // Since last frame was not sent to some sinks, no reliable update // information is available, so we need to clear the update rect. webrtc::VideoFrame copy = frame; copy.clear_update_rect(); sink_pair.sink-&gt;OnFrame(copy); &#125; else &#123; sink_pair.sink-&gt;OnFrame(frame); &#125; &#125; previous_frame_sent_to_all_sinks_ = !current_frame_was_discarded;&#125; captureé‡‡é›†åˆ°frameæœ€åŽéƒ½ä¼šå›žè°ƒåˆ° video_broadcasterï¼Œç„¶åŽé€šè¿‡ broadcaster éåŽ†sink åˆ†å‘å‡ºåŽ» é€šè¿‡ track æ·»åŠ çš„sink éƒ½ä¼š ç»è¿‡ source è¿›åˆ° broadcaster æ¥ç®¡ç† 12345678910111213void AdaptedVideoTrackSource::AddOrUpdateSink( rtc::VideoSinkInterface&lt;webrtc::VideoFrame&gt;* sink, const rtc::VideoSinkWants&amp; wants) &#123; broadcaster_.AddOrUpdateSink(sink, wants); OnSinkWantsChanged(broadcaster_.wants());&#125;void AdaptedVideoTrackSource::RemoveSink( rtc::VideoSinkInterface&lt;webrtc::VideoFrame&gt;* sink) &#123; broadcaster_.RemoveSink(sink); OnSinkWantsChanged(broadcaster_.wants());&#125; sink æ‹¿åˆ° é‡‡é›†çš„ frame å°±ä¼š è¿›åˆ° encode çš„è¿‡ç¨‹ encode è¿‡ç¨‹ä¸­ frame_cadence_adapter å®žçŽ°äº† VideoSinkInterface æŽ¥å£ ä¼šä½œä¸ºsink æ·»åŠ åˆ° broadcasterä¸­ï¼Œæœ€ç»ˆä¼šè¿›åˆ° VideoStreamEncoderçš„ æ ¸å¿ƒé€»è¾‘ä¸­ã€‚ encodeencode çš„è¿‡ç¨‹æ˜¯æœ€å¤æ‚çš„é€»è¾‘ã€‚ã€‚ã€‚ã€‚ .../webrtc/src/pc/sdp_offer_answer.cc SdpOfferAnswerHandler::ApplyLocalDescription -&gt; SdpOfferAnswerHandler::UpdateTransceiversAndDataChannels -&gt; SdpOfferAnswerHandler::UpdateTransceiverChannel // åˆ›å»º channel SdpOfferAnswerHandler::UpdateSessionState -&gt; SdpOfferAnswerHandler::PushdownMediaDescription -&gt; 12345678910111213141516171819202122232425262728293031RTCError SdpOfferAnswerHandler::UpdateTransceiverChannel( rtc::scoped_refptr&lt;RtpTransceiverProxyWithInternal&lt;RtpTransceiver&gt;&gt; transceiver, const cricket::ContentInfo&amp; content, const cricket::ContentGroup* bundle_group) &#123; TRACE_EVENT0("webrtc", "SdpOfferAnswerHandler::UpdateTransceiverChannel"); RTC_DCHECK(IsUnifiedPlan()); RTC_DCHECK(transceiver); cricket::ChannelInterface* channel = transceiver-&gt;internal()-&gt;channel(); if (content.rejected) &#123; if (channel) &#123; transceiver-&gt;internal()-&gt;ClearChannel(); &#125; &#125; else &#123; if (!channel) &#123; auto error = transceiver-&gt;internal()-&gt;CreateChannel( content.name, pc_-&gt;call_ptr(), pc_-&gt;configuration()-&gt;media_config, pc_-&gt;SrtpRequired(), pc_-&gt;GetCryptoOptions(), audio_options(), video_options(), video_bitrate_allocator_factory_.get(), [&amp;](absl::string_view mid) &#123; RTC_DCHECK_RUN_ON(network_thread()); return transport_controller_n()-&gt;GetRtpTransport(mid); &#125;); if (!error.ok()) &#123; return error; &#125; &#125; &#125; return RTCError::OK();&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374.../webrtc/src/pc/rtp_transceiver.ccRTCError RtpTransceiver::CreateChannel( absl::string_view mid, Call* call_ptr, const cricket::MediaConfig&amp; media_config, bool srtp_required, CryptoOptions crypto_options, const cricket::AudioOptions&amp; audio_options, const cricket::VideoOptions&amp; video_options, VideoBitrateAllocatorFactory* video_bitrate_allocator_factory, std::function&lt;RtpTransportInternal*(absl::string_view)&gt; transport_lookup) &#123; RTC_DCHECK_RUN_ON(thread_); if (!media_engine()) &#123; // TODO(hta): Must be a better way return RTCError(RTCErrorType::INTERNAL_ERROR, "No media engine for mid=" + std::string(mid)); &#125; std::unique_ptr&lt;cricket::ChannelInterface&gt; new_channel; if (media_type() == cricket::MEDIA_TYPE_AUDIO) &#123; // TODO(bugs.webrtc.org/11992): CreateVideoChannel internally switches to // the worker thread. We shouldn't be using the `call_ptr_` hack here but // simply be on the worker thread and use `call_` (update upstream code). RTC_DCHECK(call_ptr); RTC_DCHECK(media_engine()); // TODO(bugs.webrtc.org/11992): Remove this workaround after updates in // PeerConnection and add the expectation that we're already on the right // thread. context()-&gt;worker_thread()-&gt;BlockingCall([&amp;] &#123; RTC_DCHECK_RUN_ON(context()-&gt;worker_thread()); cricket::VoiceMediaChannel* media_channel = media_engine()-&gt;voice().CreateMediaChannel( call_ptr, media_config, audio_options, crypto_options); if (!media_channel) &#123; return; &#125; new_channel = std::make_unique&lt;cricket::VoiceChannel&gt;( context()-&gt;worker_thread(), context()-&gt;network_thread(), context()-&gt;signaling_thread(), absl::WrapUnique(media_channel), mid, srtp_required, crypto_options, context()-&gt;ssrc_generator()); &#125;); &#125; else &#123; RTC_DCHECK_EQ(cricket::MEDIA_TYPE_VIDEO, media_type()); // TODO(bugs.webrtc.org/11992): CreateVideoChannel internally switches to // the worker thread. We shouldn't be using the `call_ptr_` hack here but // simply be on the worker thread and use `call_` (update upstream code). context()-&gt;worker_thread()-&gt;BlockingCall([&amp;] &#123; RTC_DCHECK_RUN_ON(context()-&gt;worker_thread()); cricket::VideoMediaChannel* media_channel = media_engine()-&gt;video().CreateMediaChannel( call_ptr, media_config, video_options, crypto_options, video_bitrate_allocator_factory); if (!media_channel) &#123; return; &#125; new_channel = std::make_unique&lt;cricket::VideoChannel&gt;( context()-&gt;worker_thread(), context()-&gt;network_thread(), context()-&gt;signaling_thread(), absl::WrapUnique(media_channel), mid, srtp_required, crypto_options, context()-&gt;ssrc_generator()); &#125;); &#125; if (!new_channel) &#123; // TODO(hta): Must be a better way return RTCError(RTCErrorType::INTERNAL_ERROR, "Failed to create channel for mid=" + std::string(mid)); &#125; SetChannel(std::move(new_channel), transport_lookup); return RTCError::OK();&#125; media_engine æ˜¯åˆ›å»º factory çš„è¿‡ç¨‹ä¸­ ç”Ÿæˆçš„ dependencies.media_engine = cricket::CreateMediaEngine(std::move(media_dependencies)); 1234567891011121314151617181920212223242526272829.../src/media/engine/webrtc_media_engine.ccstd::unique_ptr&lt;MediaEngineInterface&gt; CreateMediaEngine( MediaEngineDependencies dependencies) &#123; // TODO(sprang): Make populating `dependencies.trials` mandatory and remove // these fallbacks. std::unique_ptr&lt;webrtc::FieldTrialsView&gt; fallback_trials( dependencies.trials ? nullptr : new webrtc::FieldTrialBasedConfig()); const webrtc::FieldTrialsView&amp; trials = dependencies.trials ? *dependencies.trials : *fallback_trials; auto audio_engine = std::make_unique&lt;WebRtcVoiceEngine&gt;( dependencies.task_queue_factory, dependencies.adm.get(), std::move(dependencies.audio_encoder_factory), std::move(dependencies.audio_decoder_factory), std::move(dependencies.audio_mixer), std::move(dependencies.audio_processing), dependencies.audio_frame_processor, trials);#ifdef HAVE_WEBRTC_VIDEO auto video_engine = std::make_unique&lt;WebRtcVideoEngine&gt;( std::move(dependencies.video_encoder_factory), std::move(dependencies.video_decoder_factory), trials);#else auto video_engine = std::make_unique&lt;NullWebRtcVideoEngine&gt;();#endif return std::make_unique&lt;CompositeMediaEngine&gt;(std::move(fallback_trials), std::move(audio_engine), std::move(video_engine));&#125; 12345678910111213.../src/media/engine/webrtc_video_engine.ccVideoMediaChannel* WebRtcVideoEngine::CreateMediaChannel( webrtc::Call* call, const MediaConfig&amp; config, const VideoOptions&amp; options, const webrtc::CryptoOptions&amp; crypto_options, webrtc::VideoBitrateAllocatorFactory* video_bitrate_allocator_factory) &#123; RTC_LOG(LS_INFO) &lt;&lt; "CreateMediaChannel. Options: " &lt;&lt; options.ToString(); return new WebRtcVideoChannel(call, config, options, crypto_options, encoder_factory_.get(), decoder_factory_.get(), video_bitrate_allocator_factory);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198.../webrtc/src/pc/channel.ccVideoChannel::VideoChannel(rtc::Thread* worker_thread, rtc::Thread* network_thread, rtc::Thread* signaling_thread, std::unique_ptr&lt;VideoMediaChannel&gt; media_channel, absl::string_view mid, bool srtp_required, webrtc::CryptoOptions crypto_options, UniqueRandomIdGenerator* ssrc_generator) : BaseChannel(worker_thread, network_thread, signaling_thread, std::move(media_channel), mid, srtp_required, crypto_options, ssrc_generator), send_channel_(this-&gt;media_channel()-&gt;AsVideoChannel()), receive_channel_(this-&gt;media_channel()-&gt;AsVideoChannel()) &#123;&#125;bool BaseChannel::SetLocalContent(const MediaContentDescription* content, SdpType type, std::string&amp; error_desc) &#123; RTC_DCHECK_RUN_ON(worker_thread()); TRACE_EVENT0("webrtc", "BaseChannel::SetLocalContent"); return SetLocalContent_w(content, type, error_desc);&#125;bool VideoChannel::SetLocalContent_w(const MediaContentDescription* content, SdpType type, std::string&amp; error_desc) &#123; TRACE_EVENT0("webrtc", "VideoChannel::SetLocalContent_w"); RTC_DLOG(LS_INFO) &lt;&lt; "Setting local video description for " &lt;&lt; ToString(); RTC_LOG_THREAD_BLOCK_COUNT(); RtpHeaderExtensions header_extensions = GetDeduplicatedRtpHeaderExtensions(content-&gt;rtp_header_extensions()); bool update_header_extensions = true; media_send_channel()-&gt;SetExtmapAllowMixed(content-&gt;extmap_allow_mixed()); VideoRecvParameters recv_params = last_recv_params_; RtpParametersFromMediaDescription( content-&gt;as_video(), header_extensions, webrtc::RtpTransceiverDirectionHasRecv(content-&gt;direction()), &amp;recv_params); VideoSendParameters send_params = last_send_params_; bool needs_send_params_update = false; if (type == SdpType::kAnswer || type == SdpType::kPrAnswer) &#123; for (auto&amp; send_codec : send_params.codecs) &#123; auto* recv_codec = FindMatchingCodec(recv_params.codecs, send_codec); if (recv_codec) &#123; if (!recv_codec-&gt;packetization &amp;&amp; send_codec.packetization) &#123; send_codec.packetization.reset(); needs_send_params_update = true; &#125; else if (recv_codec-&gt;packetization != send_codec.packetization) &#123; error_desc = StringFormat( "Failed to set local answer due to invalid codec packetization " "specified in m-section with mid='%s'.", mid().c_str()); return false; &#125; &#125; &#125; &#125; if (!media_receive_channel()-&gt;SetRecvParameters(recv_params)) &#123; error_desc = StringFormat( "Failed to set local video description recv parameters for m-section " "with mid='%s'.", mid().c_str()); return false; &#125; bool criteria_modified = false; if (webrtc::RtpTransceiverDirectionHasRecv(content-&gt;direction())) &#123; for (const VideoCodec&amp; codec : content-&gt;as_video()-&gt;codecs()) &#123; if (MaybeAddHandledPayloadType(codec.id)) criteria_modified = true; &#125; &#125; last_recv_params_ = recv_params; if (needs_send_params_update) &#123; if (!media_send_channel()-&gt;SetSendParameters(send_params)) &#123; error_desc = StringFormat( "Failed to set send parameters for m-section with mid='%s'.", mid().c_str()); return false; &#125; last_send_params_ = send_params; &#125; if (!UpdateLocalStreams_w(content-&gt;as_video()-&gt;streams(), type, error_desc)) &#123; RTC_DCHECK(!error_desc.empty()); return false; &#125; set_local_content_direction(content-&gt;direction()); UpdateMediaSendRecvState_w(); RTC_DCHECK_BLOCK_COUNT_NO_MORE_THAN(0); bool success = MaybeUpdateDemuxerAndRtpExtensions_w( criteria_modified, update_header_extensions ? absl::optional&lt;RtpHeaderExtensions&gt;(std::move(header_extensions)) : absl::nullopt, error_desc); RTC_DCHECK_BLOCK_COUNT_NO_MORE_THAN(1); return success;&#125;bool BaseChannel::UpdateLocalStreams_w(const std::vector&lt;StreamParams&gt;&amp; streams, SdpType type, std::string&amp; error_desc) &#123; // In the case of RIDs (where SSRCs are not negotiated), this method will // generate an SSRC for each layer in StreamParams. That representation will // be stored internally in `local_streams_`. // In subsequent offers, the same stream can appear in `streams` again // (without the SSRCs), so it should be looked up using RIDs (if available) // and then by primary SSRC. // In both scenarios, it is safe to assume that the media channel will be // created with a StreamParams object with SSRCs. However, it is not safe to // assume that `local_streams_` will always have SSRCs as there are scenarios // in which niether SSRCs or RIDs are negotiated. // Check for streams that have been removed. bool ret = true; for (const StreamParams&amp; old_stream : local_streams_) &#123; if (!old_stream.has_ssrcs() || GetStream(streams, StreamFinder(&amp;old_stream))) &#123; continue; &#125; if (!media_send_channel()-&gt;RemoveSendStream(old_stream.first_ssrc())) &#123; error_desc = StringFormat( "Failed to remove send stream with ssrc %u from m-section with " "mid='%s'.", old_stream.first_ssrc(), mid().c_str()); ret = false; &#125; &#125; // Check for new streams. std::vector&lt;StreamParams&gt; all_streams; for (const StreamParams&amp; stream : streams) &#123; StreamParams* existing = GetStream(local_streams_, StreamFinder(&amp;stream)); if (existing) &#123; // Parameters cannot change for an existing stream. all_streams.push_back(*existing); continue; &#125; all_streams.push_back(stream); StreamParams&amp; new_stream = all_streams.back(); if (!new_stream.has_ssrcs() &amp;&amp; !new_stream.has_rids()) &#123; continue; &#125; RTC_DCHECK(new_stream.has_ssrcs() || new_stream.has_rids()); if (new_stream.has_ssrcs() &amp;&amp; new_stream.has_rids()) &#123; error_desc = StringFormat( "Failed to add send stream: %u into m-section with mid='%s'. Stream " "has both SSRCs and RIDs.", new_stream.first_ssrc(), mid().c_str()); ret = false; continue; &#125; // At this point we use the legacy simulcast group in StreamParams to // indicate that we want multiple layers to the media channel. if (!new_stream.has_ssrcs()) &#123; // TODO(bugs.webrtc.org/10250): Indicate if flex is desired here. new_stream.GenerateSsrcs(new_stream.rids().size(), /* rtx = */ true, /* flex_fec = */ false, ssrc_generator_); &#125; if (media_send_channel()-&gt;AddSendStream(new_stream)) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Add send stream ssrc: " &lt;&lt; new_stream.ssrcs[0] &lt;&lt; " into " &lt;&lt; ToString(); &#125; else &#123; error_desc = StringFormat( "Failed to add send stream ssrc: %u into m-section with mid='%s'", new_stream.first_ssrc(), mid().c_str()); ret = false; &#125; &#125; local_streams_ = all_streams; return ret;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151.../webrtc/src/media/engine/webrtc_video_engine.ccbool WebRtcVideoChannel::AddSendStream(const StreamParams&amp; sp) &#123; RTC_DCHECK_RUN_ON(&amp;thread_checker_); RTC_LOG(LS_INFO) &lt;&lt; "AddSendStream: " &lt;&lt; sp.ToString(); if (!ValidateStreamParams(sp)) return false; if (!ValidateSendSsrcAvailability(sp)) return false; for (uint32_t used_ssrc : sp.ssrcs) send_ssrcs_.insert(used_ssrc); webrtc::VideoSendStream::Config config(this); for (const RidDescription&amp; rid : sp.rids()) &#123; config.rtp.rids.push_back(rid.rid); &#125; config.suspend_below_min_bitrate = video_config_.suspend_below_min_bitrate; config.periodic_alr_bandwidth_probing = video_config_.periodic_alr_bandwidth_probing; config.encoder_settings.experiment_cpu_load_estimator = video_config_.experiment_cpu_load_estimator; config.encoder_settings.encoder_factory = encoder_factory_; config.encoder_settings.bitrate_allocator_factory = bitrate_allocator_factory_; config.encoder_settings.encoder_switch_request_callback = this; config.crypto_options = crypto_options_; config.rtp.extmap_allow_mixed = ExtmapAllowMixed(); config.rtcp_report_interval_ms = video_config_.rtcp_report_interval_ms; WebRtcVideoSendStream* stream = new WebRtcVideoSendStream( call_, sp, std::move(config), default_send_options_, video_config_.enable_cpu_adaptation, bitrate_config_.max_bitrate_bps, send_codec_, send_rtp_extensions_, send_params_); uint32_t ssrc = sp.first_ssrc(); RTC_DCHECK(ssrc != 0); send_streams_[ssrc] = stream; if (rtcp_receiver_report_ssrc_ == kDefaultRtcpReceiverReportSsrc) &#123; SetReceiverReportSsrc(ssrc); &#125; if (sending_) &#123; stream-&gt;SetSend(true); &#125; return true;&#125;void WebRtcVideoChannel::WebRtcVideoSendStream::SetSend(bool send) &#123; RTC_DCHECK_RUN_ON(&amp;thread_checker_); sending_ = send; UpdateSendState();&#125;void WebRtcVideoChannel::WebRtcVideoSendStream::SetSendParameters( const ChangedSendParameters&amp; params) &#123; RTC_DCHECK_RUN_ON(&amp;thread_checker_); // `recreate_stream` means construction-time parameters have changed and the // sending stream needs to be reset with the new config. bool recreate_stream = false; if (params.rtcp_mode) &#123; parameters_.config.rtp.rtcp_mode = *params.rtcp_mode; rtp_parameters_.rtcp.reduced_size = parameters_.config.rtp.rtcp_mode == webrtc::RtcpMode::kReducedSize; recreate_stream = true; &#125; if (params.extmap_allow_mixed) &#123; parameters_.config.rtp.extmap_allow_mixed = *params.extmap_allow_mixed; recreate_stream = true; &#125; if (params.rtp_header_extensions) &#123; parameters_.config.rtp.extensions = *params.rtp_header_extensions; rtp_parameters_.header_extensions = *params.rtp_header_extensions; recreate_stream = true; &#125; if (params.mid) &#123; parameters_.config.rtp.mid = *params.mid; recreate_stream = true; &#125; if (params.max_bandwidth_bps) &#123; parameters_.max_bitrate_bps = *params.max_bandwidth_bps; ReconfigureEncoder(nullptr); &#125; if (params.conference_mode) &#123; parameters_.conference_mode = *params.conference_mode; &#125; // Set codecs and options. if (params.send_codec) &#123; SetCodec(*params.send_codec); recreate_stream = false; // SetCodec has already recreated the stream. &#125; else if (params.conference_mode &amp;&amp; parameters_.codec_settings) &#123; SetCodec(*parameters_.codec_settings); recreate_stream = false; // SetCodec has already recreated the stream. &#125; if (recreate_stream) &#123; RTC_LOG(LS_INFO) &lt;&lt; "RecreateWebRtcStream (send) because of SetSendParameters"; RecreateWebRtcStream(); &#125;&#125;void WebRtcVideoChannel::WebRtcVideoSendStream::RecreateWebRtcStream() &#123; RTC_DCHECK_RUN_ON(&amp;thread_checker_); if (stream_ != NULL) &#123; call_-&gt;DestroyVideoSendStream(stream_); &#125; RTC_CHECK(parameters_.codec_settings); RTC_DCHECK_EQ((parameters_.encoder_config.content_type == webrtc::VideoEncoderConfig::ContentType::kScreen), parameters_.options.is_screencast.value_or(false)) &lt;&lt; "encoder content type inconsistent with screencast option"; parameters_.encoder_config.encoder_specific_settings = ConfigureVideoEncoderSettings(parameters_.codec_settings-&gt;codec); webrtc::VideoSendStream::Config config = parameters_.config.Copy(); if (!config.rtp.rtx.ssrcs.empty() &amp;&amp; config.rtp.rtx.payload_type == -1) &#123; RTC_LOG(LS_WARNING) &lt;&lt; "RTX SSRCs configured but there's no configured RTX " "payload type the set codec. Ignoring RTX."; config.rtp.rtx.ssrcs.clear(); &#125; if (parameters_.encoder_config.number_of_streams == 1) &#123; // SVC is used instead of simulcast. Remove unnecessary SSRCs. if (config.rtp.ssrcs.size() &gt; 1) &#123; config.rtp.ssrcs.resize(1); if (config.rtp.rtx.ssrcs.size() &gt; 1) &#123; config.rtp.rtx.ssrcs.resize(1); &#125; &#125; &#125; stream_ = call_-&gt;CreateVideoSendStream(std::move(config), parameters_.encoder_config.Copy()); parameters_.encoder_config.encoder_specific_settings = NULL; // Calls stream_-&gt;StartPerRtpStream() to start the VideoSendStream // if necessary conditions are met. UpdateSendState(); // Attach the source after starting the send stream to prevent frames from // being injected into a not-yet initializated video stream encoder. if (source_) &#123; stream_-&gt;SetSource(source_, GetDegradationPreference()); &#125;&#125; 123456789101112131415161718.../webrtc/src/call/degraded_call.ccVideoSendStream* DegradedCall::CreateVideoSendStream( VideoSendStream::Config config, VideoEncoderConfig encoder_config) &#123; std::unique_ptr&lt;FakeNetworkPipeTransportAdapter&gt; transport_adapter; if (!send_configs_.empty()) &#123; transport_adapter = std::make_unique&lt;FakeNetworkPipeTransportAdapter&gt;( send_pipe_.get(), call_.get(), clock_, config.send_transport); config.send_transport = transport_adapter.get(); &#125; VideoSendStream* send_stream = call_-&gt;CreateVideoSendStream( std::move(config), std::move(encoder_config)); if (send_stream &amp;&amp; transport_adapter) &#123; video_send_transport_adapters_[send_stream] = std::move(transport_adapter); &#125; return send_stream;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162.../webrtc/src/call/call.ccwebrtc::VideoSendStream* Call::CreateVideoSendStream( webrtc::VideoSendStream::Config config, VideoEncoderConfig encoder_config, std::unique_ptr&lt;FecController&gt; fec_controller) &#123; TRACE_EVENT0("webrtc", "Call::CreateVideoSendStream"); RTC_DCHECK_RUN_ON(worker_thread_); EnsureStarted(); video_send_delay_stats_-&gt;AddSsrcs(config); for (size_t ssrc_index = 0; ssrc_index &lt; config.rtp.ssrcs.size(); ++ssrc_index) &#123; event_log_-&gt;Log(std::make_unique&lt;RtcEventVideoSendStreamConfig&gt;( CreateRtcLogStreamConfig(config, ssrc_index))); &#125; // TODO(mflodman): Base the start bitrate on a current bandwidth estimate, if // the call has already started. // Copy ssrcs from `config` since `config` is moved. std::vector&lt;uint32_t&gt; ssrcs = config.rtp.ssrcs; VideoSendStream* send_stream = new VideoSendStream( clock_, num_cpu_cores_, task_queue_factory_, network_thread_, call_stats_-&gt;AsRtcpRttStats(), transport_send_.get(), bitrate_allocator_.get(), video_send_delay_stats_.get(), event_log_, std::move(config), std::move(encoder_config), suspended_video_send_ssrcs_, suspended_video_payload_states_, std::move(fec_controller), *config_.trials); for (uint32_t ssrc : ssrcs) &#123; RTC_DCHECK(video_send_ssrcs_.find(ssrc) == video_send_ssrcs_.end()); video_send_ssrcs_[ssrc] = send_stream; &#125; video_send_streams_.insert(send_stream); video_send_streams_empty_.store(false, std::memory_order_relaxed); // Forward resources that were previously added to the call to the new stream. for (const auto&amp; resource_forwarder : adaptation_resource_forwarders_) &#123; resource_forwarder-&gt;OnCreateVideoSendStream(send_stream); &#125; UpdateAggregateNetworkState(); return send_stream;&#125;webrtc::VideoSendStream* Call::CreateVideoSendStream( webrtc::VideoSendStream::Config config, VideoEncoderConfig encoder_config) &#123; RTC_DCHECK_RUN_ON(worker_thread_); if (config_.fec_controller_factory) &#123; RTC_LOG(LS_INFO) &lt;&lt; "External FEC Controller will be used."; &#125; std::unique_ptr&lt;FecController&gt; fec_controller = config_.fec_controller_factory ? config_.fec_controller_factory-&gt;CreateFecController() : std::make_unique&lt;FecControllerDefault&gt;(clock_); return CreateVideoSendStream(std::move(config), std::move(encoder_config), std::move(fec_controller));&#125; 123456789.../webrtc/src/video/video_send_stream.ccvoid VideoSendStream::SetSource( rtc::VideoSourceInterface&lt;webrtc::VideoFrame&gt;* source, const DegradationPreference&amp; degradation_preference) &#123; RTC_DCHECK_RUN_ON(&amp;thread_checker_); video_stream_encoder_-&gt;SetSource(source, degradation_preference);&#125; addtrack è¿‡ç¨‹ ä¼šåˆ›å»º transceiver ï¼Œtransceiver åˆ†åˆ«åˆ›å»º audiochannel &amp; videochannel åŽç»­channel ä¼šé’ˆå¯¹ sdp åšè§£æžï¼ˆlocal/remoteï¼‰, åå•†å‡º éŸ³è§†é¢‘ ä¼ è¾“çš„å„ç§å‚æ•° ï¼Œå‚æ•°ä¼šå­˜å‚¨åœ¨ VideoSendStreamä¸­ï¼Œè¿™æ—¶å€™encoder è¿˜æ²¡å¼€å§‹åˆ›å»º VideoSendStream æž„é€ å‡½æ•° ä¼š åˆ›å»º VideoStreamEncoder VideoStreamEncoder æ˜¯åŽç»­ åˆ›å»ºå…·ä½“çš„ encode ä»¥åŠ æŽ¥æ”¶ videoframe ç»è¿‡ encode ç¼–ç ï¼ŒæŽ¥æ”¶EncodedImage å›žè°ƒçš„ å…³é”®ç±» 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697.../webrtc/src/pc/rtp_transmission_manager.ccRTCErrorOr&lt;rtc::scoped_refptr&lt;RtpSenderInterface&gt;&gt;RtpTransmissionManager::AddTrack( rtc::scoped_refptr&lt;MediaStreamTrackInterface&gt; track, const std::vector&lt;std::string&gt;&amp; stream_ids, const std::vector&lt;RtpEncodingParameters&gt;* init_send_encodings) &#123; RTC_DCHECK_RUN_ON(signaling_thread()); return (IsUnifiedPlan() ? AddTrackUnifiedPlan(track, stream_ids, init_send_encodings) : AddTrackPlanB(track, stream_ids, init_send_encodings));&#125;RTCErrorOr&lt;rtc::scoped_refptr&lt;RtpSenderInterface&gt;&gt;RtpTransmissionManager::AddTrackUnifiedPlan( rtc::scoped_refptr&lt;MediaStreamTrackInterface&gt; track, const std::vector&lt;std::string&gt;&amp; stream_ids, const std::vector&lt;RtpEncodingParameters&gt;* init_send_encodings) &#123; auto transceiver = FindFirstTransceiverForAddedTrack(track, init_send_encodings); if (transceiver) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Reusing an existing " &lt;&lt; cricket::MediaTypeToString(transceiver-&gt;media_type()) &lt;&lt; " transceiver for AddTrack."; if (transceiver-&gt;stopping()) &#123; LOG_AND_RETURN_ERROR(RTCErrorType::INVALID_PARAMETER, "The existing transceiver is stopping."); &#125; if (transceiver-&gt;direction() == RtpTransceiverDirection::kRecvOnly) &#123; transceiver-&gt;internal()-&gt;set_direction( RtpTransceiverDirection::kSendRecv); &#125; else if (transceiver-&gt;direction() == RtpTransceiverDirection::kInactive) &#123; transceiver-&gt;internal()-&gt;set_direction( RtpTransceiverDirection::kSendOnly); &#125; transceiver-&gt;sender()-&gt;SetTrack(track.get()); transceiver-&gt;internal()-&gt;sender_internal()-&gt;set_stream_ids(stream_ids); transceiver-&gt;internal()-&gt;set_reused_for_addtrack(true); &#125; else &#123; cricket::MediaType media_type = (track-&gt;kind() == MediaStreamTrackInterface::kAudioKind ? cricket::MEDIA_TYPE_AUDIO : cricket::MEDIA_TYPE_VIDEO); RTC_LOG(LS_INFO) &lt;&lt; "Adding " &lt;&lt; cricket::MediaTypeToString(media_type) &lt;&lt; " transceiver in response to a call to AddTrack."; std::string sender_id = track-&gt;id(); // Avoid creating a sender with an existing ID by generating a random ID. // This can happen if this is the second time AddTrack has created a sender // for this track. if (FindSenderById(sender_id)) &#123; sender_id = rtc::CreateRandomUuid(); &#125; auto sender = CreateSender( media_type, sender_id, track, stream_ids, init_send_encodings ? *init_send_encodings : std::vector&lt;RtpEncodingParameters&gt;(1, RtpEncodingParameters&#123;&#125;)); auto receiver = CreateReceiver(media_type, rtc::CreateRandomUuid()); transceiver = CreateAndAddTransceiver(sender, receiver); transceiver-&gt;internal()-&gt;set_created_by_addtrack(true); transceiver-&gt;internal()-&gt;set_direction(RtpTransceiverDirection::kSendRecv); &#125; return transceiver-&gt;sender();&#125;rtc::scoped_refptr&lt;RtpSenderProxyWithInternal&lt;RtpSenderInternal&gt;&gt;RtpTransmissionManager::CreateSender( cricket::MediaType media_type, const std::string&amp; id, rtc::scoped_refptr&lt;MediaStreamTrackInterface&gt; track, const std::vector&lt;std::string&gt;&amp; stream_ids, const std::vector&lt;RtpEncodingParameters&gt;&amp; send_encodings) &#123; RTC_DCHECK_RUN_ON(signaling_thread()); rtc::scoped_refptr&lt;RtpSenderProxyWithInternal&lt;RtpSenderInternal&gt;&gt; sender; if (media_type == cricket::MEDIA_TYPE_AUDIO) &#123; RTC_DCHECK(!track || (track-&gt;kind() == MediaStreamTrackInterface::kAudioKind)); sender = RtpSenderProxyWithInternal&lt;RtpSenderInternal&gt;::Create( signaling_thread(), AudioRtpSender::Create(worker_thread(), id, legacy_stats_, this)); NoteUsageEvent(UsageEvent::AUDIO_ADDED); &#125; else &#123; RTC_DCHECK_EQ(media_type, cricket::MEDIA_TYPE_VIDEO); RTC_DCHECK(!track || (track-&gt;kind() == MediaStreamTrackInterface::kVideoKind)); sender = RtpSenderProxyWithInternal&lt;RtpSenderInternal&gt;::Create( signaling_thread(), VideoRtpSender::Create(worker_thread(), id, this)); NoteUsageEvent(UsageEvent::VIDEO_ADDED); &#125; bool set_track_succeeded = sender-&gt;SetTrack(track.get()); RTC_DCHECK(set_track_succeeded); sender-&gt;internal()-&gt;set_stream_ids(stream_ids); sender-&gt;internal()-&gt;set_init_send_encodings(send_encodings); return sender;&#125; RtpTransmissionManager::AddTrackUnifiedPlan -&gt; RtpSenderBase::SetTrack -&gt; VideoRtpSender::SetSend -&gt; WebRtcVideoChannel::WebRtcVideoSendStream::SetVideoSend -&gt; VideoSendStream::SetSource -&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071.../src/video/video_send_stream.ccVideoSendStream::VideoSendStream( Clock* clock, int num_cpu_cores, TaskQueueFactory* task_queue_factory, TaskQueueBase* network_queue, RtcpRttStats* call_stats, RtpTransportControllerSendInterface* transport, BitrateAllocatorInterface* bitrate_allocator, SendDelayStats* send_delay_stats, RtcEventLog* event_log, VideoSendStream::Config config, VideoEncoderConfig encoder_config, const std::map&lt;uint32_t, RtpState&gt;&amp; suspended_ssrcs, const std::map&lt;uint32_t, RtpPayloadState&gt;&amp; suspended_payload_states, std::unique_ptr&lt;FecController&gt; fec_controller, const FieldTrialsView&amp; field_trials) : rtp_transport_queue_(transport-&gt;GetWorkerQueue()), transport_(transport), stats_proxy_(clock, config, encoder_config.content_type, field_trials), config_(std::move(config)), content_type_(encoder_config.content_type), video_stream_encoder_(CreateVideoStreamEncoder( clock, num_cpu_cores, task_queue_factory, &amp;stats_proxy_, config_.encoder_settings, GetBitrateAllocationCallbackType(config_, field_trials), field_trials, config_.encoder_selector)), encoder_feedback_( clock, config_.rtp.ssrcs, video_stream_encoder_.get(), [this](uint32_t ssrc, const std::vector&lt;uint16_t&gt;&amp; seq_nums) &#123; return rtp_video_sender_-&gt;GetSentRtpPacketInfos(ssrc, seq_nums); &#125;), rtp_video_sender_( transport-&gt;CreateRtpVideoSender(suspended_ssrcs, suspended_payload_states, config_.rtp, config_.rtcp_report_interval_ms, config_.send_transport, CreateObservers(call_stats, &amp;encoder_feedback_, &amp;stats_proxy_, send_delay_stats), event_log, std::move(fec_controller), CreateFrameEncryptionConfig(&amp;config_), config_.frame_transformer)), send_stream_(clock, &amp;stats_proxy_, transport, bitrate_allocator, video_stream_encoder_.get(), &amp;config_, encoder_config.max_bitrate_bps, encoder_config.bitrate_priority, encoder_config.content_type, rtp_video_sender_, field_trials) &#123; RTC_DCHECK(config_.encoder_settings.encoder_factory); RTC_DCHECK(config_.encoder_settings.bitrate_allocator_factory); video_stream_encoder_-&gt;SetFecControllerOverride(rtp_video_sender_); ReconfigureVideoEncoder(std::move(encoder_config));&#125; send_stream_ å°±æ˜¯ VideoSendStreamImpl ç»§æ‰¿äº† VideoStreamEncoderInterface::EncoderSink å®žçŽ°äº† OnEncodedImage æ–¹æ³• 12345// Callback function which is called when an image has been encoded. virtual Result OnEncodedImage( const EncodedImage&amp; encoded_image, const CodecSpecificInfo* codec_specific_info) = 0; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134.../webrtc/src/video/video_stream_encoder.ccVideoStreamEncoder::VideoStreamEncoder( Clock* clock, uint32_t number_of_cores, VideoStreamEncoderObserver* encoder_stats_observer, const VideoStreamEncoderSettings&amp; settings, std::unique_ptr&lt;OveruseFrameDetector&gt; overuse_detector, std::unique_ptr&lt;FrameCadenceAdapterInterface&gt; frame_cadence_adapter, std::unique_ptr&lt;webrtc::TaskQueueBase, webrtc::TaskQueueDeleter&gt; encoder_queue, BitrateAllocationCallbackType allocation_cb_type, const FieldTrialsView&amp; field_trials, webrtc::VideoEncoderFactory::EncoderSelectorInterface* encoder_selector) : field_trials_(field_trials), worker_queue_(TaskQueueBase::Current()), number_of_cores_(number_of_cores), sink_(nullptr), settings_(settings), allocation_cb_type_(allocation_cb_type), rate_control_settings_(RateControlSettings::ParseFromFieldTrials()), encoder_selector_from_constructor_(encoder_selector), encoder_selector_from_factory_( encoder_selector_from_constructor_ ? nullptr : settings.encoder_factory-&gt;GetEncoderSelector()), encoder_selector_(encoder_selector_from_constructor_ ? encoder_selector_from_constructor_ : encoder_selector_from_factory_.get()), encoder_stats_observer_(encoder_stats_observer), cadence_callback_(*this), frame_cadence_adapter_(std::move(frame_cadence_adapter)), encoder_initialized_(false), max_framerate_(-1), pending_encoder_reconfiguration_(false), pending_encoder_creation_(false), crop_width_(0), crop_height_(0), encoder_target_bitrate_bps_(absl::nullopt), max_data_payload_length_(0), encoder_paused_and_dropped_frame_(false), was_encode_called_since_last_initialization_(false), encoder_failed_(false), clock_(clock), last_captured_timestamp_(0), delta_ntp_internal_ms_(clock_-&gt;CurrentNtpInMilliseconds() - clock_-&gt;TimeInMilliseconds()), last_frame_log_ms_(clock_-&gt;TimeInMilliseconds()), captured_frame_count_(0), dropped_frame_cwnd_pushback_count_(0), dropped_frame_encoder_block_count_(0), pending_frame_post_time_us_(0), accumulated_update_rect_&#123;0, 0, 0, 0&#125;, accumulated_update_rect_is_valid_(true), animation_start_time_(Timestamp::PlusInfinity()), cap_resolution_due_to_video_content_(false), expect_resize_state_(ExpectResizeState::kNoResize), fec_controller_override_(nullptr), force_disable_frame_dropper_(false), pending_frame_drops_(0), cwnd_frame_counter_(0), next_frame_types_(1, VideoFrameType::kVideoFrameDelta), frame_encode_metadata_writer_(this), experiment_groups_(GetExperimentGroups()), automatic_animation_detection_experiment_( ParseAutomatincAnimationDetectionFieldTrial()), input_state_provider_(encoder_stats_observer), video_stream_adapter_( std::make_unique&lt;VideoStreamAdapter&gt;(&amp;input_state_provider_, encoder_stats_observer, field_trials)), degradation_preference_manager_( std::make_unique&lt;DegradationPreferenceManager&gt;( video_stream_adapter_.get())), adaptation_constraints_(), stream_resource_manager_(&amp;input_state_provider_, encoder_stats_observer, clock_, settings_.experiment_cpu_load_estimator, std::move(overuse_detector), degradation_preference_manager_.get(), field_trials), video_source_sink_controller_(/*sink=*/frame_cadence_adapter_.get(), /*source=*/nullptr), default_limits_allowed_( !field_trials.IsEnabled("WebRTC-DefaultBitrateLimitsKillSwitch")), qp_parsing_allowed_( !field_trials.IsEnabled("WebRTC-QpParsingKillSwitch")), switch_encoder_on_init_failures_(!field_trials.IsDisabled( kSwitchEncoderOnInitializationFailuresFieldTrial)), vp9_low_tier_core_threshold_( ParseVp9LowTierCoreCountThreshold(field_trials)), encoder_queue_(std::move(encoder_queue)) &#123; TRACE_EVENT0("webrtc", "VideoStreamEncoder::VideoStreamEncoder"); RTC_DCHECK_RUN_ON(worker_queue_); RTC_DCHECK(encoder_stats_observer); RTC_DCHECK_GE(number_of_cores, 1); frame_cadence_adapter_-&gt;Initialize(&amp;cadence_callback_); stream_resource_manager_.Initialize(encoder_queue_.Get()); encoder_queue_.PostTask([this] &#123; RTC_DCHECK_RUN_ON(&amp;encoder_queue_); resource_adaptation_processor_ = std::make_unique&lt;ResourceAdaptationProcessor&gt;( video_stream_adapter_.get()); stream_resource_manager_.SetAdaptationProcessor( resource_adaptation_processor_.get(), video_stream_adapter_.get()); resource_adaptation_processor_-&gt;AddResourceLimitationsListener( &amp;stream_resource_manager_); video_stream_adapter_-&gt;AddRestrictionsListener(&amp;stream_resource_manager_); video_stream_adapter_-&gt;AddRestrictionsListener(this); stream_resource_manager_.MaybeInitializePixelLimitResource(); // Add the stream resource manager's resources to the processor. adaptation_constraints_ = stream_resource_manager_.AdaptationConstraints(); for (auto* constraint : adaptation_constraints_) &#123; video_stream_adapter_-&gt;AddAdaptationConstraint(constraint); &#125; &#125;);&#125;void VideoStreamEncoder::SetSink(EncoderSink* sink, bool rotation_applied) &#123; RTC_DCHECK_RUN_ON(worker_queue_); video_source_sink_controller_.SetRotationApplied(rotation_applied); video_source_sink_controller_.PushSourceSinkSettings(); encoder_queue_.PostTask([this, sink] &#123; RTC_DCHECK_RUN_ON(&amp;encoder_queue_); sink_ = sink; &#125;);&#125; videostreamencode é€šè¿‡ video_source_sink_controller_ frame_cadence_adapter_ æ³¨å…¥åˆ° videotrack sink ï¼Œè¿›è€ŒæŽ¥å— onframe çš„å›žè°ƒ12345cadence_callback_(*this),video_source_sink_controller_(/*sink=*/frame_cadence_adapter_.get(), /*source=*/nullptr), 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389void VideoStreamEncoder::OnFrame(Timestamp post_time, int frames_scheduled_for_processing, const VideoFrame&amp; video_frame) &#123; RTC_DCHECK_RUN_ON(&amp;encoder_queue_); VideoFrame incoming_frame = video_frame; // In some cases, e.g., when the frame from decoder is fed to encoder, // the timestamp may be set to the future. As the encoding pipeline assumes // capture time to be less than present time, we should reset the capture // timestamps here. Otherwise there may be issues with RTP send stream. if (incoming_frame.timestamp_us() &gt; post_time.us()) incoming_frame.set_timestamp_us(post_time.us()); // Capture time may come from clock with an offset and drift from clock_. int64_t capture_ntp_time_ms; if (video_frame.ntp_time_ms() &gt; 0) &#123; capture_ntp_time_ms = video_frame.ntp_time_ms(); &#125; else if (video_frame.render_time_ms() != 0) &#123; capture_ntp_time_ms = video_frame.render_time_ms() + delta_ntp_internal_ms_; &#125; else &#123; capture_ntp_time_ms = post_time.ms() + delta_ntp_internal_ms_; &#125; incoming_frame.set_ntp_time_ms(capture_ntp_time_ms); // Convert NTP time, in ms, to RTP timestamp. const int kMsToRtpTimestamp = 90; incoming_frame.set_timestamp( kMsToRtpTimestamp * static_cast&lt;uint32_t&gt;(incoming_frame.ntp_time_ms())); if (incoming_frame.ntp_time_ms() &lt;= last_captured_timestamp_) &#123; // We don't allow the same capture time for two frames, drop this one. RTC_LOG(LS_WARNING) &lt;&lt; "Same/old NTP timestamp (" &lt;&lt; incoming_frame.ntp_time_ms() &lt;&lt; " &lt;= " &lt;&lt; last_captured_timestamp_ &lt;&lt; ") for incoming frame. Dropping."; encoder_queue_.PostTask([this, incoming_frame]() &#123; RTC_DCHECK_RUN_ON(&amp;encoder_queue_); accumulated_update_rect_.Union(incoming_frame.update_rect()); accumulated_update_rect_is_valid_ &amp;= incoming_frame.has_update_rect(); &#125;); return; &#125; bool log_stats = false; if (post_time.ms() - last_frame_log_ms_ &gt; kFrameLogIntervalMs) &#123; last_frame_log_ms_ = post_time.ms(); log_stats = true; &#125; last_captured_timestamp_ = incoming_frame.ntp_time_ms(); encoder_stats_observer_-&gt;OnIncomingFrame(incoming_frame.width(), incoming_frame.height()); ++captured_frame_count_; CheckForAnimatedContent(incoming_frame, post_time.us()); bool cwnd_frame_drop = cwnd_frame_drop_interval_ &amp;&amp; (cwnd_frame_counter_++ % cwnd_frame_drop_interval_.value() == 0); if (frames_scheduled_for_processing == 1 &amp;&amp; !cwnd_frame_drop) &#123; MaybeEncodeVideoFrame(incoming_frame, post_time.us()); &#125; else &#123; if (cwnd_frame_drop) &#123; // Frame drop by congestion window pushback. Do not encode this // frame. ++dropped_frame_cwnd_pushback_count_; encoder_stats_observer_-&gt;OnFrameDropped( VideoStreamEncoderObserver::DropReason::kCongestionWindow); &#125; else &#123; // There is a newer frame in flight. Do not encode this frame. RTC_LOG(LS_VERBOSE) &lt;&lt; "Incoming frame dropped due to that the encoder is blocked."; ++dropped_frame_encoder_block_count_; encoder_stats_observer_-&gt;OnFrameDropped( VideoStreamEncoderObserver::DropReason::kEncoderQueue); &#125; accumulated_update_rect_.Union(incoming_frame.update_rect()); accumulated_update_rect_is_valid_ &amp;= incoming_frame.has_update_rect(); &#125; if (log_stats) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Number of frames: captured " &lt;&lt; captured_frame_count_ &lt;&lt; ", dropped (due to congestion window pushback) " &lt;&lt; dropped_frame_cwnd_pushback_count_ &lt;&lt; ", dropped (due to encoder blocked) " &lt;&lt; dropped_frame_encoder_block_count_ &lt;&lt; ", interval_ms " &lt;&lt; kFrameLogIntervalMs; captured_frame_count_ = 0; dropped_frame_cwnd_pushback_count_ = 0; dropped_frame_encoder_block_count_ = 0; &#125;&#125;void VideoStreamEncoder::MaybeEncodeVideoFrame(const VideoFrame&amp; video_frame, int64_t time_when_posted_us) &#123; RTC_DCHECK_RUN_ON(&amp;encoder_queue_); input_state_provider_.OnFrameSizeObserved(video_frame.size()); if (!last_frame_info_ || video_frame.width() != last_frame_info_-&gt;width || video_frame.height() != last_frame_info_-&gt;height || video_frame.is_texture() != last_frame_info_-&gt;is_texture) &#123; if ((!last_frame_info_ || video_frame.width() != last_frame_info_-&gt;width || video_frame.height() != last_frame_info_-&gt;height) &amp;&amp; settings_.encoder_switch_request_callback &amp;&amp; encoder_selector_) &#123; if (auto encoder = encoder_selector_-&gt;OnResolutionChange( &#123;video_frame.width(), video_frame.height()&#125;)) &#123; settings_.encoder_switch_request_callback-&gt;RequestEncoderSwitch( *encoder, /*allow_default_fallback=*/false); &#125; &#125; pending_encoder_reconfiguration_ = true; last_frame_info_ = VideoFrameInfo(video_frame.width(), video_frame.height(), video_frame.is_texture()); RTC_LOG(LS_INFO) &lt;&lt; "Video frame parameters changed: dimensions=" &lt;&lt; last_frame_info_-&gt;width &lt;&lt; "x" &lt;&lt; last_frame_info_-&gt;height &lt;&lt; ", texture=" &lt;&lt; last_frame_info_-&gt;is_texture &lt;&lt; "."; // Force full frame update, since resolution has changed. accumulated_update_rect_ = VideoFrame::UpdateRect&#123;0, 0, video_frame.width(), video_frame.height()&#125;; &#125; // We have to create the encoder before the frame drop logic, // because the latter depends on encoder_-&gt;GetScalingSettings. // According to the testcase // InitialFrameDropOffWhenEncoderDisabledScaling, the return value // from GetScalingSettings should enable or disable the frame drop. // Update input frame rate before we start using it. If we update it after // any potential frame drop we are going to artificially increase frame sizes. // Poll the rate before updating, otherwise we risk the rate being estimated // a little too high at the start of the call when then window is small. uint32_t framerate_fps = GetInputFramerateFps(); frame_cadence_adapter_-&gt;UpdateFrameRate(); int64_t now_ms = clock_-&gt;TimeInMilliseconds(); if (pending_encoder_reconfiguration_) &#123; ReconfigureEncoder(); last_parameters_update_ms_.emplace(now_ms); &#125; else if (!last_parameters_update_ms_ || now_ms - *last_parameters_update_ms_ &gt;= kParameterUpdateIntervalMs) &#123; if (last_encoder_rate_settings_) &#123; // Clone rate settings before update, so that SetEncoderRates() will // actually detect the change between the input and // `last_encoder_rate_setings_`, triggering the call to SetRate() on the // encoder. EncoderRateSettings new_rate_settings = *last_encoder_rate_settings_; new_rate_settings.rate_control.framerate_fps = static_cast&lt;double&gt;(framerate_fps); SetEncoderRates(UpdateBitrateAllocation(new_rate_settings)); &#125; last_parameters_update_ms_.emplace(now_ms); &#125; // Because pending frame will be dropped in any case, we need to // remember its updated region. if (pending_frame_) &#123; encoder_stats_observer_-&gt;OnFrameDropped( VideoStreamEncoderObserver::DropReason::kEncoderQueue); accumulated_update_rect_.Union(pending_frame_-&gt;update_rect()); accumulated_update_rect_is_valid_ &amp;= pending_frame_-&gt;has_update_rect(); &#125; if (DropDueToSize(video_frame.size())) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Dropping frame. Too large for target bitrate."; stream_resource_manager_.OnFrameDroppedDueToSize(); // Storing references to a native buffer risks blocking frame capture. if (video_frame.video_frame_buffer()-&gt;type() != VideoFrameBuffer::Type::kNative) &#123; pending_frame_ = video_frame; pending_frame_post_time_us_ = time_when_posted_us; &#125; else &#123; // Ensure that any previously stored frame is dropped. pending_frame_.reset(); accumulated_update_rect_.Union(video_frame.update_rect()); accumulated_update_rect_is_valid_ &amp;= video_frame.has_update_rect(); encoder_stats_observer_-&gt;OnFrameDropped( VideoStreamEncoderObserver::DropReason::kEncoderQueue); &#125; return; &#125; stream_resource_manager_.OnMaybeEncodeFrame(); if (EncoderPaused()) &#123; // Storing references to a native buffer risks blocking frame capture. if (video_frame.video_frame_buffer()-&gt;type() != VideoFrameBuffer::Type::kNative) &#123; if (pending_frame_) TraceFrameDropStart(); pending_frame_ = video_frame; pending_frame_post_time_us_ = time_when_posted_us; &#125; else &#123; // Ensure that any previously stored frame is dropped. pending_frame_.reset(); TraceFrameDropStart(); accumulated_update_rect_.Union(video_frame.update_rect()); accumulated_update_rect_is_valid_ &amp;= video_frame.has_update_rect(); encoder_stats_observer_-&gt;OnFrameDropped( VideoStreamEncoderObserver::DropReason::kEncoderQueue); &#125; return; &#125; pending_frame_.reset(); frame_dropper_.Leak(framerate_fps); // Frame dropping is enabled iff frame dropping is not force-disabled, and // rate controller is not trusted. const bool frame_dropping_enabled = !force_disable_frame_dropper_ &amp;&amp; !encoder_info_.has_trusted_rate_controller; frame_dropper_.Enable(frame_dropping_enabled); if (frame_dropping_enabled &amp;&amp; frame_dropper_.DropFrame()) &#123; RTC_LOG(LS_VERBOSE) &lt;&lt; "Drop Frame: " "target bitrate " &lt;&lt; (last_encoder_rate_settings_ ? last_encoder_rate_settings_-&gt;encoder_target.bps() : 0) &lt;&lt; ", input frame rate " &lt;&lt; framerate_fps; OnDroppedFrame( EncodedImageCallback::DropReason::kDroppedByMediaOptimizations); accumulated_update_rect_.Union(video_frame.update_rect()); accumulated_update_rect_is_valid_ &amp;= video_frame.has_update_rect(); return; &#125; EncodeVideoFrame(video_frame, time_when_posted_us);&#125;void VideoStreamEncoder::EncodeVideoFrame(const VideoFrame&amp; video_frame, int64_t time_when_posted_us) &#123; RTC_DCHECK_RUN_ON(&amp;encoder_queue_); RTC_LOG(LS_VERBOSE) &lt;&lt; __func__ &lt;&lt; " posted " &lt;&lt; time_when_posted_us &lt;&lt; " ntp time " &lt;&lt; video_frame.ntp_time_ms(); // If the encoder fail we can't continue to encode frames. When this happens // the WebrtcVideoSender is notified and the whole VideoSendStream is // recreated. if (encoder_failed_ || !encoder_initialized_) return; // It's possible that EncodeVideoFrame can be called after we've completed // a Stop() operation. Check if the encoder_ is set before continuing. // See: bugs.webrtc.org/12857 if (!encoder_) return; TraceFrameDropEnd(); // Encoder metadata needs to be updated before encode complete callback. VideoEncoder::EncoderInfo info = encoder_-&gt;GetEncoderInfo(); if (info.implementation_name != encoder_info_.implementation_name || info.is_hardware_accelerated != encoder_info_.is_hardware_accelerated) &#123; encoder_stats_observer_-&gt;OnEncoderImplementationChanged(&#123; .name = info.implementation_name, .is_hardware_accelerated = info.is_hardware_accelerated, &#125;); if (bitrate_adjuster_) &#123; // Encoder implementation changed, reset overshoot detector states. bitrate_adjuster_-&gt;Reset(); &#125; &#125; if (encoder_info_ != info) &#123; OnEncoderSettingsChanged(); stream_resource_manager_.ConfigureEncodeUsageResource(); // Re-configure scalers when encoder info changed. Consider two cases: // 1. When the status of the scaler changes from enabled to disabled, if we // don't do this CL, scaler will adapt up/down to trigger an unnecessary // full ReconfigureEncoder() when the scaler should be banned. // 2. When the status of the scaler changes from disabled to enabled, if we // don't do this CL, scaler will not work until some code trigger // ReconfigureEncoder(). In extreme cases, the scaler doesn't even work for // a long time when we expect that the scaler should work. stream_resource_manager_.ConfigureQualityScaler(info); stream_resource_manager_.ConfigureBandwidthQualityScaler(info); RTC_LOG(LS_INFO) &lt;&lt; "Encoder info changed to " &lt;&lt; info.ToString(); &#125; if (bitrate_adjuster_) &#123; for (size_t si = 0; si &lt; kMaxSpatialLayers; ++si) &#123; if (info.fps_allocation[si] != encoder_info_.fps_allocation[si]) &#123; bitrate_adjuster_-&gt;OnEncoderInfo(info); break; &#125; &#125; &#125; encoder_info_ = info; last_encode_info_ms_ = clock_-&gt;TimeInMilliseconds(); VideoFrame out_frame(video_frame); // Crop or scale the frame if needed. Dimension may be reduced to fit encoder // requirements, e.g. some encoders may require them to be divisible by 4. if ((crop_width_ &gt; 0 || crop_height_ &gt; 0) &amp;&amp; (out_frame.video_frame_buffer()-&gt;type() != VideoFrameBuffer::Type::kNative || !info.supports_native_handle)) &#123; int cropped_width = video_frame.width() - crop_width_; int cropped_height = video_frame.height() - crop_height_; rtc::scoped_refptr&lt;VideoFrameBuffer&gt; cropped_buffer; // TODO(ilnik): Remove scaling if cropping is too big, as it should never // happen after SinkWants signaled correctly from ReconfigureEncoder. VideoFrame::UpdateRect update_rect = video_frame.update_rect(); if (crop_width_ &lt; 4 &amp;&amp; crop_height_ &lt; 4) &#123; // The difference is small, crop without scaling. cropped_buffer = video_frame.video_frame_buffer()-&gt;CropAndScale( crop_width_ / 2, crop_height_ / 2, cropped_width, cropped_height, cropped_width, cropped_height); update_rect.offset_x -= crop_width_ / 2; update_rect.offset_y -= crop_height_ / 2; update_rect.Intersect( VideoFrame::UpdateRect&#123;0, 0, cropped_width, cropped_height&#125;); &#125; else &#123; // The difference is large, scale it. cropped_buffer = video_frame.video_frame_buffer()-&gt;Scale(cropped_width, cropped_height); if (!update_rect.IsEmpty()) &#123; // Since we can't reason about pixels after scaling, we invalidate whole // picture, if anything changed. update_rect = VideoFrame::UpdateRect&#123;0, 0, cropped_width, cropped_height&#125;; &#125; &#125; if (!cropped_buffer) &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Cropping and scaling frame failed, dropping frame."; return; &#125; out_frame.set_video_frame_buffer(cropped_buffer); out_frame.set_update_rect(update_rect); out_frame.set_ntp_time_ms(video_frame.ntp_time_ms()); // Since accumulated_update_rect_ is constructed before cropping, // we can't trust it. If any changes were pending, we invalidate whole // frame here. if (!accumulated_update_rect_.IsEmpty()) &#123; accumulated_update_rect_ = VideoFrame::UpdateRect&#123;0, 0, out_frame.width(), out_frame.height()&#125;; accumulated_update_rect_is_valid_ = false; &#125; &#125; if (!accumulated_update_rect_is_valid_) &#123; out_frame.clear_update_rect(); &#125; else if (!accumulated_update_rect_.IsEmpty() &amp;&amp; out_frame.has_update_rect()) &#123; accumulated_update_rect_.Union(out_frame.update_rect()); accumulated_update_rect_.Intersect( VideoFrame::UpdateRect&#123;0, 0, out_frame.width(), out_frame.height()&#125;); out_frame.set_update_rect(accumulated_update_rect_); accumulated_update_rect_.MakeEmptyUpdate(); &#125; accumulated_update_rect_is_valid_ = true; TRACE_EVENT_ASYNC_STEP0("webrtc", "Video", video_frame.render_time_ms(), "Encode"); stream_resource_manager_.OnEncodeStarted(out_frame, time_when_posted_us); // The encoder should get the size that it expects. RTC_DCHECK(send_codec_.width &lt;= out_frame.width() &amp;&amp; send_codec_.height &lt;= out_frame.height()) &lt;&lt; "Encoder configured to " &lt;&lt; send_codec_.width &lt;&lt; "x" &lt;&lt; send_codec_.height &lt;&lt; " received a too small frame " &lt;&lt; out_frame.width() &lt;&lt; "x" &lt;&lt; out_frame.height(); TRACE_EVENT1("webrtc", "VCMGenericEncoder::Encode", "timestamp", out_frame.timestamp()); frame_encode_metadata_writer_.OnEncodeStarted(out_frame); const int32_t encode_status = encoder_-&gt;Encode(out_frame, &amp;next_frame_types_); was_encode_called_since_last_initialization_ = true; if (encode_status &lt; 0) &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Encoder failed, failing encoder format: " &lt;&lt; encoder_config_.video_format.ToString(); RequestEncoderSwitch(); return; &#125; for (auto&amp; it : next_frame_types_) &#123; it = VideoFrameType::kVideoFrameDelta; &#125;&#125; ReconfigureEncoder() ä¸­æ ¹æ® encodefactory åˆ›å»º encoder encoder_ = settings_.encoder_factory-&gt;CreateVideoEncoder(encoder_config_.video_format); ç„¶åŽæ³¨å†Œ encoder çš„ å›žè°ƒ encoder_-&gt;RegisterEncodeCompleteCallback(this); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798EncodedImageCallback::Result VideoStreamEncoder::OnEncodedImage( const EncodedImage&amp; encoded_image, const CodecSpecificInfo* codec_specific_info) &#123; TRACE_EVENT_INSTANT1("webrtc", "VCMEncodedFrameCallback::Encoded", "timestamp", encoded_image.Timestamp()); // TODO(bugs.webrtc.org/10520): Signal the simulcast id explicitly. const size_t spatial_idx = encoded_image.SpatialIndex().value_or(0); const VideoCodecType codec_type = codec_specific_info ? codec_specific_info-&gt;codecType : VideoCodecType::kVideoCodecGeneric; EncodedImage image_copy = AugmentEncodedImage(encoded_image, codec_specific_info); // Post a task because `send_codec_` requires `encoder_queue_` lock and we // need to update on quality convergence. unsigned int image_width = image_copy._encodedWidth; unsigned int image_height = image_copy._encodedHeight; encoder_queue_.PostTask([this, codec_type, image_width, image_height, spatial_idx, at_target_quality = image_copy.IsAtTargetQuality()] &#123; RTC_DCHECK_RUN_ON(&amp;encoder_queue_); // Let the frame cadence adapter know about quality convergence. if (frame_cadence_adapter_) frame_cadence_adapter_-&gt;UpdateLayerQualityConvergence(spatial_idx, at_target_quality); // Currently, the internal quality scaler is used for VP9 instead of the // webrtc qp scaler (in the no-svc case or if only a single spatial layer is // encoded). It has to be explicitly detected and reported to adaptation // metrics. if (codec_type == VideoCodecType::kVideoCodecVP9 &amp;&amp; send_codec_.VP9()-&gt;automaticResizeOn) &#123; unsigned int expected_width = send_codec_.width; unsigned int expected_height = send_codec_.height; int num_active_layers = 0; for (int i = 0; i &lt; send_codec_.VP9()-&gt;numberOfSpatialLayers; ++i) &#123; if (send_codec_.spatialLayers[i].active) &#123; ++num_active_layers; expected_width = send_codec_.spatialLayers[i].width; expected_height = send_codec_.spatialLayers[i].height; &#125; &#125; RTC_DCHECK_LE(num_active_layers, 1) &lt;&lt; "VP9 quality scaling is enabled for " "SVC with several active layers."; encoder_stats_observer_-&gt;OnEncoderInternalScalerUpdate( image_width &lt; expected_width || image_height &lt; expected_height); &#125; &#125;); // Encoded is called on whatever thread the real encoder implementation run // on. In the case of hardware encoders, there might be several encoders // running in parallel on different threads. encoder_stats_observer_-&gt;OnSendEncodedImage(image_copy, codec_specific_info); EncodedImageCallback::Result result = sink_-&gt;OnEncodedImage(image_copy, codec_specific_info); // We are only interested in propagating the meta-data about the image, not // encoded data itself, to the post encode function. Since we cannot be sure // the pointer will still be valid when run on the task queue, set it to null. DataSize frame_size = DataSize::Bytes(image_copy.size()); image_copy.ClearEncodedData(); int temporal_index = 0; if (codec_specific_info) &#123; if (codec_specific_info-&gt;codecType == kVideoCodecVP9) &#123; temporal_index = codec_specific_info-&gt;codecSpecific.VP9.temporal_idx; &#125; else if (codec_specific_info-&gt;codecType == kVideoCodecVP8) &#123; temporal_index = codec_specific_info-&gt;codecSpecific.VP8.temporalIdx; &#125; &#125; if (temporal_index == kNoTemporalIdx) &#123; temporal_index = 0; &#125; RunPostEncode(image_copy, clock_-&gt;CurrentTime().us(), temporal_index, frame_size); if (result.error == Result::OK) &#123; // In case of an internal encoder running on a separate thread, the // decision to drop a frame might be a frame late and signaled via // atomic flag. This is because we can't easily wait for the worker thread // without risking deadlocks, eg during shutdown when the worker thread // might be waiting for the internal encoder threads to stop. if (pending_frame_drops_.load() &gt; 0) &#123; int pending_drops = pending_frame_drops_.fetch_sub(1); RTC_DCHECK_GT(pending_drops, 0); result.drop_next_frame = true; &#125; &#125; return result;&#125; sink_-&gt;OnEncodedImage(image_copy, codec_specific_info); è¿›åˆ°äº† VideoSendStreamImplçš„OnEncodedImageå¤„ç†é€»è¾‘ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091VideoSendStreamImpl::VideoSendStreamImpl( Clock* clock, SendStatisticsProxy* stats_proxy, RtpTransportControllerSendInterface* transport, BitrateAllocatorInterface* bitrate_allocator, VideoStreamEncoderInterface* video_stream_encoder, const VideoSendStream::Config* config, int initial_encoder_max_bitrate, double initial_encoder_bitrate_priority, VideoEncoderConfig::ContentType content_type, RtpVideoSenderInterface* rtp_video_sender, const FieldTrialsView&amp; field_trials) : clock_(clock), has_alr_probing_(config-&gt;periodic_alr_bandwidth_probing || GetAlrSettings(content_type)), pacing_config_(PacingConfig(field_trials)), stats_proxy_(stats_proxy), config_(config), rtp_transport_queue_(transport-&gt;GetWorkerQueue()), timed_out_(false), transport_(transport), bitrate_allocator_(bitrate_allocator), disable_padding_(true), max_padding_bitrate_(0), encoder_min_bitrate_bps_(0), encoder_max_bitrate_bps_( GetInitialEncoderMaxBitrate(initial_encoder_max_bitrate)), encoder_target_rate_bps_(0), encoder_bitrate_priority_(initial_encoder_bitrate_priority), video_stream_encoder_(video_stream_encoder), bandwidth_observer_(transport-&gt;GetBandwidthObserver()), rtp_video_sender_(rtp_video_sender), configured_pacing_factor_( GetConfiguredPacingFactor(*config_, content_type, pacing_config_)) &#123; RTC_DCHECK_GE(config_-&gt;rtp.payload_type, 0); RTC_DCHECK_LE(config_-&gt;rtp.payload_type, 127); RTC_DCHECK(!config_-&gt;rtp.ssrcs.empty()); RTC_DCHECK(transport_); RTC_DCHECK_NE(initial_encoder_max_bitrate, 0); RTC_LOG(LS_INFO) &lt;&lt; "VideoSendStreamImpl: " &lt;&lt; config_-&gt;ToString(); RTC_CHECK(AlrExperimentSettings::MaxOneFieldTrialEnabled()); // Only request rotation at the source when we positively know that the remote // side doesn't support the rotation extension. This allows us to prepare the // encoder in the expectation that rotation is supported - which is the common // case. bool rotation_applied = absl::c_none_of( config_-&gt;rtp.extensions, [](const RtpExtension&amp; extension) &#123; return extension.uri == RtpExtension::kVideoRotationUri; &#125;); video_stream_encoder_-&gt;SetSink(this, rotation_applied); absl::optional&lt;bool&gt; enable_alr_bw_probing; // If send-side BWE is enabled, check if we should apply updated probing and // pacing settings. if (configured_pacing_factor_) &#123; absl::optional&lt;AlrExperimentSettings&gt; alr_settings = GetAlrSettings(content_type); int queue_time_limit_ms; if (alr_settings) &#123; enable_alr_bw_probing = true; queue_time_limit_ms = alr_settings-&gt;max_paced_queue_time; &#125; else &#123; RateControlSettings rate_control_settings = RateControlSettings::ParseFromFieldTrials(); enable_alr_bw_probing = rate_control_settings.UseAlrProbing(); queue_time_limit_ms = pacing_config_.max_pacing_delay.Get().ms(); &#125; transport-&gt;SetQueueTimeLimit(queue_time_limit_ms); &#125; if (config_-&gt;periodic_alr_bandwidth_probing) &#123; enable_alr_bw_probing = config_-&gt;periodic_alr_bandwidth_probing; &#125; if (enable_alr_bw_probing) &#123; transport-&gt;EnablePeriodicAlrProbing(*enable_alr_bw_probing); &#125; rtp_transport_queue_-&gt;RunOrPost(SafeTask(transport_queue_safety_, [this] &#123; if (configured_pacing_factor_) transport_-&gt;SetPacingFactor(*configured_pacing_factor_); video_stream_encoder_-&gt;SetStartBitrate( bitrate_allocator_-&gt;GetStartBitrate(this)); &#125;));&#125; video_stream_encoder_-&gt;SetSink(this, rotation_applied); VideoSendStreamImpl ä½œä¸º VideoStreamEncoder çš„sinkï¼Œ æŽ¥æ”¶ç»è¿‡ç¼–ç ä¹‹åŽçš„å›¾åƒæ•°æ® 1234567891011121314151617181920212223242526272829303132.../webrtc/src/video/video_send_stream_impl.ccEncodedImageCallback::Result VideoSendStreamImpl::OnEncodedImage( const EncodedImage&amp; encoded_image, const CodecSpecificInfo* codec_specific_info) &#123; // Encoded is called on whatever thread the real encoder implementation run // on. In the case of hardware encoders, there might be several encoders // running in parallel on different threads. // Indicate that there still is activity going on. activity_ = true; RTC_DCHECK(!rtp_transport_queue_-&gt;IsCurrent()); auto task_to_run_on_worker = [this]() &#123; RTC_DCHECK_RUN_ON(rtp_transport_queue_); if (disable_padding_) &#123; disable_padding_ = false; // To ensure that padding bitrate is propagated to the bitrate allocator. SignalEncoderActive(); &#125; // Check if there's a throttled VideoBitrateAllocation that we should try // sending. auto&amp; context = video_bitrate_allocation_context_; if (context &amp;&amp; context-&gt;throttled_allocation) &#123; OnBitrateAllocationUpdated(*context-&gt;throttled_allocation); &#125; &#125;; rtp_transport_queue_-&gt;TaskQueueForPost()-&gt;PostTask( SafeTask(transport_queue_safety_, std::move(task_to_run_on_worker))); return rtp_video_sender_-&gt;OnEncodedImage(encoded_image, codec_specific_info);&#125; send123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314.../webrtc/src/call/rtp_video_sender.ccRtpVideoSender::RtpVideoSender( Clock* clock, const std::map&lt;uint32_t, RtpState&gt;&amp; suspended_ssrcs, const std::map&lt;uint32_t, RtpPayloadState&gt;&amp; states, const RtpConfig&amp; rtp_config, int rtcp_report_interval_ms, Transport* send_transport, const RtpSenderObservers&amp; observers, RtpTransportControllerSendInterface* transport, RtcEventLog* event_log, RateLimiter* retransmission_limiter, std::unique_ptr&lt;FecController&gt; fec_controller, FrameEncryptorInterface* frame_encryptor, const CryptoOptions&amp; crypto_options, rtc::scoped_refptr&lt;FrameTransformerInterface&gt; frame_transformer, const FieldTrialsView&amp; field_trials, TaskQueueFactory* task_queue_factory) : field_trials_(field_trials), use_frame_rate_for_overhead_(absl::StartsWith( field_trials_.Lookup("WebRTC-Video-UseFrameRateForOverhead"), "Enabled")), has_packet_feedback_(TransportSeqNumExtensionConfigured(rtp_config)), active_(false), fec_controller_(std::move(fec_controller)), fec_allowed_(true), rtp_streams_(CreateRtpStreamSenders(clock, rtp_config, observers, rtcp_report_interval_ms, send_transport, transport-&gt;GetBandwidthObserver(), transport, suspended_ssrcs, event_log, retransmission_limiter, frame_encryptor, crypto_options, std::move(frame_transformer), field_trials_, task_queue_factory)), rtp_config_(rtp_config), codec_type_(GetVideoCodecType(rtp_config)), transport_(transport), transport_overhead_bytes_per_packet_(0), encoder_target_rate_bps_(0), frame_counts_(rtp_config.ssrcs.size()), frame_count_observer_(observers.frame_count_observer) &#123; transport_checker_.Detach(); RTC_DCHECK_EQ(rtp_config_.ssrcs.size(), rtp_streams_.size()); if (has_packet_feedback_) transport_-&gt;IncludeOverheadInPacedSender(); // SSRCs are assumed to be sorted in the same order as `rtp_modules`. for (uint32_t ssrc : rtp_config_.ssrcs) &#123; // Restore state if it previously existed. const RtpPayloadState* state = nullptr; auto it = states.find(ssrc); if (it != states.end()) &#123; state = &amp;it-&gt;second; shared_frame_id_ = std::max(shared_frame_id_, state-&gt;shared_frame_id); &#125; params_.push_back(RtpPayloadParams(ssrc, state, field_trials_)); &#125; // RTP/RTCP initialization. for (size_t i = 0; i &lt; rtp_config_.extensions.size(); ++i) &#123; const std::string&amp; extension = rtp_config_.extensions[i].uri; int id = rtp_config_.extensions[i].id; RTC_DCHECK(RtpExtension::IsSupportedForVideo(extension)); for (const RtpStreamSender&amp; stream : rtp_streams_) &#123; stream.rtp_rtcp-&gt;RegisterRtpHeaderExtension(extension, id); &#125; &#125; ConfigureSsrcs(suspended_ssrcs); if (!rtp_config_.mid.empty()) &#123; for (const RtpStreamSender&amp; stream : rtp_streams_) &#123; stream.rtp_rtcp-&gt;SetMid(rtp_config_.mid); &#125; &#125; bool fec_enabled = false; for (const RtpStreamSender&amp; stream : rtp_streams_) &#123; // Simulcast has one module for each layer. Set the CNAME on all modules. stream.rtp_rtcp-&gt;SetCNAME(rtp_config_.c_name.c_str()); stream.rtp_rtcp-&gt;SetMaxRtpPacketSize(rtp_config_.max_packet_size); stream.rtp_rtcp-&gt;RegisterSendPayloadFrequency(rtp_config_.payload_type, kVideoPayloadTypeFrequency); if (stream.fec_generator != nullptr) &#123; fec_enabled = true; &#125; &#125; // Currently, both ULPFEC and FlexFEC use the same FEC rate calculation logic, // so enable that logic if either of those FEC schemes are enabled. fec_controller_-&gt;SetProtectionMethod(fec_enabled, NackEnabled()); fec_controller_-&gt;SetProtectionCallback(this); // Construction happens on the worker thread (see Call::CreateVideoSendStream) // but subseqeuent calls to the RTP state will happen on one of two threads: // * The pacer thread for actually sending packets. // * The transport thread when tearing down and quering GetRtpState(). // Detach thread checkers. for (const RtpStreamSender&amp; stream : rtp_streams_) &#123; stream.rtp_rtcp-&gt;OnPacketSendingThreadSwitched(); &#125;&#125;std::vector&lt;RtpStreamSender&gt; CreateRtpStreamSenders( Clock* clock, const RtpConfig&amp; rtp_config, const RtpSenderObservers&amp; observers, int rtcp_report_interval_ms, Transport* send_transport, RtcpBandwidthObserver* bandwidth_callback, RtpTransportControllerSendInterface* transport, const std::map&lt;uint32_t, RtpState&gt;&amp; suspended_ssrcs, RtcEventLog* event_log, RateLimiter* retransmission_rate_limiter, FrameEncryptorInterface* frame_encryptor, const CryptoOptions&amp; crypto_options, rtc::scoped_refptr&lt;FrameTransformerInterface&gt; frame_transformer, const FieldTrialsView&amp; trials, TaskQueueFactory* task_queue_factory) &#123; RTC_DCHECK_GT(rtp_config.ssrcs.size(), 0); RTC_DCHECK(task_queue_factory); RtpRtcpInterface::Configuration configuration; configuration.clock = clock; configuration.audio = false; configuration.receiver_only = false; configuration.outgoing_transport = send_transport; configuration.intra_frame_callback = observers.intra_frame_callback; configuration.rtcp_loss_notification_observer = observers.rtcp_loss_notification_observer; configuration.bandwidth_callback = bandwidth_callback; configuration.network_state_estimate_observer = transport-&gt;network_state_estimate_observer(); configuration.transport_feedback_callback = transport-&gt;transport_feedback_observer(); configuration.rtt_stats = observers.rtcp_rtt_stats; configuration.rtcp_packet_type_counter_observer = observers.rtcp_type_observer; configuration.report_block_data_observer = observers.report_block_data_observer; configuration.paced_sender = transport-&gt;packet_sender(); configuration.send_bitrate_observer = observers.bitrate_observer; configuration.send_side_delay_observer = observers.send_delay_observer; configuration.send_packet_observer = observers.send_packet_observer; configuration.event_log = event_log; configuration.retransmission_rate_limiter = retransmission_rate_limiter; configuration.rtp_stats_callback = observers.rtp_stats; configuration.frame_encryptor = frame_encryptor; configuration.require_frame_encryption = crypto_options.sframe.require_frame_encryption; configuration.extmap_allow_mixed = rtp_config.extmap_allow_mixed; configuration.rtcp_report_interval_ms = rtcp_report_interval_ms; configuration.field_trials = &amp;trials; std::vector&lt;RtpStreamSender&gt; rtp_streams; RTC_DCHECK(rtp_config.rtx.ssrcs.empty() || rtp_config.rtx.ssrcs.size() == rtp_config.ssrcs.size()); // Some streams could have been disabled, but the rids are still there. // This will occur when simulcast has been disabled for a codec (e.g. VP9) RTC_DCHECK(rtp_config.rids.empty() || rtp_config.rids.size() &gt;= rtp_config.ssrcs.size()); for (size_t i = 0; i &lt; rtp_config.ssrcs.size(); ++i) &#123; RTPSenderVideo::Config video_config; configuration.local_media_ssrc = rtp_config.ssrcs[i]; std::unique_ptr&lt;VideoFecGenerator&gt; fec_generator = MaybeCreateFecGenerator(clock, rtp_config, suspended_ssrcs, i, trials); configuration.fec_generator = fec_generator.get(); configuration.rtx_send_ssrc = rtp_config.GetRtxSsrcAssociatedWithMediaSsrc(rtp_config.ssrcs[i]); RTC_DCHECK_EQ(configuration.rtx_send_ssrc.has_value(), !rtp_config.rtx.ssrcs.empty()); configuration.rid = (i &lt; rtp_config.rids.size()) ? rtp_config.rids[i] : ""; configuration.need_rtp_packet_infos = rtp_config.lntf.enabled; std::unique_ptr&lt;ModuleRtpRtcpImpl2&gt; rtp_rtcp( ModuleRtpRtcpImpl2::Create(configuration)); rtp_rtcp-&gt;SetSendingStatus(false); rtp_rtcp-&gt;SetSendingMediaStatus(false); rtp_rtcp-&gt;SetRTCPStatus(RtcpMode::kCompound); // Set NACK. rtp_rtcp-&gt;SetStorePacketsStatus(true, kMinSendSidePacketHistorySize); video_config.clock = configuration.clock; video_config.rtp_sender = rtp_rtcp-&gt;RtpSender(); video_config.frame_encryptor = frame_encryptor; video_config.require_frame_encryption = crypto_options.sframe.require_frame_encryption; video_config.enable_retransmit_all_layers = false; video_config.field_trials = &amp;trials; const bool using_flexfec = fec_generator &amp;&amp; fec_generator-&gt;GetFecType() == VideoFecGenerator::FecType::kFlexFec; const bool should_disable_red_and_ulpfec = ShouldDisableRedAndUlpfec(using_flexfec, rtp_config, trials); if (!should_disable_red_and_ulpfec &amp;&amp; rtp_config.ulpfec.red_payload_type != -1) &#123; video_config.red_payload_type = rtp_config.ulpfec.red_payload_type; &#125; if (fec_generator) &#123; video_config.fec_type = fec_generator-&gt;GetFecType(); video_config.fec_overhead_bytes = fec_generator-&gt;MaxPacketOverhead(); &#125; video_config.frame_transformer = frame_transformer; video_config.task_queue_factory = task_queue_factory; auto sender_video = std::make_unique&lt;RTPSenderVideo&gt;(video_config); rtp_streams.emplace_back(std::move(rtp_rtcp), std::move(sender_video), std::move(fec_generator)); &#125; return rtp_streams;&#125;EncodedImageCallback::Result RtpVideoSender::OnEncodedImage( const EncodedImage&amp; encoded_image, const CodecSpecificInfo* codec_specific_info) &#123; fec_controller_-&gt;UpdateWithEncodedData(encoded_image.size(), encoded_image._frameType); MutexLock lock(&amp;mutex_); RTC_DCHECK(!rtp_streams_.empty()); if (!active_) return Result(Result::ERROR_SEND_FAILED); shared_frame_id_++; size_t stream_index = 0; if (codec_specific_info &amp;&amp; (codec_specific_info-&gt;codecType == kVideoCodecVP8 || codec_specific_info-&gt;codecType == kVideoCodecH264 || codec_specific_info-&gt;codecType == kVideoCodecGeneric)) &#123; // Map spatial index to simulcast. stream_index = encoded_image.SpatialIndex().value_or(0); &#125; RTC_DCHECK_LT(stream_index, rtp_streams_.size()); uint32_t rtp_timestamp = encoded_image.Timestamp() + rtp_streams_[stream_index].rtp_rtcp-&gt;StartTimestamp(); // RTCPSender has it's own copy of the timestamp offset, added in // RTCPSender::BuildSR, hence we must not add the in the offset for this call. // TODO(nisse): Delete RTCPSender:timestamp_offset_, and see if we can confine // knowledge of the offset to a single place. if (!rtp_streams_[stream_index].rtp_rtcp-&gt;OnSendingRtpFrame( encoded_image.Timestamp(), encoded_image.capture_time_ms_, rtp_config_.payload_type, encoded_image._frameType == VideoFrameType::kVideoFrameKey)) &#123; // The payload router could be active but this module isn't sending. return Result(Result::ERROR_SEND_FAILED); &#125; absl::optional&lt;int64_t&gt; expected_retransmission_time_ms; if (encoded_image.RetransmissionAllowed()) &#123; expected_retransmission_time_ms = rtp_streams_[stream_index].rtp_rtcp-&gt;ExpectedRetransmissionTimeMs(); &#125; if (IsFirstFrameOfACodedVideoSequence(encoded_image, codec_specific_info)) &#123; // In order to use the dependency descriptor RTP header extension: // - Pass along any `FrameDependencyStructure` templates produced by the // encoder adapter. // - If none were produced the `RtpPayloadParams::*ToGeneric` for the // particular codec have simulated a dependency structure, so provide a // minimal set of templates. // - Otherwise, don't pass along any templates at all which will disable // the generation of a dependency descriptor. RTPSenderVideo&amp; sender_video = *rtp_streams_[stream_index].sender_video; if (codec_specific_info &amp;&amp; codec_specific_info-&gt;template_structure) &#123; sender_video.SetVideoStructure(&amp;*codec_specific_info-&gt;template_structure); &#125; else if (absl::optional&lt;FrameDependencyStructure&gt; structure = params_[stream_index].GenericStructure( codec_specific_info)) &#123; sender_video.SetVideoStructure(&amp;*structure); &#125; else &#123; sender_video.SetVideoStructure(nullptr); &#125; &#125; bool send_result = rtp_streams_[stream_index].sender_video-&gt;SendEncodedImage( rtp_config_.payload_type, codec_type_, rtp_timestamp, encoded_image, params_[stream_index].GetRtpVideoHeader( encoded_image, codec_specific_info, shared_frame_id_), expected_retransmission_time_ms); if (frame_count_observer_) &#123; FrameCounts&amp; counts = frame_counts_[stream_index]; if (encoded_image._frameType == VideoFrameType::kVideoFrameKey) &#123; ++counts.key_frames; &#125; else if (encoded_image._frameType == VideoFrameType::kVideoFrameDelta) &#123; ++counts.delta_frames; &#125; else &#123; RTC_DCHECK(encoded_image._frameType == VideoFrameType::kEmptyFrame); &#125; frame_count_observer_-&gt;FrameCountUpdated(counts, rtp_config_.ssrcs[stream_index]); &#125; if (!send_result) return Result(Result::ERROR_SEND_FAILED); return Result(Result::OK, rtp_timestamp);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382.../webrtc/src/modules/rtp_rtcp/source/rtp_sender_video.ccRTPSenderVideo::RTPSenderVideo(const Config&amp; config) : rtp_sender_(config.rtp_sender), clock_(config.clock), retransmission_settings_( config.enable_retransmit_all_layers ? kRetransmitAllLayers : (kRetransmitBaseLayer | kConditionallyRetransmitHigherLayers)), last_rotation_(kVideoRotation_0), transmit_color_space_next_frame_(false), send_allocation_(SendVideoLayersAllocation::kDontSend), current_playout_delay_&#123;-1, -1&#125;, playout_delay_pending_(false), forced_playout_delay_(LoadVideoPlayoutDelayOverride(config.field_trials)), red_payload_type_(config.red_payload_type), fec_type_(config.fec_type), fec_overhead_bytes_(config.fec_overhead_bytes), packetization_overhead_bitrate_(1000, RateStatistics::kBpsScale), frame_encryptor_(config.frame_encryptor), require_frame_encryption_(config.require_frame_encryption), generic_descriptor_auth_experiment_(!absl::StartsWith( config.field_trials-&gt;Lookup("WebRTC-GenericDescriptorAuth"), "Disabled")), absolute_capture_time_sender_(config.clock), frame_transformer_delegate_( config.frame_transformer ? rtc::make_ref_counted&lt;RTPSenderVideoFrameTransformerDelegate&gt;( this, config.frame_transformer, rtp_sender_-&gt;SSRC(), rtp_sender_-&gt;Csrcs(), config.task_queue_factory) : nullptr), include_capture_clock_offset_(!absl::StartsWith( config.field_trials-&gt;Lookup(kIncludeCaptureClockOffset), "Disabled")) &#123; if (frame_transformer_delegate_) frame_transformer_delegate_-&gt;Init();&#125;bool RTPSenderVideo::SendEncodedImage( int payload_type, absl::optional&lt;VideoCodecType&gt; codec_type, uint32_t rtp_timestamp, const EncodedImage&amp; encoded_image, RTPVideoHeader video_header, absl::optional&lt;int64_t&gt; expected_retransmission_time_ms) &#123; if (frame_transformer_delegate_) &#123; // The frame will be sent async once transformed. return frame_transformer_delegate_-&gt;TransformFrame( payload_type, codec_type, rtp_timestamp, encoded_image, video_header, expected_retransmission_time_ms); &#125; return SendVideo(payload_type, codec_type, rtp_timestamp, encoded_image.capture_time_ms_, encoded_image, video_header, expected_retransmission_time_ms, rtp_sender_-&gt;Csrcs());&#125;bool RTPSenderVideo::SendVideo( int payload_type, absl::optional&lt;VideoCodecType&gt; codec_type, uint32_t rtp_timestamp, int64_t capture_time_ms, rtc::ArrayView&lt;const uint8_t&gt; payload, RTPVideoHeader video_header, absl::optional&lt;int64_t&gt; expected_retransmission_time_ms, std::vector&lt;uint32_t&gt; csrcs) &#123; TRACE_EVENT_ASYNC_STEP1("webrtc", "Video", capture_time_ms, "Send", "type", FrameTypeToString(video_header.frame_type)); RTC_CHECK_RUNS_SERIALIZED(&amp;send_checker_); if (video_header.frame_type == VideoFrameType::kEmptyFrame) return true; if (payload.empty()) return false; if (!rtp_sender_-&gt;SendingMedia()) &#123; return false; &#125; int32_t retransmission_settings = retransmission_settings_; if (codec_type == VideoCodecType::kVideoCodecH264) &#123; // Backward compatibility for older receivers without temporal layer logic. retransmission_settings = kRetransmitBaseLayer | kRetransmitHigherLayers; &#125; MaybeUpdateCurrentPlayoutDelay(video_header); if (video_header.frame_type == VideoFrameType::kVideoFrameKey) &#123; if (!IsNoopDelay(current_playout_delay_)) &#123; // Force playout delay on key-frames, if set. playout_delay_pending_ = true; &#125; if (allocation_) &#123; // Send the bitrate allocation on every key frame. send_allocation_ = SendVideoLayersAllocation::kSendWithResolution; &#125; &#125; if (video_structure_ != nullptr &amp;&amp; video_header.generic) &#123; active_decode_targets_tracker_.OnFrame( video_structure_-&gt;decode_target_protected_by_chain, video_header.generic-&gt;active_decode_targets, video_header.frame_type == VideoFrameType::kVideoFrameKey, video_header.generic-&gt;frame_id, video_header.generic-&gt;chain_diffs); &#125; const uint8_t temporal_id = GetTemporalId(video_header); // No FEC protection for upper temporal layers, if used. const bool use_fec = fec_type_.has_value() &amp;&amp; (temporal_id == 0 || temporal_id == kNoTemporalIdx); // Maximum size of packet including rtp headers. // Extra space left in case packet will be resent using fec or rtx. int packet_capacity = rtp_sender_-&gt;MaxRtpPacketSize() - (use_fec ? FecPacketOverhead() : 0) - (rtp_sender_-&gt;RtxStatus() ? kRtxHeaderSize : 0); absl::optional&lt;Timestamp&gt; capture_time; if (capture_time_ms &gt; 0) &#123; capture_time = Timestamp::Millis(capture_time_ms); &#125; rtp_sender_-&gt;SetCsrcs(std::move(csrcs)); std::unique_ptr&lt;RtpPacketToSend&gt; single_packet = rtp_sender_-&gt;AllocatePacket(); RTC_DCHECK_LE(packet_capacity, single_packet-&gt;capacity()); single_packet-&gt;SetPayloadType(payload_type); single_packet-&gt;SetTimestamp(rtp_timestamp); if (capture_time) single_packet-&gt;set_capture_time(*capture_time); // Construct the absolute capture time extension if not provided. if (!video_header.absolute_capture_time.has_value() &amp;&amp; capture_time.has_value()) &#123; video_header.absolute_capture_time.emplace(); video_header.absolute_capture_time-&gt;absolute_capture_timestamp = Int64MsToUQ32x32( clock_-&gt;ConvertTimestampToNtpTime(*capture_time).ToMs()); if (include_capture_clock_offset_) &#123; video_header.absolute_capture_time-&gt;estimated_capture_clock_offset = 0; &#125; &#125; // Let `absolute_capture_time_sender_` decide if the extension should be sent. if (video_header.absolute_capture_time.has_value()) &#123; video_header.absolute_capture_time = absolute_capture_time_sender_.OnSendPacket( AbsoluteCaptureTimeSender::GetSource(single_packet-&gt;Ssrc(), single_packet-&gt;Csrcs()), single_packet-&gt;Timestamp(), kVideoPayloadTypeFrequency, video_header.absolute_capture_time-&gt;absolute_capture_timestamp, video_header.absolute_capture_time-&gt;estimated_capture_clock_offset); &#125; auto first_packet = std::make_unique&lt;RtpPacketToSend&gt;(*single_packet); auto middle_packet = std::make_unique&lt;RtpPacketToSend&gt;(*single_packet); auto last_packet = std::make_unique&lt;RtpPacketToSend&gt;(*single_packet); // Simplest way to estimate how much extensions would occupy is to set them. AddRtpHeaderExtensions(video_header, /*first_packet=*/true, /*last_packet=*/true, single_packet.get()); if (video_structure_ != nullptr &amp;&amp; single_packet-&gt;IsRegistered&lt;RtpDependencyDescriptorExtension&gt;() &amp;&amp; !single_packet-&gt;HasExtension&lt;RtpDependencyDescriptorExtension&gt;()) &#123; RTC_DCHECK_EQ(video_header.frame_type, VideoFrameType::kVideoFrameKey); // Disable attaching dependency descriptor to delta packets (including // non-first packet of a key frame) when it wasn't attached to a key frame, // as dependency descriptor can't be usable in such case. RTC_LOG(LS_WARNING) &lt;&lt; "Disable dependency descriptor because failed to " "attach it to a key frame."; video_structure_ = nullptr; &#125; AddRtpHeaderExtensions(video_header, /*first_packet=*/true, /*last_packet=*/false, first_packet.get()); AddRtpHeaderExtensions(video_header, /*first_packet=*/false, /*last_packet=*/false, middle_packet.get()); AddRtpHeaderExtensions(video_header, /*first_packet=*/false, /*last_packet=*/true, last_packet.get()); RTC_DCHECK_GT(packet_capacity, single_packet-&gt;headers_size()); RTC_DCHECK_GT(packet_capacity, first_packet-&gt;headers_size()); RTC_DCHECK_GT(packet_capacity, middle_packet-&gt;headers_size()); RTC_DCHECK_GT(packet_capacity, last_packet-&gt;headers_size()); RtpPacketizer::PayloadSizeLimits limits; limits.max_payload_len = packet_capacity - middle_packet-&gt;headers_size(); RTC_DCHECK_GE(single_packet-&gt;headers_size(), middle_packet-&gt;headers_size()); limits.single_packet_reduction_len = single_packet-&gt;headers_size() - middle_packet-&gt;headers_size(); RTC_DCHECK_GE(first_packet-&gt;headers_size(), middle_packet-&gt;headers_size()); limits.first_packet_reduction_len = first_packet-&gt;headers_size() - middle_packet-&gt;headers_size(); RTC_DCHECK_GE(last_packet-&gt;headers_size(), middle_packet-&gt;headers_size()); limits.last_packet_reduction_len = last_packet-&gt;headers_size() - middle_packet-&gt;headers_size(); bool has_generic_descriptor = first_packet-&gt;HasExtension&lt;RtpGenericFrameDescriptorExtension00&gt;() || first_packet-&gt;HasExtension&lt;RtpDependencyDescriptorExtension&gt;(); // Minimization of the vp8 descriptor may erase temporal_id, so use // `temporal_id` rather than reference `video_header` beyond this point. if (has_generic_descriptor) &#123; MinimizeDescriptor(&amp;video_header); &#125; // TODO(benwright@webrtc.org) - Allocate enough to always encrypt inline. rtc::Buffer encrypted_video_payload; if (frame_encryptor_ != nullptr) &#123; const size_t max_ciphertext_size = frame_encryptor_-&gt;GetMaxCiphertextByteSize(cricket::MEDIA_TYPE_VIDEO, payload.size()); encrypted_video_payload.SetSize(max_ciphertext_size); size_t bytes_written = 0; // Enable header authentication if the field trial isn't disabled. std::vector&lt;uint8_t&gt; additional_data; if (generic_descriptor_auth_experiment_) &#123; additional_data = RtpDescriptorAuthentication(video_header); &#125; if (frame_encryptor_-&gt;Encrypt( cricket::MEDIA_TYPE_VIDEO, first_packet-&gt;Ssrc(), additional_data, payload, encrypted_video_payload, &amp;bytes_written) != 0) &#123; return false; &#125; encrypted_video_payload.SetSize(bytes_written); payload = encrypted_video_payload; &#125; else if (require_frame_encryption_) &#123; RTC_LOG(LS_WARNING) &lt;&lt; "No FrameEncryptor is attached to this video sending stream but " "one is required since require_frame_encryptor is set"; &#125; std::unique_ptr&lt;RtpPacketizer&gt; packetizer = RtpPacketizer::Create(codec_type, payload, limits, video_header); // TODO(bugs.webrtc.org/10714): retransmission_settings_ should generally be // replaced by expected_retransmission_time_ms.has_value(). For now, though, // only VP8 with an injected frame buffer controller actually controls it. const bool allow_retransmission = expected_retransmission_time_ms.has_value() ? AllowRetransmission(temporal_id, retransmission_settings, expected_retransmission_time_ms.value()) : false; const size_t num_packets = packetizer-&gt;NumPackets(); if (num_packets == 0) return false; bool first_frame = first_frame_sent_(); std::vector&lt;std::unique_ptr&lt;RtpPacketToSend&gt;&gt; rtp_packets; for (size_t i = 0; i &lt; num_packets; ++i) &#123; std::unique_ptr&lt;RtpPacketToSend&gt; packet; int expected_payload_capacity; // Choose right packet template: if (num_packets == 1) &#123; packet = std::move(single_packet); expected_payload_capacity = limits.max_payload_len - limits.single_packet_reduction_len; &#125; else if (i == 0) &#123; packet = std::move(first_packet); expected_payload_capacity = limits.max_payload_len - limits.first_packet_reduction_len; &#125; else if (i == num_packets - 1) &#123; packet = std::move(last_packet); expected_payload_capacity = limits.max_payload_len - limits.last_packet_reduction_len; &#125; else &#123; packet = std::make_unique&lt;RtpPacketToSend&gt;(*middle_packet); expected_payload_capacity = limits.max_payload_len; &#125; packet-&gt;set_first_packet_of_frame(i == 0); if (!packetizer-&gt;NextPacket(packet.get())) return false; RTC_DCHECK_LE(packet-&gt;payload_size(), expected_payload_capacity); packet-&gt;set_allow_retransmission(allow_retransmission); packet-&gt;set_is_key_frame(video_header.frame_type == VideoFrameType::kVideoFrameKey); // Put packetization finish timestamp into extension. if (packet-&gt;HasExtension&lt;VideoTimingExtension&gt;()) &#123; packet-&gt;set_packetization_finish_time(clock_-&gt;CurrentTime()); &#125; packet-&gt;set_fec_protect_packet(use_fec); if (red_enabled()) &#123; // TODO(sprang): Consider packetizing directly into packets with the RED // header already in place, to avoid this copy. std::unique_ptr&lt;RtpPacketToSend&gt; red_packet(new RtpPacketToSend(*packet)); BuildRedPayload(*packet, red_packet.get()); red_packet-&gt;SetPayloadType(*red_payload_type_); red_packet-&gt;set_is_red(true); // Append `red_packet` instead of `packet` to output. red_packet-&gt;set_packet_type(RtpPacketMediaType::kVideo); red_packet-&gt;set_allow_retransmission(packet-&gt;allow_retransmission()); rtp_packets.emplace_back(std::move(red_packet)); &#125; else &#123; packet-&gt;set_packet_type(RtpPacketMediaType::kVideo); rtp_packets.emplace_back(std::move(packet)); &#125; if (first_frame) &#123; if (i == 0) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Sent first RTP packet of the first video frame (pre-pacer)"; &#125; if (i == num_packets - 1) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Sent last RTP packet of the first video frame (pre-pacer)"; &#125; &#125; &#125; LogAndSendToNetwork(std::move(rtp_packets), payload.size()); // Update details about the last sent frame. last_rotation_ = video_header.rotation; if (video_header.color_space != last_color_space_) &#123; last_color_space_ = video_header.color_space; transmit_color_space_next_frame_ = !IsBaseLayer(video_header); &#125; else &#123; transmit_color_space_next_frame_ = transmit_color_space_next_frame_ ? !IsBaseLayer(video_header) : false; &#125; if (video_header.frame_type == VideoFrameType::kVideoFrameKey || PacketWillLikelyBeRequestedForRestransmitionIfLost(video_header)) &#123; // This frame will likely be delivered, no need to populate playout // delay extensions until it changes again. playout_delay_pending_ = false; if (send_allocation_ == SendVideoLayersAllocation::kSendWithResolution) &#123; last_full_sent_allocation_ = allocation_; &#125; send_allocation_ = SendVideoLayersAllocation::kDontSend; &#125; TRACE_EVENT_ASYNC_END1("webrtc", "Video", capture_time_ms, "timestamp", rtp_timestamp); return true;&#125;void RTPSenderVideo::LogAndSendToNetwork( std::vector&lt;std::unique_ptr&lt;RtpPacketToSend&gt;&gt; packets, size_t unpacketized_payload_size) &#123; &#123; MutexLock lock(&amp;stats_mutex_); size_t packetized_payload_size = 0; for (const auto&amp; packet : packets) &#123; if (*packet-&gt;packet_type() == RtpPacketMediaType::kVideo) &#123; packetized_payload_size += packet-&gt;payload_size(); &#125; &#125; // AV1 and H264 packetizers may produce less packetized bytes than // unpacketized. if (packetized_payload_size &gt;= unpacketized_payload_size) &#123; packetization_overhead_bitrate_.Update( packetized_payload_size - unpacketized_payload_size, clock_-&gt;TimeInMilliseconds()); &#125; &#125; rtp_sender_-&gt;EnqueuePackets(std::move(packets));&#125; 1234567891011121314151617.../webrtc/src/modules/rtp_rtcp/source/rtp_sender.ccvoid RTPSender::EnqueuePackets( std::vector&lt;std::unique_ptr&lt;RtpPacketToSend&gt;&gt; packets) &#123; RTC_DCHECK(!packets.empty()); Timestamp now = clock_-&gt;CurrentTime(); for (auto&amp; packet : packets) &#123; RTC_DCHECK(packet); RTC_CHECK(packet-&gt;packet_type().has_value()) &lt;&lt; "Packet type must be set before sending."; if (packet-&gt;capture_time() &lt;= Timestamp::Zero()) &#123; packet-&gt;set_capture_time(now); &#125; &#125; paced_sender_-&gt;EnqueuePackets(std::move(packets));&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758.../webrtc/src/modules/rtp_rtcp/source/rtp_rtcp_impl2.ccModuleRtpRtcpImpl2::ModuleRtpRtcpImpl2(const Configuration&amp; configuration) : worker_queue_(TaskQueueBase::Current()), rtcp_sender_(AddRtcpSendEvaluationCallback( RTCPSender::Configuration::FromRtpRtcpConfiguration(configuration), [this](TimeDelta duration) &#123; ScheduleRtcpSendEvaluation(duration); &#125;)), rtcp_receiver_(configuration, this), clock_(configuration.clock), packet_overhead_(28), // IPV4 UDP. nack_last_time_sent_full_ms_(0), nack_last_seq_number_sent_(0), rtt_stats_(configuration.rtt_stats), rtt_ms_(0) &#123; RTC_DCHECK(worker_queue_); rtcp_thread_checker_.Detach(); if (!configuration.receiver_only) &#123; rtp_sender_ = std::make_unique&lt;RtpSenderContext&gt;(configuration); rtp_sender_-&gt;sequencing_checker.Detach(); // Make sure rtcp sender use same timestamp offset as rtp sender. rtcp_sender_.SetTimestampOffset( rtp_sender_-&gt;packet_generator.TimestampOffset()); rtp_sender_-&gt;packet_sender.SetTimestampOffset( rtp_sender_-&gt;packet_generator.TimestampOffset()); &#125; // Set default packet size limit. // TODO(nisse): Kind-of duplicates // webrtc::VideoSendStream::Config::Rtp::kDefaultMaxPacketSize. const size_t kTcpOverIpv4HeaderSize = 40; SetMaxRtpPacketSize(IP_PACKET_SIZE - kTcpOverIpv4HeaderSize); rtt_update_task_ = RepeatingTaskHandle::DelayedStart( worker_queue_, kRttUpdateInterval, [this]() &#123; PeriodicUpdate(); return kRttUpdateInterval; &#125;);&#125;ModuleRtpRtcpImpl2::RtpSenderContext::RtpSenderContext( const RtpRtcpInterface::Configuration&amp; config) : packet_history(config.clock, config.enable_rtx_padding_prioritization), sequencer(config.local_media_ssrc, config.rtx_send_ssrc, /*require_marker_before_media_padding=*/!config.audio, config.clock), packet_sender(config, &amp;packet_history), non_paced_sender(&amp;packet_sender, &amp;sequencer), packet_generator( config, &amp;packet_history, config.paced_sender ? config.paced_sender : &amp;non_paced_sender) &#123;&#125;RTPSender* ModuleRtpRtcpImpl2::RtpSender() &#123; return rtp_sender_ ? &amp;rtp_sender_-&gt;packet_generator : nullptr;&#125; paced_sender_ æ˜¯åœ¨ RtpTransportControllerSendä¸­åˆ›å»ºçš„ pacer_ æ˜¯ TaskQueuePacedSender ç±»åž‹ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101.../src/modules/pacing/task_queue_paced_sender.ccvoid TaskQueuePacedSender::EnqueuePackets( std::vector&lt;std::unique_ptr&lt;RtpPacketToSend&gt;&gt; packets) &#123; task_queue_.TaskQueueForPost()-&gt;PostTask(task_queue_.MaybeSafeTask( safety_.flag(), [this, packets = std::move(packets)]() mutable &#123; RTC_DCHECK_RUN_ON(&amp;task_queue_); TRACE_EVENT0(TRACE_DISABLED_BY_DEFAULT("webrtc"), "TaskQueuePacedSender::EnqueuePackets"); for (auto&amp; packet : packets) &#123; TRACE_EVENT2(TRACE_DISABLED_BY_DEFAULT("webrtc"), "TaskQueuePacedSender::EnqueuePackets::Loop", "sequence_number", packet-&gt;SequenceNumber(), "rtp_timestamp", packet-&gt;Timestamp()); size_t packet_size = packet-&gt;payload_size() + packet-&gt;padding_size(); if (include_overhead_) &#123; packet_size += packet-&gt;headers_size(); &#125; packet_size_.Apply(1, packet_size); RTC_DCHECK_GE(packet-&gt;capture_time(), Timestamp::Zero()); pacing_controller_.EnqueuePacket(std::move(packet)); &#125; MaybeProcessPackets(Timestamp::MinusInfinity()); &#125;));&#125;void TaskQueuePacedSender::MaybeProcessPackets( Timestamp scheduled_process_time) &#123; RTC_DCHECK_RUN_ON(&amp;task_queue_); TRACE_EVENT0(TRACE_DISABLED_BY_DEFAULT("webrtc"), "TaskQueuePacedSender::MaybeProcessPackets"); if (is_shutdown_ || !is_started_) &#123; return; &#125; Timestamp next_send_time = pacing_controller_.NextSendTime(); RTC_DCHECK(next_send_time.IsFinite()); const Timestamp now = clock_-&gt;CurrentTime(); TimeDelta early_execute_margin = pacing_controller_.IsProbing() ? PacingController::kMaxEarlyProbeProcessing : TimeDelta::Zero(); // Process packets and update stats. while (next_send_time &lt;= now + early_execute_margin) &#123; pacing_controller_.ProcessPackets(); next_send_time = pacing_controller_.NextSendTime(); RTC_DCHECK(next_send_time.IsFinite()); // Probing state could change. Get margin after process packets. early_execute_margin = pacing_controller_.IsProbing() ? PacingController::kMaxEarlyProbeProcessing : TimeDelta::Zero(); &#125; UpdateStats(); // Ignore retired scheduled task, otherwise reset `next_process_time_`. if (scheduled_process_time.IsFinite()) &#123; if (scheduled_process_time != next_process_time_) &#123; return; &#125; next_process_time_ = Timestamp::MinusInfinity(); &#125; // Do not hold back in probing. TimeDelta hold_back_window = TimeDelta::Zero(); if (!pacing_controller_.IsProbing()) &#123; hold_back_window = max_hold_back_window_; DataRate pacing_rate = pacing_controller_.pacing_rate(); if (max_hold_back_window_in_packets_ != kNoPacketHoldback &amp;&amp; !pacing_rate.IsZero() &amp;&amp; packet_size_.filtered() != rtc::ExpFilter::kValueUndefined) &#123; TimeDelta avg_packet_send_time = DataSize::Bytes(packet_size_.filtered()) / pacing_rate; hold_back_window = std::min(hold_back_window, avg_packet_send_time * max_hold_back_window_in_packets_); &#125; &#125; // Calculate next process time. TimeDelta time_to_next_process = std::max(hold_back_window, next_send_time - now - early_execute_margin); next_send_time = now + time_to_next_process; // If no in flight task or in flight task is later than `next_send_time`, // schedule a new one. Previous in flight task will be retired. if (next_process_time_.IsMinusInfinity() || next_process_time_ &gt; next_send_time) &#123; // Prefer low precision if allowed and not probing. task_queue_.TaskQueueForDelayedTasks()-&gt;PostDelayedHighPrecisionTask( task_queue_.MaybeSafeTask( safety_.flag(), [this, next_send_time]() &#123; MaybeProcessPackets(next_send_time); &#125;), time_to_next_process.RoundUpTo(TimeDelta::Millis(1))); next_process_time_ = next_send_time; &#125;&#125; PacingController::ProcessPackets -&gt; PacketRouter::SendPacket -&gt; ModuleRtpRtcpImpl2::TrySendPacket -&gt; RtpSenderEgress::SendPacket -&gt; RtpSenderEgress::SendPacketToNetwork -&gt; DegradedCall::FakeNetworkPipeTransportAdapter::SendRtp -&gt; DegradedCall::FakeNetworkPipeOnTaskQueue::SendRtp -&gt; FakeNetworkPipe::DeliverNetworkPacket -&gt; WebRtcVideoChannel::SendRtp -&gt; MediaChannel::SendRtp -&gt; MediaChannel::DoSendPacket -&gt; BaseChannel::SendPacket -&gt; RtpTransport::SendPacket -&gt; rtp_transport_ å°±æ˜¯åœ¨ åˆ†æžcandidateæ–‡ç« ä¸­ åˆ›å»ºçš„é‚£ä¸ª ã€‚ P2PTransportChannel::SendPacket -&gt; ProxyConnection::Send -&gt; UDPPort::SendTo -&gt; Socket -&gt; send åˆ°è¿™é‡Œ å›¾ä¸­çš„ å·¦åŠéƒ¨åˆ† sendçš„è¿‡ç¨‹ ç»“æŸäº† receiveâ€¦RtpTransport::OnReadPacket-&gt;RtpTransport::OnRtpPacketReceived -&gt;â€¦BaseChannel::OnRtpPacket -&gt;MediaChannel::OnPacketReceived -&gt; Call::DeliverRtpPacket -&gt;RtpStreamReceiverController::OnRtpPacket -&gt; RtpVideoStreamReceiver2::OnRtpPacket -&gt; RtpVideoStreamReceiver2::OnCompleteFrames -&gt; VideoReceiveStream2::OnCompleteFrame -&gt; VideoReceiveStream2::OnFrame -&gt; WebRtcVideoReceiveStream::OnFrame -&gt; VideoBroadcaster::OnFrame -&gt; VideoRendererAdapter OnFrame -&gt; RTCEAGLVideoView renderFrame â€¦ receive å°±æ˜¯ send é€†å‘çš„è¿‡ç¨‹,ä¸é‡å¤äº† over â€¦.]]></content>
      <categories>
        <category>RTC</category>
      </categories>
      <tags>
        <tag>ios</tag>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc-candidateæºç åˆ†æž]]></title>
    <url>%2F2023%2F02%2F23%2Fwebrtc-candidate%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[webrtc ä¿¡ä»¤æ¥è‡ªChatGPT WebRTCï¼ˆWeb Real-Time Communicationï¼‰æ˜¯ä¸€ç§å¯ä»¥åœ¨æµè§ˆå™¨ä¹‹é—´å®žçŽ°å®žæ—¶éŸ³è§†é¢‘é€šä¿¡çš„æŠ€æœ¯ã€‚ä¿¡ä»¤æ˜¯ WebRTC ä¸­çš„ä¸€éƒ¨åˆ†ï¼Œç”¨äºŽç®¡ç†ä¼šè¯çš„å»ºç«‹ã€ç»´æŠ¤å’Œç»“æŸã€‚ç®€å•æ¥è¯´ï¼Œä¿¡ä»¤æ˜¯ç”¨äºŽäº¤æ¢å…ƒæ•°æ®ä»¥å»ºç«‹è¿žæŽ¥çš„è¿‡ç¨‹ã€‚ åœ¨ WebRTC ä¸­ï¼Œéœ€è¦è¿›è¡Œä¸€äº›ä¿¡ä»¤äº¤æ¢æ­¥éª¤æ¥å»ºç«‹è¿žæŽ¥ï¼Œä¾‹å¦‚ï¼š äº¤æ¢SDPï¼ˆSession Description Protocolï¼‰ï¼šæ¯ä¸ªç«¯ç‚¹éƒ½éœ€è¦å°†å…¶æœ¬åœ°çš„SDPå‘é€ç»™å¯¹æ–¹ï¼Œå¹¶ä¸”è§£æžå¯¹æ–¹å‘æ¥çš„SDPã€‚äº¤æ¢ICEï¼ˆInteractive Connectivity Establishmentï¼‰å€™é€‰é¡¹ï¼šWebRTC ä¼šåœ¨ä¸¤ä¸ªç«¯ç‚¹ä¹‹é—´å»ºç«‹å¤šä¸ªè¿žæŽ¥ï¼Œå¹¶å°è¯•æ‰¾åˆ°æœ€ä½³çš„è¿žæŽ¥ã€‚ICEå€™é€‰é¡¹æ˜¯ä¸€ç»„ç½‘ç»œåœ°å€å’Œç«¯å£ï¼Œç”¨äºŽåœ¨å¯¹ç­‰æ–¹ä¹‹é—´å»ºç«‹è¿žæŽ¥ã€‚äº¤æ¢ç½‘ç»œä¿¡æ¯ï¼šåŒ…æ‹¬ç½‘ç»œç±»åž‹ã€å¸¦å®½å’Œç½‘ç»œçŠ¶å†µç­‰ä¿¡æ¯ï¼Œä»¥å¸®åŠ©åŒæ–¹é€‰æ‹©æœ€ä½³çš„è¿žæŽ¥ã€‚ä»¥ä¸Šè¿™äº›æ­¥éª¤éœ€è¦é€šè¿‡ä¿¡ä»¤æœåŠ¡å™¨æ¥å®Œæˆã€‚ä¿¡ä»¤æœåŠ¡å™¨è´Ÿè´£åè°ƒè¿žæŽ¥åŒæ–¹ä¹‹é—´çš„é€šä¿¡ï¼Œå¹¶ç¡®ä¿ä¼šè¯èƒ½å¤Ÿé¡ºåˆ©è¿›è¡Œã€‚ WebRTC å¹¶æ²¡æœ‰è§„å®šä¿¡ä»¤åè®®ï¼Œå› æ­¤å¼€å‘äººå‘˜å¯ä»¥è‡ªè¡Œé€‰æ‹©é€‚åˆè‡ªå·±åº”ç”¨çš„åè®®ï¼Œä¾‹å¦‚ SIPï¼ˆSession Initiation Protocolï¼‰ã€XMPPï¼ˆExtensible Messaging and Presence Protocolï¼‰æˆ– WebSocket ç­‰ã€‚ æœ¬æ–‡çœ‹ä¸‹æ˜¯å¦‚ä½•èŽ·å–ICEå€™é€‰é¡¹ ice candidate åœ¨ WebRTC ä¸­ï¼ŒICEï¼ˆInteractive Connectivity Establishmentï¼‰åè®®ç”¨äºŽåœ¨ä¸¤ä¸ªç«¯ç‚¹ä¹‹é—´å»ºç«‹å¤šä¸ªè¿žæŽ¥ï¼Œå¹¶å°è¯•æ‰¾åˆ°æœ€ä½³çš„è¿žæŽ¥ã€‚ICEåè®®ä½¿ç”¨å€™é€‰é¡¹ï¼ˆCandidateï¼‰æ¥è¡¨ç¤ºå¯ä»¥å»ºç«‹è¿žæŽ¥çš„ç½‘ç»œåœ°å€å’Œç«¯å£ç»„åˆã€‚ åœ¨ WebRTC ä¸­ï¼Œå€™é€‰é¡¹ç”± ICE ä»£ç†æœåŠ¡å™¨ç”Ÿæˆï¼Œå¹¶å‘é€ç»™å¯¹ç«¯ã€‚ICE ä»£ç†æœåŠ¡å™¨å¯ä»¥æ˜¯ STUNï¼ˆSession Traversal Utilities for NATï¼‰æœåŠ¡å™¨ã€TURNï¼ˆTraversal Using Relay NATï¼‰æœåŠ¡å™¨æˆ–è€…åŒæ—¶æ”¯æŒ STUN å’Œ TURN åŠŸèƒ½çš„æœåŠ¡å™¨ã€‚ å½“ WebRTC å®¢æˆ·ç«¯å¼€å§‹å»ºç«‹è¿žæŽ¥æ—¶ï¼Œå®ƒä¼šå‘ ICE ä»£ç†æœåŠ¡å™¨å‘é€ä¸€ä¸ªè¯·æ±‚ï¼Œä»¥èŽ·å–å¯ç”¨çš„å€™é€‰é¡¹ã€‚ICE ä»£ç†æœåŠ¡å™¨ä¼šè¿”å›žä¸€ç»„ç½‘ç»œåœ°å€å’Œç«¯å£ç»„åˆï¼Œç”¨äºŽå°è¯•å»ºç«‹è¿žæŽ¥ã€‚ICE å€™é€‰é¡¹å¯èƒ½åŒ…æ‹¬ä»¥ä¸‹å‡ ç§ç±»åž‹ï¼š ä¸»æœºå€™é€‰é¡¹ï¼ˆHost Candidateï¼‰ï¼šæœ¬åœ°è®¡ç®—æœºçš„ç½‘ç»œåœ°å€å’Œç«¯å£ç»„åˆã€‚ æœåŠ¡å™¨åå°„å€™é€‰é¡¹ï¼ˆServer Reflexive Candidateï¼‰ï¼šé€šè¿‡ STUN æœåŠ¡å™¨èŽ·å–çš„å…¬ç½‘ IP åœ°å€å’Œç«¯å£ç»„åˆã€‚ å¯¹ç§°å€™é€‰é¡¹ï¼ˆSymmetric Candidateï¼‰ï¼šä½¿ç”¨å¯¹ç§° NAT è¿›è¡Œ NAT ç©¿é€æ—¶èŽ·å–çš„ç½‘ç»œåœ°å€å’Œç«¯å£ç»„åˆã€‚ ä¸­ç»§å€™é€‰é¡¹ï¼ˆRelay Candidateï¼‰ï¼šä½¿ç”¨ TURN æœåŠ¡å™¨è¿›è¡Œ NAT ç©¿é€æ—¶èŽ·å–çš„ç½‘ç»œåœ°å€å’Œç«¯å£ç»„åˆã€‚ ICE å€™é€‰é¡¹æ˜¯æ ¹æ®ç½‘ç»œçŠ¶å†µåŠ¨æ€ç”Ÿæˆçš„ï¼Œå½“ç½‘ç»œçŽ¯å¢ƒå‘ç”Ÿå˜åŒ–æ—¶ï¼ŒWebRTC å®¢æˆ·ç«¯å¯èƒ½ä¼šé‡æ–°ç”Ÿæˆæ–°çš„å€™é€‰é¡¹å¹¶å‘é€ç»™å¯¹ç«¯ã€‚å› æ­¤ï¼Œåœ¨å»ºç«‹ WebRTC è¿žæŽ¥æ—¶ï¼Œç¡®ä¿æ­£ç¡®èŽ·å–å’Œå¤„ç† ICE å€™é€‰é¡¹éžå¸¸é‡è¦ï¼Œä»¥ç¡®ä¿è¿žæŽ¥çš„ç¨³å®šæ€§å’Œè´¨é‡ã€‚ SdpOfferAnswerHandleråœ¨ crateoffer &amp;&amp; setlocalDescription ä¹‹åŽå°±éœ€è¦èŽ·å– candidateäº†ï¼ŒsetlocalDescription ä»Ž PeerConnection è¿›åˆ° SdpOfferAnswerHandler 123456789101112webrtc/src/pc/sdp_offer_answer.ccvoid SdpOfferAnswerHandler::DoSetLocalDescription(...) &#123; ... // MaybeStartGathering needs to be called after informing the observer so that // we don't signal any candidates before signaling that SetLocalDescription // completed. transport_controller_s()-&gt;MaybeStartGathering();&#125; æ³¨é‡Šä¹Ÿè¯´çš„å¾ˆæ¸…æ¥šäº† transport_controller_s()-&gt;MaybeStartGathering(); èŽ·å– candidates çš„å…¥å£ã€‚ MaybeStartGathering123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127/Users/blackox626/webrtc/src/pc/peer_connection.ccPeerConnection::Initialize -&gt; PeerConnection::InitializeTransportController_nJsepTransportController* PeerConnection::InitializeTransportController_n( const RTCConfiguration&amp; configuration, const PeerConnectionDependencies&amp; dependencies) &#123; JsepTransportController::Config config; config.redetermine_role_on_ice_restart = configuration.redetermine_role_on_ice_restart; config.ssl_max_version = options_.ssl_max_version; config.disable_encryption = options_.disable_encryption; config.bundle_policy = configuration.bundle_policy; config.rtcp_mux_policy = configuration.rtcp_mux_policy; // TODO(bugs.webrtc.org/9891) - Remove options_.crypto_options then remove // this stub. config.crypto_options = configuration.crypto_options.has_value() ? *configuration.crypto_options : options_.crypto_options; config.transport_observer = this; config.rtcp_handler = InitializeRtcpCallback(); config.event_log = event_log_ptr_;#if defined(ENABLE_EXTERNAL_AUTH) config.enable_external_auth = true;#endif config.active_reset_srtp_params = configuration.active_reset_srtp_params; // DTLS has to be enabled to use SCTP. if (dtls_enabled_) &#123; config.sctp_factory = context_-&gt;sctp_transport_factory(); &#125; config.ice_transport_factory = ice_transport_factory_.get(); config.on_dtls_handshake_error_ = [weak_ptr = weak_factory_.GetWeakPtr()](rtc::SSLHandshakeError s) &#123; if (weak_ptr) &#123; weak_ptr-&gt;OnTransportControllerDtlsHandshakeError(s); &#125; &#125;; config.field_trials = trials_.get(); transport_controller_.reset( new JsepTransportController(network_thread(), port_allocator_.get(), async_dns_resolver_factory_.get(), config)); transport_controller_-&gt;SubscribeIceConnectionState( [this](cricket::IceConnectionState s) &#123; RTC_DCHECK_RUN_ON(network_thread()); if (s == cricket::kIceConnectionConnected) &#123; ReportTransportStats(); &#125; signaling_thread()-&gt;PostTask( SafeTask(signaling_thread_safety_.flag(), [this, s]() &#123; RTC_DCHECK_RUN_ON(signaling_thread()); OnTransportControllerConnectionState(s); &#125;)); &#125;); transport_controller_-&gt;SubscribeConnectionState( [this](PeerConnectionInterface::PeerConnectionState s) &#123; RTC_DCHECK_RUN_ON(network_thread()); signaling_thread()-&gt;PostTask( SafeTask(signaling_thread_safety_.flag(), [this, s]() &#123; RTC_DCHECK_RUN_ON(signaling_thread()); SetConnectionState(s); &#125;)); &#125;); transport_controller_-&gt;SubscribeStandardizedIceConnectionState( [this](PeerConnectionInterface::IceConnectionState s) &#123; RTC_DCHECK_RUN_ON(network_thread()); signaling_thread()-&gt;PostTask( SafeTask(signaling_thread_safety_.flag(), [this, s]() &#123; RTC_DCHECK_RUN_ON(signaling_thread()); SetStandardizedIceConnectionState(s); &#125;)); &#125;); transport_controller_-&gt;SubscribeIceGatheringState( [this](cricket::IceGatheringState s) &#123; RTC_DCHECK_RUN_ON(network_thread()); signaling_thread()-&gt;PostTask( SafeTask(signaling_thread_safety_.flag(), [this, s]() &#123; RTC_DCHECK_RUN_ON(signaling_thread()); OnTransportControllerGatheringState(s); &#125;)); &#125;); transport_controller_-&gt;SubscribeIceCandidateGathered( [this](const std::string&amp; transport, const std::vector&lt;cricket::Candidate&gt;&amp; candidates) &#123; RTC_DCHECK_RUN_ON(network_thread()); signaling_thread()-&gt;PostTask( SafeTask(signaling_thread_safety_.flag(), [this, t = transport, c = candidates]() &#123; RTC_DCHECK_RUN_ON(signaling_thread()); OnTransportControllerCandidatesGathered(t, c); &#125;)); &#125;); transport_controller_-&gt;SubscribeIceCandidateError( [this](const cricket::IceCandidateErrorEvent&amp; event) &#123; RTC_DCHECK_RUN_ON(network_thread()); signaling_thread()-&gt;PostTask( SafeTask(signaling_thread_safety_.flag(), [this, event = event]() &#123; RTC_DCHECK_RUN_ON(signaling_thread()); OnTransportControllerCandidateError(event); &#125;)); &#125;); transport_controller_-&gt;SubscribeIceCandidatesRemoved( [this](const std::vector&lt;cricket::Candidate&gt;&amp; c) &#123; RTC_DCHECK_RUN_ON(network_thread()); signaling_thread()-&gt;PostTask( SafeTask(signaling_thread_safety_.flag(), [this, c = c]() &#123; RTC_DCHECK_RUN_ON(signaling_thread()); OnTransportControllerCandidatesRemoved(c); &#125;)); &#125;); transport_controller_-&gt;SubscribeIceCandidatePairChanged( [this](const cricket::CandidatePairChangeEvent&amp; event) &#123; RTC_DCHECK_RUN_ON(network_thread()); signaling_thread()-&gt;PostTask( SafeTask(signaling_thread_safety_.flag(), [this, event = event]() &#123; RTC_DCHECK_RUN_ON(signaling_thread()); OnTransportControllerCandidateChanged(event); &#125;)); &#125;); transport_controller_-&gt;SetIceConfig(ParseIceConfig(configuration)); return transport_controller_.get();&#125; æ³¨å†Œäº† candidate èŽ·å–çš„å›žè°ƒï¼š transport_controller_-&gt;SubscribeIceCandidateGathered å…ˆçœ‹ä¸‹æ”¶é›†ä¹‹åŽçš„è¡Œä¸º 1234567891011121314151617181920212223242526272829303132void PeerConnection::OnTransportControllerCandidatesGathered( const std::string&amp; transport_name, const cricket::Candidates&amp; candidates) &#123; // TODO(bugs.webrtc.org/12427): Expect this to come in on the network thread // (not signaling as it currently does), handle appropriately. int sdp_mline_index; if (!GetLocalCandidateMediaIndex(transport_name, &amp;sdp_mline_index)) &#123; RTC_LOG(LS_ERROR) &lt;&lt; "OnTransportControllerCandidatesGathered: content name " &lt;&lt; transport_name &lt;&lt; " not found"; return; &#125; for (cricket::Candidates::const_iterator citer = candidates.begin(); citer != candidates.end(); ++citer) &#123; // Use transport_name as the candidate media id. std::unique_ptr&lt;JsepIceCandidate&gt; candidate( new JsepIceCandidate(transport_name, sdp_mline_index, *citer)); sdp_handler_-&gt;AddLocalIceCandidate(candidate.get()); OnIceCandidate(std::move(candidate)); &#125;&#125;void PeerConnection::OnIceCandidate( std::unique_ptr&lt;IceCandidateInterface&gt; candidate) &#123; if (IsClosed()) &#123; return; &#125; ReportIceCandidateCollected(candidate-&gt;candidate()); ClearStatsCache(); Observer()-&gt;OnIceCandidate(candidate.get());&#125; é¦–å…ˆ sdp_handler_-&gt;AddLocalIceCandidate(candidate.get()); è®¾ç½®æœ¬åœ°ice candidateç„¶åŽ é€šè¿‡ OnIceCandidate äº‹ä»¶å›žè°ƒ ä¼ é€’åˆ°ä¸Šå±‚app ï¼Œappé€šè¿‡ signal message å‘é€åˆ°webrtc serverï¼Œwebrtc server è½¬å‘ç»™å¯¹ç«¯ app åŒæ ·ä¹Ÿä¼šæ”¶åˆ° webrtc serverè½¬å‘è¿‡æ¥çš„å¯¹ç«¯çš„ ice candidate 12345678910void PeerConnection::AddIceCandidate( std::unique_ptr&lt;IceCandidateInterface&gt; candidate, std::function&lt;void(RTCError)&gt; callback) &#123; RTC_DCHECK_RUN_ON(signaling_thread()); sdp_handler_-&gt;AddIceCandidate(std::move(candidate), [this, callback](webrtc::RTCError result) &#123; ClearStatsCache(); callback(result); &#125;);&#125; é€šè¿‡ sdp_handler_-&gt;AddIceCandidate è®¾ç½®å¯¹ç«¯çš„ice candidateï¼› JsepTransportController JavaScript Session Establishment Protocol (JSEP) JavaScript ä¼šè¯å»ºç«‹åè®® 123456789101112/webrtc/src/pc/jsep_transport_controller.ccvoid JsepTransportController::MaybeStartGathering() &#123; if (!network_thread_-&gt;IsCurrent()) &#123; network_thread_-&gt;BlockingCall([&amp;] &#123; MaybeStartGathering(); &#125;); return; &#125; for (auto&amp; dtls : GetDtlsTransports()) &#123; dtls-&gt;ice_transport()-&gt;MaybeStartGathering(); &#125;&#125; å…ˆçœ‹ä¸‹ DtlsTransports çš„ç”Ÿäº§è¿‡ç¨‹ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273SdpOfferAnswerHandler::DoSetLocalDescription -&gt;SdpOfferAnswerHandler::ApplyLocalDescription -&gt;SdpOfferAnswerHandler::PushdownTransportDescription -&gt; JsepTransportController::SetLocalDescription -&gt;JsepTransportController::ApplyDescription_n -&gt; RTCError JsepTransportController::ApplyDescription_n( bool local, SdpType type, const cricket::SessionDescription* description) &#123; TRACE_EVENT0("webrtc", "JsepTransportController::ApplyDescription_n"); RTC_DCHECK(description); if (local) &#123; local_desc_ = description; &#125; else &#123; remote_desc_ = description; &#125; RTCError error; error = ValidateAndMaybeUpdateBundleGroups(local, type, description); if (!error.ok()) &#123; return error; &#125; std::map&lt;const cricket::ContentGroup*, std::vector&lt;int&gt;&gt; merged_encrypted_extension_ids_by_bundle; if (!bundles_.bundle_groups().empty()) &#123; merged_encrypted_extension_ids_by_bundle = MergeEncryptedHeaderExtensionIdsForBundles(description); &#125; for (const cricket::ContentInfo&amp; content_info : description-&gt;contents()) &#123; // Don't create transports for rejected m-lines and bundled m-lines. if (content_info.rejected || !bundles_.IsFirstMidInGroup(content_info.name)) &#123; continue; &#125; error = MaybeCreateJsepTransport(local, content_info, *description); if (!error.ok()) &#123; return error; &#125; &#125; RTC_DCHECK(description-&gt;contents().size() == description-&gt;transport_infos().size()); for (size_t i = 0; i &lt; description-&gt;contents().size(); ++i) &#123; const cricket::ContentInfo&amp; content_info = description-&gt;contents()[i]; const cricket::TransportInfo&amp; transport_info = description-&gt;transport_infos()[i]; if (content_info.rejected) &#123; // This may cause groups to be removed from |bundles_.bundle_groups()|. HandleRejectedContent(content_info); continue; &#125; const cricket::ContentGroup* established_bundle_group = bundles_.LookupGroupByMid(content_info.name); // For bundle members that are not BUNDLE-tagged (not first in the group), // configure their transport to be the same as the BUNDLE-tagged transport. if (established_bundle_group &amp;&amp; content_info.name != *established_bundle_group-&gt;FirstContentName()) &#123; if (!HandleBundledContent(content_info, *established_bundle_group)) &#123; return RTCError(RTCErrorType::INVALID_PARAMETER, "Failed to process the bundled m= section with " "mid='" + content_info.name + "'."); &#125; continue; &#125; error = ValidateContent(content_info); if (!error.ok()) &#123; return error; &#125; std::vector&lt;int&gt; extension_ids; // Is BUNDLE-tagged (first in the group)? if (established_bundle_group &amp;&amp; content_info.name == *established_bundle_group-&gt;FirstContentName()) &#123; auto it = merged_encrypted_extension_ids_by_bundle.find( established_bundle_group); RTC_DCHECK(it != merged_encrypted_extension_ids_by_bundle.end()); extension_ids = it-&gt;second; &#125; else &#123; extension_ids = GetEncryptedHeaderExtensionIds(content_info); &#125; int rtp_abs_sendtime_extn_id = GetRtpAbsSendTimeHeaderExtensionId(content_info); cricket::JsepTransport* transport = GetJsepTransportForMid(content_info.name); RTC_DCHECK(transport); SetIceRole_n(DetermineIceRole(transport, transport_info, type, local)); cricket::JsepTransportDescription jsep_description = CreateJsepTransportDescription(content_info, transport_info, extension_ids, rtp_abs_sendtime_extn_id); if (local) &#123; error = transport-&gt;SetLocalJsepTransportDescription(jsep_description, type); &#125; else &#123; error = transport-&gt;SetRemoteJsepTransportDescription(jsep_description, type); &#125; if (!error.ok()) &#123; LOG_AND_RETURN_ERROR( RTCErrorType::INVALID_PARAMETER, "Failed to apply the description for m= section with mid='" + content_info.name + "': " + error.message()); &#125; &#125; if (type == SdpType::kAnswer) &#123; transports_.CommitTransports(); bundles_.Commit(); &#125; return RTCError::OK();&#125;RTCError JsepTransportController::MaybeCreateJsepTransport( bool local, const cricket::ContentInfo&amp; content_info, const cricket::SessionDescription&amp; description) &#123; cricket::JsepTransport* transport = GetJsepTransportByName(content_info.name); if (transport) &#123; return RTCError::OK(); &#125; const cricket::MediaContentDescription* content_desc = content_info.media_description(); if (certificate_ &amp;&amp; !content_desc-&gt;cryptos().empty()) &#123; return RTCError(RTCErrorType::INVALID_PARAMETER, "SDES and DTLS-SRTP cannot be enabled at the same time."); &#125; rtc::scoped_refptr&lt;webrtc::IceTransportInterface&gt; ice = CreateIceTransport(content_info.name, /*rtcp=*/false); std::unique_ptr&lt;cricket::DtlsTransportInternal&gt; rtp_dtls_transport = CreateDtlsTransport(content_info, ice-&gt;internal()); std::unique_ptr&lt;cricket::DtlsTransportInternal&gt; rtcp_dtls_transport; std::unique_ptr&lt;RtpTransport&gt; unencrypted_rtp_transport; std::unique_ptr&lt;SrtpTransport&gt; sdes_transport; std::unique_ptr&lt;DtlsSrtpTransport&gt; dtls_srtp_transport; rtc::scoped_refptr&lt;webrtc::IceTransportInterface&gt; rtcp_ice; if (config_.rtcp_mux_policy != PeerConnectionInterface::kRtcpMuxPolicyRequire &amp;&amp; content_info.type == cricket::MediaProtocolType::kRtp) &#123; rtcp_ice = CreateIceTransport(content_info.name, /*rtcp=*/true); rtcp_dtls_transport = CreateDtlsTransport(content_info, rtcp_ice-&gt;internal()); &#125; if (config_.disable_encryption) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Creating UnencryptedRtpTransport, becayse encryption is disabled."; unencrypted_rtp_transport = CreateUnencryptedRtpTransport( content_info.name, rtp_dtls_transport.get(), rtcp_dtls_transport.get()); &#125; else if (!content_desc-&gt;cryptos().empty()) &#123; sdes_transport = CreateSdesTransport( content_info.name, rtp_dtls_transport.get(), rtcp_dtls_transport.get()); RTC_LOG(LS_INFO) &lt;&lt; "Creating SdesTransport."; &#125; else &#123; RTC_LOG(LS_INFO) &lt;&lt; "Creating DtlsSrtpTransport."; dtls_srtp_transport = CreateDtlsSrtpTransport( content_info.name, rtp_dtls_transport.get(), rtcp_dtls_transport.get()); &#125; std::unique_ptr&lt;cricket::SctpTransportInternal&gt; sctp_transport; if (config_.sctp_factory) &#123; sctp_transport = config_.sctp_factory-&gt;CreateSctpTransport(rtp_dtls_transport.get()); &#125; std::unique_ptr&lt;cricket::JsepTransport&gt; jsep_transport = std::make_unique&lt;cricket::JsepTransport&gt;( content_info.name, certificate_, std::move(ice), std::move(rtcp_ice), std::move(unencrypted_rtp_transport), std::move(sdes_transport), std::move(dtls_srtp_transport), std::move(rtp_dtls_transport), std::move(rtcp_dtls_transport), std::move(sctp_transport), [&amp;]() &#123; RTC_DCHECK_RUN_ON(network_thread_); UpdateAggregateStates_n(); &#125;); jsep_transport-&gt;rtp_transport()-&gt;SignalRtcpPacketReceived.connect( this, &amp;JsepTransportController::OnRtcpPacketReceived_n); transports_.RegisterTransport(content_info.name, std::move(jsep_transport)); UpdateAggregateStates_n(); return RTCError::OK();&#125;rtc::scoped_refptr&lt;webrtc::IceTransportInterface&gt;JsepTransportController::CreateIceTransport(const std::string&amp; transport_name, bool rtcp) &#123; int component = rtcp ? cricket::ICE_CANDIDATE_COMPONENT_RTCP : cricket::ICE_CANDIDATE_COMPONENT_RTP; IceTransportInit init; init.set_port_allocator(port_allocator_); init.set_async_dns_resolver_factory(async_dns_resolver_factory_); init.set_event_log(config_.event_log); init.set_field_trials(config_.field_trials); auto transport = config_.ice_transport_factory-&gt;CreateIceTransport( transport_name, component, std::move(init)); RTC_DCHECK(transport); transport-&gt;internal()-&gt;SetIceRole(ice_role_); transport-&gt;internal()-&gt;SetIceTiebreaker(ice_tiebreaker_); transport-&gt;internal()-&gt;SetIceConfig(ice_config_); return transport;&#125;std::unique_ptr&lt;cricket::DtlsTransportInternal&gt;JsepTransportController::CreateDtlsTransport( const cricket::ContentInfo&amp; content_info, cricket::IceTransportInternal* ice) &#123; RTC_DCHECK_RUN_ON(network_thread_); std::unique_ptr&lt;cricket::DtlsTransportInternal&gt; dtls; if (config_.dtls_transport_factory) &#123; dtls = config_.dtls_transport_factory-&gt;CreateDtlsTransport( ice, config_.crypto_options, config_.ssl_max_version); &#125; else &#123; dtls = std::make_unique&lt;cricket::DtlsTransport&gt;(ice, config_.crypto_options, config_.event_log, config_.ssl_max_version); &#125; RTC_DCHECK(dtls); RTC_DCHECK_EQ(ice, dtls-&gt;ice_transport()); if (certificate_) &#123; bool set_cert_success = dtls-&gt;SetLocalCertificate(certificate_); RTC_DCHECK(set_cert_success); &#125; // Connect to signals offered by the DTLS and ICE transport. dtls-&gt;SignalWritableState.connect( this, &amp;JsepTransportController::OnTransportWritableState_n); dtls-&gt;SignalReceivingState.connect( this, &amp;JsepTransportController::OnTransportReceivingState_n); dtls-&gt;ice_transport()-&gt;SignalGatheringState.connect( this, &amp;JsepTransportController::OnTransportGatheringState_n); dtls-&gt;ice_transport()-&gt;SignalCandidateGathered.connect( this, &amp;JsepTransportController::OnTransportCandidateGathered_n); dtls-&gt;ice_transport()-&gt;SignalCandidateError.connect( this, &amp;JsepTransportController::OnTransportCandidateError_n); dtls-&gt;ice_transport()-&gt;SignalCandidatesRemoved.connect( this, &amp;JsepTransportController::OnTransportCandidatesRemoved_n); dtls-&gt;ice_transport()-&gt;SignalRoleConflict.connect( this, &amp;JsepTransportController::OnTransportRoleConflict_n); dtls-&gt;ice_transport()-&gt;SignalStateChanged.connect( this, &amp;JsepTransportController::OnTransportStateChanged_n); dtls-&gt;ice_transport()-&gt;SignalIceTransportStateChanged.connect( this, &amp;JsepTransportController::OnTransportStateChanged_n); dtls-&gt;ice_transport()-&gt;SignalCandidatePairChanged.connect( this, &amp;JsepTransportController::OnTransportCandidatePairChanged_n); dtls-&gt;SubscribeDtlsHandshakeError( [this](rtc::SSLHandshakeError error) &#123; OnDtlsHandshakeError(error); &#125;); return dtls;&#125; 12345678910111213.../webrtc/src/p2p/base/default_ice_transport_factory.ccrtc::scoped_refptr&lt;IceTransportInterface&gt;DefaultIceTransportFactory::CreateIceTransport( const std::string&amp; transport_name, int component, IceTransportInit init) &#123; BasicIceControllerFactory factory; init.set_ice_controller_factory(&amp;factory); return rtc::make_ref_counted&lt;DefaultIceTransport&gt;( cricket::P2PTransportChannel::Create(transport_name, component, std::move(init)));&#125; åœ¨æ¥çœ‹ dtls-&gt;ice_transport()-&gt;MaybeStartGathering() dtls-&gt;ice_transport() å°±æ˜¯ P2PTransportChannel 123456789101112131415161718192021dtls-&gt;ice_transport()-&gt;SignalCandidateGathered.connect( this, &amp;JsepTransportController::OnTransportCandidateGathered_n);void JsepTransportController::OnTransportCandidateGathered_n( cricket::IceTransportInternal* transport, const cricket::Candidate&amp; candidate) &#123; // We should never signal peer-reflexive candidates. if (candidate.type() == cricket::PRFLX_PORT_TYPE) &#123; RTC_DCHECK_NOTREACHED(); return; &#125; signal_ice_candidates_gathered_.Send( transport-&gt;transport_name(), std::vector&lt;cricket::Candidate&gt;&#123;candidate&#125;);&#125;void SubscribeIceCandidateGathered(F&amp;&amp; callback) &#123; RTC_DCHECK_RUN_ON(network_thread_); signal_ice_candidates_gathered_.AddReceiver(std::forward&lt;F&gt;(callback)); &#125; è¿™é‡Œå°±è·Ÿä¹‹å‰çš„peer_connection ä¸­ SubscribeIceCandidateGathered æ³¨å†Œå›žè°ƒ å¯¹åº”ä¸Šäº† P2PTransportChannel1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980.../webrtc/src/p2p/base/p2p_transport_channel.ccvoid P2PTransportChannel::MaybeStartGathering() &#123; RTC_DCHECK_RUN_ON(network_thread_); // TODO(bugs.webrtc.org/14605): ensure tie_breaker_ is set. if (ice_parameters_.ufrag.empty() || ice_parameters_.pwd.empty()) &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Cannot gather candidates because ICE parameters are empty" " ufrag: " &lt;&lt; ice_parameters_.ufrag &lt;&lt; " pwd: " &lt;&lt; ice_parameters_.pwd; return; &#125; // Start gathering if we never started before, or if an ICE restart occurred. if (allocator_sessions_.empty() || IceCredentialsChanged(allocator_sessions_.back()-&gt;ice_ufrag(), allocator_sessions_.back()-&gt;ice_pwd(), ice_parameters_.ufrag, ice_parameters_.pwd)) &#123; if (gathering_state_ != kIceGatheringGathering) &#123; gathering_state_ = kIceGatheringGathering; SignalGatheringState(this); &#125; if (!allocator_sessions_.empty()) &#123; IceRestartState state; if (writable()) &#123; state = IceRestartState::CONNECTED; &#125; else if (IsGettingPorts()) &#123; state = IceRestartState::CONNECTING; &#125; else &#123; state = IceRestartState::DISCONNECTED; &#125; RTC_HISTOGRAM_ENUMERATION("WebRTC.PeerConnection.IceRestartState", static_cast&lt;int&gt;(state), static_cast&lt;int&gt;(IceRestartState::MAX_VALUE)); &#125; for (const auto&amp; session : allocator_sessions_) &#123; if (session-&gt;IsStopped()) &#123; continue; &#125; session-&gt;StopGettingPorts(); &#125; // Time for a new allocator. std::unique_ptr&lt;PortAllocatorSession&gt; pooled_session = allocator_-&gt;TakePooledSession(transport_name(), component(), ice_parameters_.ufrag, ice_parameters_.pwd); if (pooled_session) &#123; pooled_session-&gt;set_ice_tiebreaker(tiebreaker_); AddAllocatorSession(std::move(pooled_session)); PortAllocatorSession* raw_pooled_session = allocator_sessions_.back().get(); // Process the pooled session's existing candidates/ports, if they exist. OnCandidatesReady(raw_pooled_session, raw_pooled_session-&gt;ReadyCandidates()); for (PortInterface* port : allocator_sessions_.back()-&gt;ReadyPorts()) &#123; OnPortReady(raw_pooled_session, port); &#125; if (allocator_sessions_.back()-&gt;CandidatesAllocationDone()) &#123; OnCandidatesAllocationDone(raw_pooled_session); &#125; &#125; else &#123; AddAllocatorSession(allocator_-&gt;CreateSession( transport_name(), component(), ice_parameters_.ufrag, ice_parameters_.pwd)); allocator_sessions_.back()-&gt;set_ice_tiebreaker(tiebreaker_); allocator_sessions_.back()-&gt;StartGettingPorts(); &#125; &#125;&#125;void P2PTransportChannel::OnCandidatesReady( PortAllocatorSession* session, const std::vector&lt;Candidate&gt;&amp; candidates) &#123; RTC_DCHECK_RUN_ON(network_thread_); for (size_t i = 0; i &lt; candidates.size(); ++i) &#123; SignalCandidateGathered(this, candidates[i]); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491.../webrtc/src/p2p/client/basic_port_allocator.cc// BasicPortAllocatorSessionBasicPortAllocatorSession::BasicPortAllocatorSession( BasicPortAllocator* allocator, absl::string_view content_name, int component, absl::string_view ice_ufrag, absl::string_view ice_pwd) : PortAllocatorSession(content_name, component, ice_ufrag, ice_pwd, allocator-&gt;flags()), allocator_(allocator), network_thread_(rtc::Thread::Current()), socket_factory_(allocator-&gt;socket_factory()), allocation_started_(false), network_manager_started_(false), allocation_sequences_created_(false), turn_port_prune_policy_(allocator-&gt;turn_port_prune_policy()) &#123; TRACE_EVENT0("webrtc", "BasicPortAllocatorSession::BasicPortAllocatorSession"); allocator_-&gt;network_manager()-&gt;SignalNetworksChanged.connect( this, &amp;BasicPortAllocatorSession::OnNetworksChanged); /// æ”¶é›†networks BasicNetworkManager allocator_-&gt;network_manager()-&gt;StartUpdating();&#125;void BasicPortAllocatorSession::StartGettingPorts() &#123; RTC_DCHECK_RUN_ON(network_thread_); state_ = SessionState::GATHERING; network_thread_-&gt;PostTask( SafeTask(network_safety_.flag(), [this] &#123; GetPortConfigurations(); &#125;)); RTC_LOG(LS_INFO) &lt;&lt; "Start getting ports with turn_port_prune_policy " &lt;&lt; turn_port_prune_policy_;&#125;void BasicPortAllocatorSession::GetPortConfigurations() &#123; RTC_DCHECK_RUN_ON(network_thread_); auto config = std::make_unique&lt;PortConfiguration&gt;( allocator_-&gt;stun_servers(), username(), password(), allocator()-&gt;field_trials()); for (const RelayServerConfig&amp; turn_server : allocator_-&gt;turn_servers()) &#123; config-&gt;AddRelay(turn_server); &#125; ConfigReady(std::move(config));&#125;void BasicPortAllocatorSession::ConfigReady(PortConfiguration* config) &#123; RTC_DCHECK_RUN_ON(network_thread_); ConfigReady(absl::WrapUnique(config));&#125;void BasicPortAllocatorSession::ConfigReady( std::unique_ptr&lt;PortConfiguration&gt; config) &#123; RTC_DCHECK_RUN_ON(network_thread_); network_thread_-&gt;PostTask(SafeTask( network_safety_.flag(), [this, config = std::move(config)]() mutable &#123; OnConfigReady(std::move(config)); &#125;));&#125;// Adds a configuration to the list.void BasicPortAllocatorSession::OnConfigReady( std::unique_ptr&lt;PortConfiguration&gt; config) &#123; RTC_DCHECK_RUN_ON(network_thread_); if (config) configs_.push_back(std::move(config)); AllocatePorts();&#125;void BasicPortAllocatorSession::AllocatePorts() &#123; RTC_DCHECK_RUN_ON(network_thread_); network_thread_-&gt;PostTask(SafeTask( network_safety_.flag(), [this, allocation_epoch = allocation_epoch_] &#123; OnAllocate(allocation_epoch); &#125;));&#125;void BasicPortAllocatorSession::OnAllocate(int allocation_epoch) &#123; RTC_DCHECK_RUN_ON(network_thread_); if (allocation_epoch != allocation_epoch_) return; if (network_manager_started_ &amp;&amp; !IsStopped()) &#123; bool disable_equivalent_phases = true; DoAllocate(disable_equivalent_phases); &#125; allocation_started_ = true;&#125;void BasicPortAllocatorSession::DoAllocate(bool disable_equivalent) &#123; RTC_DCHECK_RUN_ON(network_thread_); bool done_signal_needed = false; std::vector&lt;const rtc::Network*&gt; networks = GetNetworks(); if (networks.empty()) &#123; RTC_LOG(LS_WARNING) &lt;&lt; "Machine has no networks; no ports will be allocated"; done_signal_needed = true; &#125; else &#123; RTC_LOG(LS_INFO) &lt;&lt; "Allocate ports on " &lt;&lt; NetworksToString(networks); PortConfiguration* config = configs_.empty() ? nullptr : configs_.back().get(); for (uint32_t i = 0; i &lt; networks.size(); ++i) &#123; uint32_t sequence_flags = flags(); if ((sequence_flags &amp; DISABLE_ALL_PHASES) == DISABLE_ALL_PHASES) &#123; // If all the ports are disabled we should just fire the allocation // done event and return. done_signal_needed = true; break; &#125; if (!config || config-&gt;relays.empty()) &#123; // No relay ports specified in this config. sequence_flags |= PORTALLOCATOR_DISABLE_RELAY; &#125; if (!(sequence_flags &amp; PORTALLOCATOR_ENABLE_IPV6) &amp;&amp; networks[i]-&gt;GetBestIP().family() == AF_INET6) &#123; // Skip IPv6 networks unless the flag's been set. continue; &#125; if (!(sequence_flags &amp; PORTALLOCATOR_ENABLE_IPV6_ON_WIFI) &amp;&amp; networks[i]-&gt;GetBestIP().family() == AF_INET6 &amp;&amp; networks[i]-&gt;type() == rtc::ADAPTER_TYPE_WIFI) &#123; // Skip IPv6 Wi-Fi networks unless the flag's been set. continue; &#125; if (disable_equivalent) &#123; // Disable phases that would only create ports equivalent to // ones that we have already made. DisableEquivalentPhases(networks[i], config, &amp;sequence_flags); if ((sequence_flags &amp; DISABLE_ALL_PHASES) == DISABLE_ALL_PHASES) &#123; // New AllocationSequence would have nothing to do, so don't make it. continue; &#125; &#125; AllocationSequence* sequence = new AllocationSequence(this, networks[i], config, sequence_flags, [this, safety_flag = network_safety_.flag()] &#123; if (safety_flag-&gt;alive()) OnPortAllocationComplete(); &#125;); sequence-&gt;Init(); sequence-&gt;Start(); sequences_.push_back(sequence); done_signal_needed = true; &#125; &#125; if (done_signal_needed) &#123; network_thread_-&gt;PostTask(SafeTask(network_safety_.flag(), [this] &#123; OnAllocationSequenceObjectsCreated(); &#125;)); &#125;&#125;std::vector&lt;const rtc::Network*&gt; BasicPortAllocatorSession::GetNetworks() &#123; RTC_DCHECK_RUN_ON(network_thread_); std::vector&lt;const rtc::Network*&gt; networks; rtc::NetworkManager* network_manager = allocator_-&gt;network_manager(); RTC_DCHECK(network_manager != nullptr); // If the network permission state is BLOCKED, we just act as if the flag has // been passed in. if (network_manager-&gt;enumeration_permission() == rtc::NetworkManager::ENUMERATION_BLOCKED) &#123; set_flags(flags() | PORTALLOCATOR_DISABLE_ADAPTER_ENUMERATION); &#125; // If the adapter enumeration is disabled, we'll just bind to any address // instead of specific NIC. This is to ensure the same routing for http // traffic by OS is also used here to avoid any local or public IP leakage // during stun process. if (flags() &amp; PORTALLOCATOR_DISABLE_ADAPTER_ENUMERATION) &#123; networks = network_manager-&gt;GetAnyAddressNetworks(); &#125; else &#123; networks = network_manager-&gt;GetNetworks(); // If network enumeration fails, use the ANY address as a fallback, so we // can at least try gathering candidates using the default route chosen by // the OS. Or, if the PORTALLOCATOR_ENABLE_ANY_ADDRESS_PORTS flag is // set, we'll use ANY address candidates either way. if (networks.empty() || (flags() &amp; PORTALLOCATOR_ENABLE_ANY_ADDRESS_PORTS)) &#123; std::vector&lt;const rtc::Network*&gt; any_address_networks = network_manager-&gt;GetAnyAddressNetworks(); networks.insert(networks.end(), any_address_networks.begin(), any_address_networks.end()); &#125; &#125; // Filter out link-local networks if needed. if (flags() &amp; PORTALLOCATOR_DISABLE_LINK_LOCAL_NETWORKS) &#123; NetworkFilter link_local_filter( [](const rtc::Network* network) &#123; return IPIsLinkLocal(network-&gt;prefix()); &#125;, "link-local"); FilterNetworks(&amp;networks, link_local_filter); &#125; // Do some more filtering, depending on the network ignore mask and "disable // costly networks" flag. NetworkFilter ignored_filter( [this](const rtc::Network* network) &#123; return allocator_-&gt;GetNetworkIgnoreMask() &amp; network-&gt;type(); &#125;, "ignored"); FilterNetworks(&amp;networks, ignored_filter); if (flags() &amp; PORTALLOCATOR_DISABLE_COSTLY_NETWORKS) &#123; uint16_t lowest_cost = rtc::kNetworkCostMax; for (const rtc::Network* network : networks) &#123; // Don't determine the lowest cost from a link-local network. // On iOS, a device connected to the computer will get a link-local // network for communicating with the computer, however this network can't // be used to connect to a peer outside the network. if (rtc::IPIsLinkLocal(network-&gt;GetBestIP())) &#123; continue; &#125; lowest_cost = std::min&lt;uint16_t&gt;( lowest_cost, network-&gt;GetCost(*allocator()-&gt;field_trials())); &#125; NetworkFilter costly_filter( [lowest_cost, this](const rtc::Network* network) &#123; return network-&gt;GetCost(*allocator()-&gt;field_trials()) &gt; lowest_cost + rtc::kNetworkCostLow; &#125;, "costly"); FilterNetworks(&amp;networks, costly_filter); &#125; // Lastly, if we have a limit for the number of IPv6 network interfaces (by // default, it's 5), remove networks to ensure that limit is satisfied. // // TODO(deadbeef): Instead of just taking the first N arbitrary IPv6 // networks, we could try to choose a set that's "most likely to work". It's // hard to define what that means though; it's not just "lowest cost". // Alternatively, we could just focus on making our ICE pinging logic smarter // such that this filtering isn't necessary in the first place. const webrtc::FieldTrialsView* field_trials = allocator_-&gt;field_trials(); if (IsDiversifyIpv6InterfacesEnabled(field_trials)) &#123; std::vector&lt;const rtc::Network*&gt; ipv6_networks; for (auto it = networks.begin(); it != networks.end();) &#123; if ((*it)-&gt;prefix().family() == AF_INET6) &#123; ipv6_networks.push_back(*it); it = networks.erase(it); continue; &#125; ++it; &#125; ipv6_networks = SelectIPv6Networks(ipv6_networks, allocator_-&gt;max_ipv6_networks()); networks.insert(networks.end(), ipv6_networks.begin(), ipv6_networks.end()); &#125; else &#123; int ipv6_networks = 0; for (auto it = networks.begin(); it != networks.end();) &#123; if ((*it)-&gt;prefix().family() == AF_INET6) &#123; if (ipv6_networks &gt;= allocator_-&gt;max_ipv6_networks()) &#123; it = networks.erase(it); continue; &#125; else &#123; ++ipv6_networks; &#125; &#125; ++it; &#125; &#125; return networks;&#125;void AllocationSequence::Start() &#123; state_ = kRunning; session_-&gt;network_thread()-&gt;PostTask( SafeTask(safety_.flag(), [this, epoch = epoch_] &#123; Process(epoch); &#125;)); // Take a snapshot of the best IP, so that when DisableEquivalentPhases is // called next time, we enable all phases if the best IP has since changed. previous_best_ip_ = network_-&gt;GetBestIP();&#125;void AllocationSequence::Process(int epoch) &#123; RTC_DCHECK(rtc::Thread::Current() == session_-&gt;network_thread()); const char* const PHASE_NAMES[kNumPhases] = &#123;"Udp", "Relay", "Tcp"&#125;; if (epoch != epoch_) return; // Perform all of the phases in the current step. RTC_LOG(LS_INFO) &lt;&lt; network_-&gt;ToString() &lt;&lt; ": Allocation Phase=" &lt;&lt; PHASE_NAMES[phase_]; switch (phase_) &#123; case PHASE_UDP: CreateUDPPorts(); CreateStunPorts(); break; case PHASE_RELAY: CreateRelayPorts(); break; case PHASE_TCP: CreateTCPPorts(); state_ = kCompleted; break; default: RTC_DCHECK_NOTREACHED(); &#125; if (state() == kRunning) &#123; ++phase_; session_-&gt;network_thread()-&gt;PostDelayedTask( SafeTask(safety_.flag(), [this, epoch = epoch_] &#123; Process(epoch); &#125;), TimeDelta::Millis(session_-&gt;allocator()-&gt;step_delay())); &#125; else &#123; // No allocation steps needed further if all phases in AllocationSequence // are completed. Cause further Process calls in the previous epoch to be // ignored. ++epoch_; port_allocation_complete_callback_(); &#125;&#125;void AllocationSequence::CreateUDPPorts() &#123; if (IsFlagSet(PORTALLOCATOR_DISABLE_UDP)) &#123; RTC_LOG(LS_VERBOSE) &lt;&lt; "AllocationSequence: UDP ports disabled, skipping."; return; &#125; // TODO(mallinath) - Remove UDPPort creating socket after shared socket // is enabled completely. std::unique_ptr&lt;UDPPort&gt; port; bool emit_local_candidate_for_anyaddress = !IsFlagSet(PORTALLOCATOR_DISABLE_DEFAULT_LOCAL_CANDIDATE); if (IsFlagSet(PORTALLOCATOR_ENABLE_SHARED_SOCKET) &amp;&amp; udp_socket_) &#123; port = UDPPort::Create( session_-&gt;network_thread(), session_-&gt;socket_factory(), network_, udp_socket_.get(), session_-&gt;username(), session_-&gt;password(), emit_local_candidate_for_anyaddress, session_-&gt;allocator()-&gt;stun_candidate_keepalive_interval(), session_-&gt;allocator()-&gt;field_trials()); &#125; else &#123; port = UDPPort::Create( session_-&gt;network_thread(), session_-&gt;socket_factory(), network_, session_-&gt;allocator()-&gt;min_port(), session_-&gt;allocator()-&gt;max_port(), session_-&gt;username(), session_-&gt;password(), emit_local_candidate_for_anyaddress, session_-&gt;allocator()-&gt;stun_candidate_keepalive_interval(), session_-&gt;allocator()-&gt;field_trials()); &#125; if (port) &#123; port-&gt;SetIceTiebreaker(session_-&gt;ice_tiebreaker()); // If shared socket is enabled, STUN candidate will be allocated by the // UDPPort. if (IsFlagSet(PORTALLOCATOR_ENABLE_SHARED_SOCKET)) &#123; udp_port_ = port.get(); port-&gt;SubscribePortDestroyed( [this](PortInterface* port) &#123; OnPortDestroyed(port); &#125;); // If STUN is not disabled, setting stun server address to port. if (!IsFlagSet(PORTALLOCATOR_DISABLE_STUN)) &#123; if (config_ &amp;&amp; !config_-&gt;StunServers().empty()) &#123; RTC_LOG(LS_INFO) &lt;&lt; "AllocationSequence: UDPPort will be handling the " "STUN candidate generation."; port-&gt;set_server_addresses(config_-&gt;StunServers()); &#125; &#125; &#125; session_-&gt;AddAllocatedPort(port.release(), this); &#125;&#125;void BasicPortAllocatorSession::AddAllocatedPort(Port* port, AllocationSequence* seq) &#123; RTC_DCHECK_RUN_ON(network_thread_); if (!port) return; RTC_LOG(LS_INFO) &lt;&lt; "Adding allocated port for " &lt;&lt; content_name(); port-&gt;set_content_name(content_name()); port-&gt;set_component(component()); port-&gt;set_generation(generation()); if (allocator_-&gt;proxy().type != rtc::PROXY_NONE) port-&gt;set_proxy(allocator_-&gt;user_agent(), allocator_-&gt;proxy()); port-&gt;set_send_retransmit_count_attribute( (flags() &amp; PORTALLOCATOR_ENABLE_STUN_RETRANSMIT_ATTRIBUTE) != 0); PortData data(port, seq); ports_.push_back(data); port-&gt;SignalCandidateReady.connect( this, &amp;BasicPortAllocatorSession::OnCandidateReady); port-&gt;SignalCandidateError.connect( this, &amp;BasicPortAllocatorSession::OnCandidateError); port-&gt;SignalPortComplete.connect(this, &amp;BasicPortAllocatorSession::OnPortComplete); port-&gt;SubscribePortDestroyed( [this](PortInterface* port) &#123; OnPortDestroyed(port); &#125;); port-&gt;SignalPortError.connect(this, &amp;BasicPortAllocatorSession::OnPortError); RTC_LOG(LS_INFO) &lt;&lt; port-&gt;ToString() &lt;&lt; ": Added port to allocator"; port-&gt;PrepareAddress();&#125;void BasicPortAllocatorSession::OnCandidateReady(Port* port, const Candidate&amp; c) &#123; RTC_DCHECK_RUN_ON(network_thread_); PortData* data = FindPort(port); RTC_DCHECK(data != NULL); RTC_LOG(LS_INFO) &lt;&lt; port-&gt;ToString() &lt;&lt; ": Gathered candidate: " &lt;&lt; c.ToSensitiveString(); // Discarding any candidate signal if port allocation status is // already done with gathering. if (!data-&gt;inprogress()) &#123; RTC_LOG(LS_WARNING) &lt;&lt; "Discarding candidate because port is already done gathering."; return; &#125; // Mark that the port has a pairable candidate, either because we have a // usable candidate from the port, or simply because the port is bound to the // any address and therefore has no host candidate. This will trigger the port // to start creating candidate pairs (connections) and issue connectivity // checks. If port has already been marked as having a pairable candidate, // do nothing here. // Note: We should check whether any candidates may become ready after this // because there we will check whether the candidate is generated by the ready // ports, which may include this port. bool pruned = false; if (CandidatePairable(c, port) &amp;&amp; !data-&gt;has_pairable_candidate()) &#123; data-&gt;set_has_pairable_candidate(true); if (port-&gt;Type() == RELAY_PORT_TYPE) &#123; if (turn_port_prune_policy_ == webrtc::KEEP_FIRST_READY) &#123; pruned = PruneNewlyPairableTurnPort(data); &#125; else if (turn_port_prune_policy_ == webrtc::PRUNE_BASED_ON_PRIORITY) &#123; pruned = PruneTurnPorts(port); &#125; &#125; // If the current port is not pruned yet, SignalPortReady. if (!data-&gt;pruned()) &#123; RTC_LOG(LS_INFO) &lt;&lt; port-&gt;ToString() &lt;&lt; ": Port ready."; SignalPortReady(this, port); port-&gt;KeepAliveUntilPruned(); &#125; &#125; if (data-&gt;ready() &amp;&amp; CheckCandidateFilter(c)) &#123; std::vector&lt;Candidate&gt; candidates; candidates.push_back(allocator_-&gt;SanitizeCandidate(c)); SignalCandidatesReady(this, candidates); &#125; else &#123; RTC_LOG(LS_INFO) &lt;&lt; "Discarding candidate because it doesn't match filter."; &#125; // If we have pruned any port, maybe need to signal port allocation done. if (pruned) &#123; MaybeSignalCandidatesAllocationDone(); &#125;&#125;void BasicPortAllocatorSession::OnPortComplete(Port* port) &#123; RTC_DCHECK_RUN_ON(network_thread_); RTC_LOG(LS_INFO) &lt;&lt; port-&gt;ToString() &lt;&lt; ": Port completed gathering candidates."; PortData* data = FindPort(port); RTC_DCHECK(data != NULL); // Ignore any late signals. if (!data-&gt;inprogress()) &#123; return; &#125; // Moving to COMPLETE state. data-&gt;set_state(PortData::STATE_COMPLETE); // Send candidate allocation complete signal if this was the last port. MaybeSignalCandidatesAllocationDone();&#125; é€šè¿‡ udp port è¿žæŽ¥åˆ° ice server ï¼Œ æ³¨å†Œ OnCandidateReady å›žè°ƒ å°±è·Ÿå‰é¢ p2p_transport_channel OnCandidateReady å¯¹åº”ä¸Šäº† port123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218.../webrtc/src/p2p/base/stun_port.ccUDPPort::UDPPort(rtc::Thread* thread, rtc::PacketSocketFactory* factory, const rtc::Network* network, rtc::AsyncPacketSocket* socket, absl::string_view username, absl::string_view password, bool emit_local_for_anyaddress, const webrtc::FieldTrialsView* field_trials) : Port(thread, LOCAL_PORT_TYPE, factory, network, username, password, field_trials), request_manager_( thread, [this](const void* data, size_t size, StunRequest* request) &#123; OnSendPacket(data, size, request); &#125;), socket_(socket), error_(0), ready_(false), stun_keepalive_delay_(STUN_KEEPALIVE_INTERVAL), dscp_(rtc::DSCP_NO_CHANGE), emit_local_for_anyaddress_(emit_local_for_anyaddress) &#123;&#125;UDPPort::UDPPort(rtc::Thread* thread, rtc::PacketSocketFactory* factory, const rtc::Network* network, uint16_t min_port, uint16_t max_port, absl::string_view username, absl::string_view password, bool emit_local_for_anyaddress, const webrtc::FieldTrialsView* field_trials) : Port(thread, LOCAL_PORT_TYPE, factory, network, min_port, max_port, username, password, field_trials), request_manager_( thread, [this](const void* data, size_t size, StunRequest* request) &#123; OnSendPacket(data, size, request); &#125;), socket_(nullptr), error_(0), ready_(false), stun_keepalive_delay_(STUN_KEEPALIVE_INTERVAL), dscp_(rtc::DSCP_NO_CHANGE), emit_local_for_anyaddress_(emit_local_for_anyaddress) &#123;&#125;bool UDPPort::Init() &#123; stun_keepalive_lifetime_ = GetStunKeepaliveLifetime(); if (!SharedSocket()) &#123; RTC_DCHECK(socket_ == nullptr); socket_ = socket_factory()-&gt;CreateUdpSocket( rtc::SocketAddress(Network()-&gt;GetBestIP(), 0), min_port(), max_port()); if (!socket_) &#123; RTC_LOG(LS_WARNING) &lt;&lt; ToString() &lt;&lt; ": UDP socket creation failed"; return false; &#125; socket_-&gt;SignalReadPacket.connect(this, &amp;UDPPort::OnReadPacket); &#125; socket_-&gt;SignalSentPacket.connect(this, &amp;UDPPort::OnSentPacket); socket_-&gt;SignalReadyToSend.connect(this, &amp;UDPPort::OnReadyToSend); socket_-&gt;SignalAddressReady.connect(this, &amp;UDPPort::OnLocalAddressReady); return true;&#125;void UDPPort::PrepareAddress() &#123; RTC_DCHECK(request_manager_.empty()); if (socket_-&gt;GetState() == rtc::AsyncPacketSocket::STATE_BOUND) &#123; OnLocalAddressReady(socket_, socket_-&gt;GetLocalAddress()); &#125;&#125;void UDPPort::OnLocalAddressReady(rtc::AsyncPacketSocket* socket, const rtc::SocketAddress&amp; address) &#123; // When adapter enumeration is disabled and binding to the any address, the // default local address will be issued as a candidate instead if // `emit_local_for_anyaddress` is true. This is to allow connectivity for // applications which absolutely requires a HOST candidate. rtc::SocketAddress addr = address; // If MaybeSetDefaultLocalAddress fails, we keep the "any" IP so that at // least the port is listening. MaybeSetDefaultLocalAddress(&amp;addr); AddAddress(addr, addr, rtc::SocketAddress(), UDP_PROTOCOL_NAME, "", "", LOCAL_PORT_TYPE, ICE_TYPE_PREFERENCE_HOST, 0, "", false); MaybePrepareStunCandidate();&#125;void UDPPort::MaybePrepareStunCandidate() &#123; // Sending binding request to the STUN server if address is available to // prepare STUN candidate. if (!server_addresses_.empty()) &#123; SendStunBindingRequests(); &#125; else &#123; // Port is done allocating candidates. MaybeSetPortCompleteOrError(); &#125;&#125;void UDPPort::SendStunBindingRequests() &#123; // We will keep pinging the stun server to make sure our NAT pin-hole stays // open until the deadline (specified in SendStunBindingRequest). RTC_DCHECK(request_manager_.empty()); for (ServerAddresses::const_iterator it = server_addresses_.begin(); it != server_addresses_.end();) &#123; // sending a STUN binding request may cause the current SocketAddress to be // erased from the set, invalidating the loop iterator before it is // incremented (even if the SocketAddress itself still exists). So make a // copy of the loop iterator, which may be safely invalidated. ServerAddresses::const_iterator addr = it++; SendStunBindingRequest(*addr); &#125;&#125;void UDPPort::SendStunBindingRequest(const rtc::SocketAddress&amp; stun_addr) &#123; if (stun_addr.IsUnresolvedIP()) &#123; ResolveStunAddress(stun_addr); &#125; else if (socket_-&gt;GetState() == rtc::AsyncPacketSocket::STATE_BOUND) &#123; // Check if `server_addr_` is compatible with the port's ip. if (IsCompatibleAddress(stun_addr)) &#123; request_manager_.Send( new StunBindingRequest(this, stun_addr, rtc::TimeMillis())); &#125; else &#123; // Since we can't send stun messages to the server, we should mark this // port ready. const char* reason = "STUN server address is incompatible."; RTC_LOG(LS_WARNING) &lt;&lt; reason; OnStunBindingOrResolveRequestFailed(stun_addr, SERVER_NOT_REACHABLE_ERROR, reason); &#125; &#125;&#125;StunBindingRequest(UDPPort* port, const rtc::SocketAddress&amp; addr, int64_t start_time) : StunRequest(port-&gt;request_manager(), std::make_unique&lt;StunMessage&gt;(STUN_BINDING_REQUEST)), port_(port), server_addr_(addr), start_time_(start_time) &#123;&#125; const rtc::SocketAddress&amp; server_addr() const &#123; return server_addr_; &#125; void OnResponse(StunMessage* response) override &#123; const StunAddressAttribute* addr_attr = response-&gt;GetAddress(STUN_ATTR_MAPPED_ADDRESS); if (!addr_attr) &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Binding response missing mapped address."; &#125; else if (addr_attr-&gt;family() != STUN_ADDRESS_IPV4 &amp;&amp; addr_attr-&gt;family() != STUN_ADDRESS_IPV6) &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Binding address has bad family"; &#125; else &#123; rtc::SocketAddress addr(addr_attr-&gt;ipaddr(), addr_attr-&gt;port()); port_-&gt;OnStunBindingRequestSucceeded(this-&gt;Elapsed(), server_addr_, addr); &#125; // The keep-alive requests will be stopped after its lifetime has passed. if (WithinLifetime(rtc::TimeMillis())) &#123; port_-&gt;request_manager_.SendDelayed( new StunBindingRequest(port_, server_addr_, start_time_), port_-&gt;stun_keepalive_delay()); &#125; &#125;void UDPPort::OnStunBindingRequestSucceeded( int rtt_ms, const rtc::SocketAddress&amp; stun_server_addr, const rtc::SocketAddress&amp; stun_reflected_addr) &#123; RTC_DCHECK(stats_.stun_binding_responses_received &lt; stats_.stun_binding_requests_sent); stats_.stun_binding_responses_received++; stats_.stun_binding_rtt_ms_total += rtt_ms; stats_.stun_binding_rtt_ms_squared_total += rtt_ms * rtt_ms; if (bind_request_succeeded_servers_.find(stun_server_addr) != bind_request_succeeded_servers_.end()) &#123; return; &#125; bind_request_succeeded_servers_.insert(stun_server_addr); // If socket is shared and `stun_reflected_addr` is equal to local socket // address and mDNS obfuscation is not enabled, or if the same address has // been added by another STUN server, then discarding the stun address. // For STUN, related address is the local socket address. if ((!SharedSocket() || stun_reflected_addr != socket_-&gt;GetLocalAddress() || Network()-&gt;GetMdnsResponder() != nullptr) &amp;&amp; !HasStunCandidateWithAddress(stun_reflected_addr)) &#123; rtc::SocketAddress related_address = socket_-&gt;GetLocalAddress(); // If we can't stamp the related address correctly, empty it to avoid leak. if (!MaybeSetDefaultLocalAddress(&amp;related_address)) &#123; related_address = rtc::EmptySocketAddressWithFamily(related_address.family()); &#125; rtc::StringBuilder url; url &lt;&lt; "stun:" &lt;&lt; stun_server_addr.hostname() &lt;&lt; ":" &lt;&lt; stun_server_addr.port(); AddAddress(stun_reflected_addr, socket_-&gt;GetLocalAddress(), related_address, UDP_PROTOCOL_NAME, "", "", STUN_PORT_TYPE, ICE_TYPE_PREFERENCE_SRFLX, 0, url.str(), false); &#125; MaybeSetPortCompleteOrError();&#125; udp port è·Ÿ stun/turn server socketè¿žæŽ¥ å‘é€ SendStunBindingRequestï¼Œæ‹¿åˆ° related_addressã€‚ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051.../webrtc/src/p2p/base/port.ccvoid Port::AddAddress(const rtc::SocketAddress&amp; address, const rtc::SocketAddress&amp; base_address, const rtc::SocketAddress&amp; related_address, absl::string_view protocol, absl::string_view relay_protocol, absl::string_view tcptype, absl::string_view type, uint32_t type_preference, uint32_t relay_preference, absl::string_view url, bool is_final) &#123; RTC_DCHECK_RUN_ON(thread_); if (protocol == TCP_PROTOCOL_NAME &amp;&amp; type == LOCAL_PORT_TYPE) &#123; RTC_DCHECK(!tcptype.empty()); &#125; std::string foundation = ComputeFoundation(type, protocol, relay_protocol, base_address); Candidate c(component_, protocol, address, 0U, username_fragment(), password_, type, generation_, foundation, network_-&gt;id(), network_cost_); c.set_priority( c.GetPriority(type_preference, network_-&gt;preference(), relay_preference)); c.set_relay_protocol(relay_protocol); c.set_tcptype(tcptype); c.set_network_name(network_-&gt;name()); c.set_network_type(network_-&gt;type()); c.set_underlying_type_for_vpn(network_-&gt;underlying_type_for_vpn()); c.set_url(url); c.set_related_address(related_address); bool pending = MaybeObfuscateAddress(&amp;c, type, is_final); if (!pending) &#123; FinishAddingAddress(c, is_final); &#125;&#125;void Port::FinishAddingAddress(const Candidate&amp; c, bool is_final) &#123; candidates_.push_back(c); SignalCandidateReady(this, c); PostAddAddress(is_final);&#125;void Port::PostAddAddress(bool is_final) &#123; if (is_final) &#123; SignalPortComplete(this); &#125;&#125; AddAddress åˆ›å»º Candidateï¼Œé€šè¿‡ SignalCandidateReady å±‚å±‚å›žè°ƒè¿”å›ž å›žåŽ»â€¦. conclusionæ•´ä¸ª Candidate çš„ æ”¶é›†è¿‡ç¨‹å°±èµ°å®Œäº† ~ OVER ~ åœ¨ WebRTC ä¸­ï¼ŒICE åè®®ä½¿ç”¨ ICE Candidate ä¿¡æ¯æ¥æè¿°è®¾å¤‡çš„ç½‘ç»œåœ°å€ã€‚ICE Candidate åŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š åª’ä½“ç±»åž‹ï¼ˆéŸ³é¢‘æˆ–è§†é¢‘ï¼‰åè®®ç±»åž‹ï¼ˆUDP æˆ– TCPï¼‰IP åœ°å€ç«¯å£å·å¥—æŽ¥å­—ç±»åž‹ï¼ˆIPv4 æˆ– IPv6ï¼‰ä¼˜å…ˆçº§åŸºç¡€åœ°å€ç±»åž‹ï¼ˆæœåŠ¡å™¨åå°„åœ°å€ã€å¯¹ç§° NAT åœ°å€ã€ä¸­ç»§åœ°å€ç­‰ï¼‰æ ¹æ® ICE Candidate ä¸­çš„åŸºç¡€åœ°å€ç±»åž‹ï¼Œå¯ä»¥å°† ICE Candidate åˆ†ä¸ºä»¥ä¸‹å››ç§ç±»åž‹ï¼š ä¸»æœºå€™é€‰ï¼ˆhost candidateï¼‰ï¼šä¸»æœºå€™é€‰æ˜¯æŒ‡è®¾å¤‡çš„æœ¬åœ°åœ°å€ï¼Œå³é€šè¿‡ STUN æœåŠ¡å™¨èŽ·å–çš„æœ¬åœ° IP åœ°å€å’Œç«¯å£å·ã€‚ä¸»æœºå€™é€‰å¯ä»¥ç›´æŽ¥ç”¨äºŽé€šä¿¡ï¼Œæ˜¯ ICE åè®®ä¸­ä¼˜å…ˆçº§æœ€é«˜çš„å€™é€‰ç±»åž‹ã€‚æœåŠ¡å™¨åå°„å€™é€‰ï¼ˆserver reflexive candidateï¼‰ï¼šæœåŠ¡å™¨åå°„å€™é€‰æ˜¯æŒ‡é€šè¿‡ STUN æœåŠ¡å™¨èŽ·å–çš„å…¬ç½‘ IP åœ°å€å’Œç«¯å£å·ã€‚æœåŠ¡å™¨åå°„å€™é€‰å¯ä»¥ç”¨äºŽ NAT çŽ¯å¢ƒä¸‹çš„é€šä¿¡ï¼Œä¼˜å…ˆçº§æ¬¡äºŽä¸»æœºå€™é€‰ã€‚ï¼ˆstun bingding requestï¼‰ä¸­ç»§å€™é€‰ï¼ˆrelay candidateï¼‰ï¼šä¸­ç»§å€™é€‰æ˜¯æŒ‡é€šè¿‡ TURN æœåŠ¡å™¨èŽ·å–çš„ IP åœ°å€å’Œç«¯å£å·ã€‚ä¸­ç»§å€™é€‰å¯ä»¥ç”¨äºŽ NAT çŽ¯å¢ƒä¸‹çš„é€šä¿¡ï¼Œä½†é€šä¿¡è´¨é‡å¯èƒ½ä¼šè¾ƒå·®ï¼Œä¼˜å…ˆçº§æœ€ä½Žã€‚ è¿žé€šæ€§æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œåœ¨æ¥è‡ªå¯¹æ–¹çš„æ•°æ®æŠ¥æ–‡é‡Œçœ‹åˆ°çš„åœ°å€ï¼ˆpeer reflexiveï¼Œç¼©å†™ä¸ºprflxï¼‰ ï¼ˆConnection Requestï¼‰ referenceJSEP]]></content>
      <categories>
        <category>RTC</category>
      </categories>
      <tags>
        <tag>ios</tag>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OWT-client-iosä¿¡ä»¤äº¤äº’æºç åˆ†æž]]></title>
    <url>%2F2023%2F02%2F15%2FOWT-client-ios%E4%BF%A1%E4%BB%A4%E4%BA%A4%E4%BA%92%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[OWTOWT ä¿¡ä»¤äº¤äº’è¿‡ç¨‹: A POST /tokens/A SocketIO connectA SocketIO loginA SocketIO publishA SocketIO soac offerA SocketIO soac candidatePortal SocketIO soac answer B POST /tokens/B SocketIO connectB SocketIO loginB SocketIO subscribeB SocketIO soac offerB SocketIO soac candidatePortal SocketIO soac answer SocketIO logout token12345678910111213141516-(void)getTokenFromBasicSample:(NSString *)basicServer roomId:(NSString *)roomId onSuccess:(void (^)(NSString *))onSuccess onFailure:(void (^)())onFailure&#123; AFHTTPRequestOperationManager *manager = [AFHTTPRequestOperationManager manager]; manager.requestSerializer = [AFJSONRequestSerializer serializer]; [manager.requestSerializer setValue:@"*/*" forHTTPHeaderField:@"Accept"]; [manager.requestSerializer setValue:@"application/json" forHTTPHeaderField:@"Content-Type"]; manager.responseSerializer = [AFHTTPResponseSerializer serializer]; manager.securityPolicy.allowInvalidCertificates=YES; manager.securityPolicy.validatesDomainName=NO; NSDictionary *params = [[NSDictionary alloc]initWithObjectsAndKeys:roomId, @"room", @"user", @"username", @"presenter", @"role", nil]; [manager POST:[basicServer stringByAppendingString:@"createToken/"] parameters:params success:^(AFHTTPRequestOperation *operation, id responseObject) &#123; NSData* data=[[NSData alloc]initWithData:responseObject]; onSuccess([[NSString alloc]initWithData:data encoding:NSUTF8StringEncoding]); &#125; failure:^(AFHTTPRequestOperation *operation, NSError *error) &#123; NSLog(@"Error: %@", error); &#125;];&#125; data base64 decodeä¹‹åŽ123456&#123; "tokenId":"63ec8bb0e20782d930e787bb", "host":"172.19.35.107:8080", "secure":true, "signature":"NWE0YjQzM2M1Zjk3NDMwMTRkOGM3Nzg5Zjk3MGQ1YWZkM2I2YmI1MWNmZDk2NzM5NGJiYjBhNWRkMDA2NGE2OQ=="&#125; connectä¸Šä¸€æ­¥ token çš„ responseï¼Œ host å°±æ˜¯ socketé“¾æŽ¥çš„ url åœ°å€ã€‚ connectå°±æ˜¯ä¸Žserverå»ºè®®é•¿è¿žæŽ¥ï¼ˆsocketIOï¼‰,OWT.frameworkå¯¹å¤–æš´éœ²çš„OWTConferenceClientä¸­å¹¶æ²¡æœ‰æä¾›connnectçš„æ–¹æ³•ï¼Œconnectçš„è¿‡ç¨‹å…¶å®žæ˜¯åœ¨joinæ–¹æ³•ä¸­ join12345678910111213141516171819202122232425262728293031../src/talk/owt/sdk/conference/objc/OWTConferenceClient.mm- (void)joinWithToken:(NSString*)token onSuccess:(void (^)(OWTConferenceInfo*))onSuccess onFailure:(void (^)(NSError*))onFailure &#123; if (token == nil) &#123; if (onFailure != nil) &#123; NSError* err = [[NSError alloc] initWithDomain:OWTErrorDomain code:OWTConferenceErrorUnknown userInfo:[[NSDictionary alloc] initWithObjectsAndKeys:@"Token cannot be nil.", NSLocalizedDescriptionKey, nil]]; onFailure(err); &#125; return; &#125; const std::string nativeToken = [token UTF8String]; __weak OWTConferenceClient *weakSelf = self; _nativeConferenceClient-&gt;Join( nativeToken, [=](std::shared_ptr&lt;owt::conference::ConferenceInfo&gt; info) &#123; if (onSuccess != nil) onSuccess([[OWTConferenceInfo alloc] initWithNativeInfo:info]); &#125;, [=](std::unique_ptr&lt;owt::base::Exception&gt; e) &#123; [weakSelf triggerOnFailure:onFailure withException:(std::move(e))]; &#125;);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122../src/talk/owt/sdk/conference/conferenceclient.ccvoid ConferenceClient::Join( const std::string&amp; token, std::function&lt;void(std::shared_ptr&lt;ConferenceInfo&gt;)&gt; on_success, std::function&lt;void(std::unique_ptr&lt;Exception&gt;)&gt; on_failure) &#123; if (signaling_channel_connected_) &#123; if (on_failure != nullptr) &#123; event_queue_-&gt;PostTask([on_failure]() &#123; std::unique_ptr&lt;Exception&gt; e( new Exception(ExceptionType::kConferenceUnknown, "Already connected to conference server.")); on_failure(std::move(e)); &#125;); &#125; return; &#125; std::string token_base64(token); if (!StringUtils::IsBase64EncodedString(token)) &#123; RTC_LOG(LS_WARNING) &lt;&lt; "Passing token with Base64 decoded is deprecated, " "please pass it without modification."; token_base64 = rtc::Base64::Encode(token); &#125; signaling_channel_-&gt;Connect( token_base64, [=](sio::message::ptr info) &#123; signaling_channel_connected_ = true; // Get current user's participantId, user ID and role and fill in the // ConferenceInfo. std::string participant_id, user_id, role; if (info-&gt;get_map()["id"]-&gt;get_flag() != sio::message::flag_string || info-&gt;get_map()["user"]-&gt;get_flag() != sio::message::flag_string || info-&gt;get_map()["role"]-&gt;get_flag() != sio::message::flag_string) &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Room info doesn't contain participant's ID/uerID/role."; if (on_failure) &#123; event_queue_-&gt;PostTask([on_failure]() &#123; std::unique_ptr&lt;Exception&gt; e( new Exception(ExceptionType::kConferenceUnknown, "Received invalid user info from MCU.")); on_failure(std::move(e)); &#125;); &#125; return; &#125; else &#123; participant_id = info-&gt;get_map()["id"]-&gt;get_string(); user_id = info-&gt;get_map()["user"]-&gt;get_string(); role = info-&gt;get_map()["role"]-&gt;get_string(); const std::lock_guard&lt;std::mutex&gt; lock(conference_info_mutex_); if (current_conference_info_.get()) &#123; current_conference_info_.reset(); &#125; current_conference_info_.reset(new ConferenceInfo); current_conference_info_-&gt;self_.reset( new Participant(participant_id, role, user_id)); &#125; auto room_info = info-&gt;get_map()["room"]; if (room_info == nullptr || room_info-&gt;get_flag() != sio::message::flag_object) &#123; RTC_DCHECK(false); return; &#125; if (room_info-&gt;get_map()["id"]-&gt;get_flag() != sio::message::flag_string) &#123; RTC_DCHECK(false); return; &#125; else &#123; current_conference_info_-&gt;id_ = room_info-&gt;get_map()["id"]-&gt;get_string(); &#125; // Trigger OnUserJoin for existed users, and also fill in the // ConferenceInfo. if (room_info-&gt;get_map()["participants"]-&gt;get_flag() != sio::message::flag_array) &#123; RTC_LOG(LS_WARNING) &lt;&lt; "Room info doesn't contain valid users."; &#125; else &#123; auto users = room_info-&gt;get_map()["participants"]-&gt;get_vector(); // Make sure |on_success| is triggered before any other events because // OnUserJoined and OnStreamAdded should be triggered after join a // conference. for (auto it = users.begin(); it != users.end(); ++it) &#123; TriggerOnUserJoined(*it, true); &#125; &#125; // Trigger OnStreamAdded for existed remote streams, and also fill in // the ConferenceInfo. if (room_info-&gt;get_map()["streams"]-&gt;get_flag() != sio::message::flag_array) &#123; RTC_LOG(LS_WARNING) &lt;&lt; "Room info doesn't contain valid streams."; &#125; else &#123; auto streams = room_info-&gt;get_map()["streams"]-&gt;get_vector(); for (auto it = streams.begin(); it != streams.end(); ++it) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Find streams in the conference."; TriggerOnStreamAdded(*it, true); &#125; &#125;#ifdef OWT_ENABLE_QUIC auto webtransport_token = info-&gt;get_map()["webTransportToken"]; if (webtransport_token != nullptr &amp;&amp; webtransport_token-&gt;get_flag() == sio::message::flag_string) &#123; // Base64 encoded webTransportToken with format: // &#123;tokenId, transportId, participantId, issueTime&#125;. Parse the transportId // and save it. webtransport_token_ = info-&gt;get_map()["webTransportToken"]-&gt;get_string(); bool transport_id_get = ParseWebTransportToken(); // If server provides WebTransport channel, prepare the QUIC client as // well. No underlying webtransport connection setup at this phase. if (transport_id_get) InitializeQuicClientIfSupported(token_base64); &#125;#endif // Invoke the success callback before trigger any participant join or // stream added message. if (on_success) &#123; event_queue_-&gt;PostTask( [on_success, this]() &#123; on_success(current_conference_info_); &#125;); &#125; &#125;, on_failure);&#125; å¯ä»¥çœ‹åˆ° å…ˆè¿›è¡Œäº† token çš„æ ¡éªŒï¼Œç„¶åŽ è¿›è¡Œ signaling_channel_-&gt;Connectï¼Œæœ¬è´¨ä¸Š join å…¶å®žå°±æ˜¯ æ‰§è¡Œconnectã€‚ publish12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455-(void)doPublish&#123; if (_localStream == nil) &#123;#if TARGET_IPHONE_SIMULATOR NSLog(@"Camera is not supported on simulator"); OWTStreamConstraints* constraints=[[OWTStreamConstraints alloc]init]; constraints.audio=YES; constraints.video=nil;#else /* Create LocalStream with constraints */ OWTStreamConstraints* constraints=[[OWTStreamConstraints alloc] init]; constraints.audio=YES; constraints.video=[[OWTVideoTrackConstraints alloc] init]; constraints.video.frameRate=24; constraints.video.resolution=CGSizeMake(640,480); constraints.video.devicePosition=AVCaptureDevicePositionFront;#endif RTCMediaStream *localRTCStream = [self createLocalSenderStream:constraints]; OWTStreamSourceInfo *sourceinfo = [[OWTStreamSourceInfo alloc] init]; sourceinfo.audio = OWTAudioSourceInfoMic; sourceinfo.video = OWTVideoSourceInfoCamera; _localStream=[[OWTLocalStream alloc] initWithMediaStream:localRTCStream source:sourceinfo];#if TARGET_IPHONE_SIMULATOR NSLog(@"Stream does not have video track.");#else dispatch_async(dispatch_get_main_queue(), ^&#123; [((SFUStreamView *)self.view).localVideoView setCaptureSession:[_capturer captureSession] ]; &#125;);#endif OWTPublishOptions* options=[[OWTPublishOptions alloc] init]; OWTAudioCodecParameters* opusParameters=[[OWTAudioCodecParameters alloc] init]; opusParameters.name=OWTAudioCodecOpus; OWTAudioEncodingParameters *audioParameters=[[OWTAudioEncodingParameters alloc] init]; audioParameters.codec=opusParameters; options.audio=[NSArray arrayWithObjects:audioParameters, nil]; OWTVideoCodecParameters *h264Parameters=[[OWTVideoCodecParameters alloc] init]; h264Parameters.name=OWTVideoCodecH264; OWTVideoEncodingParameters *videoParameters=[[OWTVideoEncodingParameters alloc]init]; videoParameters.codec=h264Parameters; options.video=[NSArray arrayWithObjects:videoParameters, nil]; [_conferenceClient publish:_localStream withOptions:options onSuccess:^(OWTConferencePublication* p) &#123; NSLog(@"[ZSPDEBUG Function:%s Line:%d] publish success! OWTConferencePublication:%@ id:%@", __FUNCTION__,__LINE__,p,p.publicationId); _publication=p; _publication.delegate=self; [self mixToCommonView:p]; &#125; onFailure:^(NSError* err) &#123; NSLog(@"publish failure!"); [self showMsg:[err localizedFailureReason]]; &#125;]; _screenStream=appDelegate.screenStream; _remoteStream=appDelegate.mixedStream; [self subscribe]; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940../src/talk/owt/sdk/conference/objc/OWTConferenceClient.mm- (void)publish:(OWTLocalStream*)stream withOptions:(OWTPublishOptions*)options onSuccess:(void (^)(OWTConferencePublication*))onSuccess onFailure:(void (^)(NSError*))onFailure &#123; RTC_CHECK(stream); auto nativeStreamRefPtr = [stream nativeStream]; std::shared_ptr&lt;owt::base::LocalStream&gt; nativeStream( std::static_pointer_cast&lt;owt::base::LocalStream&gt;(nativeStreamRefPtr)); __weak OWTConferenceClient *weakSelf = self; if (options == nil) &#123; _nativeConferenceClient-&gt;Publish( nativeStream, [=](std::shared_ptr&lt;owt::conference::ConferencePublication&gt; publication) &#123; [_publishedStreams setObject:stream forKey:[stream streamId]]; if (onSuccess != nil) onSuccess([[OWTConferencePublication alloc] initWithNativePublication:publication]); &#125;, [=](std::unique_ptr&lt;owt::base::Exception&gt; e) &#123; [weakSelf triggerOnFailure:onFailure withException:(std::move(e))]; &#125;); &#125; else &#123; _nativeConferenceClient-&gt;Publish( nativeStream, *[options nativePublishOptions].get(), [=](std::shared_ptr&lt;owt::conference::ConferencePublication&gt; publication) &#123; [_publishedStreams setObject:stream forKey:[stream streamId]]; if (onSuccess != nil) onSuccess([[OWTConferencePublication alloc] initWithNativePublication:publication]); &#125;, [=](std::unique_ptr&lt;owt::base::Exception&gt; e) &#123; [weakSelf triggerOnFailure:onFailure withException:(std::move(e))]; &#125;); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115../src/talk/owt/sdk/conference/conferenceclient.ccvoid ConferenceClient::Publish( std::shared_ptr&lt;LocalStream&gt; stream, const PublishOptions&amp; options, std::function&lt;void(std::shared_ptr&lt;ConferencePublication&gt;)&gt; on_success, std::function&lt;void(std::unique_ptr&lt;Exception&gt;)&gt; on_failure) &#123; if (!CheckNullPointer((uintptr_t)stream.get(), on_failure)) &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Local stream cannot be nullptr."; return; &#125; if (!CheckSignalingChannelOnline(on_failure)) &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Signaling channel disconnected."; return; &#125;#ifdef OWT_ENABLE_QUIC if (stream-&gt;DataEnabled()) &#123; if (web_transport_channel_ &amp;&amp; web_transport_channel_connected_) &#123; std::weak_ptr&lt;ConferenceClient&gt; weak_this = shared_from_this(); web_transport_channel_-&gt;Publish( stream, [stream, on_success, weak_this](std::string session_id, std::string transport_id) &#123; auto that = weak_this.lock(); if (!that) return; // map current pcc if (on_success != nullptr) &#123; // For QUIC stream we use session_id as stream_id for publication. RTC_LOG(LS_INFO) &lt;&lt; "Publication succeed. Returning session id/transport id:" &lt;&lt; session_id; std::shared_ptr&lt;ConferencePublication&gt; cp( new ConferencePublication(that, session_id, session_id)); &#123; std::lock_guard&lt;std::mutex&gt; lock(that-&gt;quic_publications_mutex_); that-&gt;quic_publications_[session_id] = cp; &#125; RTC_LOG(LS_INFO) &lt;&lt; "Writting session id for stream auth:" &lt;&lt; session_id; // Convert to hex16 and write for stream auth. uint8_t* stream_uuid = new uint8_t[16]; ConvertUUID(session_id.c_str(), stream_uuid); stream-&gt;Stream()-&gt;Write(stream_uuid, 16); delete []stream_uuid; on_success(cp); &#125; &#125;, on_failure); &#125; else &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Cannot publish a quic stream without quic client connected."; std::string failure_message( "Publishing quic stream without quic client connected"); if (on_failure != nullptr) &#123; event_queue_-&gt;PostTask([on_failure, failure_message]() &#123; std::unique_ptr&lt;Exception&gt; e(new Exception( ExceptionType::kConferenceUnknown, failure_message)); on_failure(std::move(e)); &#125;); &#125; &#125; return; &#125;#endif if (!CheckNullPointer((uintptr_t)(stream-&gt;MediaStream()), on_failure)) &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Cannot publish a local stream without media stream."; return; &#125; if (stream-&gt;MediaStream()-&gt;GetAudioTracks().size() == 0 &amp;&amp; stream-&gt;MediaStream()-&gt;GetVideoTracks().size() == 0) &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Cannot publish a local stream without audio &amp; video"; std::string failure_message( "Publishing local stream with neither audio nor video."); if (on_failure != nullptr) &#123; event_queue_-&gt;PostTask([on_failure, failure_message]() &#123; std::unique_ptr&lt;Exception&gt; e( new Exception(ExceptionType::kConferenceUnknown, failure_message)); on_failure(std::move(e)); &#125;); &#125; return; &#125; // Reorder SDP according to perference list. PeerConnectionChannelConfiguration config = GetPeerConnectionChannelConfiguration(); for (auto codec : options.video) &#123; config.video.push_back(VideoEncodingParameters(codec)); &#125; for (auto codec : options.audio) &#123; config.audio.push_back(AudioEncodingParameters(codec)); &#125; std::shared_ptr&lt;ConferencePeerConnectionChannel&gt; pcc( new ConferencePeerConnectionChannel(config, signaling_channel_, event_queue_)); pcc-&gt;AddObserver(*this); &#123; std::lock_guard&lt;std::mutex&gt; lock(publish_pcs_mutex_); publish_pcs_.push_back(pcc); &#125; std::weak_ptr&lt;ConferenceClient&gt; weak_this = shared_from_this(); std::string stream_id = stream-&gt;Id(); pcc-&gt;Publish(stream, [on_success, weak_this, stream_id](std::string session_id) &#123; auto that = weak_this.lock(); if (!that) return; // map current pcc if (on_success != nullptr) &#123; std::shared_ptr&lt;ConferencePublication&gt; cp( new ConferencePublication(that, session_id, stream_id)); on_success(cp); &#125; &#125;, on_failure);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159../src/talk/owt/sdk/conference/ConferencePeerConnectionChannel.ccvoid ConferencePeerConnectionChannel::Publish( std::shared_ptr&lt;LocalStream&gt; stream, std::function&lt;void(std::string)&gt; on_success, std::function&lt;void(std::unique_ptr&lt;Exception&gt;)&gt; on_failure) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Publish a local stream."; published_stream_ = stream; if ((!CheckNullPointer((uintptr_t)stream.get(), on_failure)) || (!CheckNullPointer((uintptr_t)stream-&gt;MediaStream(), on_failure))) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Local stream cannot be nullptr."; &#125; if (IsMediaStreamEnded(stream-&gt;MediaStream())) &#123; if (on_failure != nullptr) &#123; event_queue_-&gt;PostTask([on_failure]() &#123; std::unique_ptr&lt;Exception&gt; e(new Exception( ExceptionType::kConferenceUnknown, "Cannot publish ended stream.")); on_failure(std::move(e)); &#125;); &#125; return; &#125; int audio_track_count = 0, video_track_count = 0; audio_track_count = stream-&gt;MediaStream()-&gt;GetAudioTracks().size(); video_track_count = stream-&gt;MediaStream()-&gt;GetVideoTracks().size(); if (audio_track_count == 0 &amp;&amp; video_track_count == 0) &#123; if (on_failure != nullptr) &#123; event_queue_-&gt;PostTask([on_failure]() &#123; std::unique_ptr&lt;Exception&gt; e(new Exception( ExceptionType::kConferenceUnknown, "Cannot publish media stream without any tracks.")); on_failure(std::move(e)); &#125;); &#125; return; &#125; publish_success_callback_ = on_success; failure_callback_ = on_failure; audio_transceiver_direction_=webrtc::RtpTransceiverDirection::kSendOnly; video_transceiver_direction_=webrtc::RtpTransceiverDirection::kSendOnly; sio::message::ptr options = sio::object_message::create(); // attributes sio::message::ptr attributes_ptr = sio::object_message::create(); for (auto const&amp; attr : stream-&gt;Attributes()) &#123; attributes_ptr-&gt;get_map()[attr.first] = sio::string_message::create(attr.second); &#125; options-&gt;get_map()[kStreamOptionAttributesKey] = attributes_ptr; // TODO(jianlin): Currently we fix mid to 0/1. Need // to update the flow to set local desc for retrieving the mid. // See https://github.com/open-webrtc-toolkit/owt-client-native/issues/459 // for more details. sio::message::ptr media_ptr = sio::object_message::create(); sio::message::ptr tracks_ptr = sio::array_message::create(); if (audio_track_count != 0) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Adding audio tracks for publish."; sio::message::ptr audio_options = sio::object_message::create(); audio_options-&gt;get_map()["type"] = sio::string_message::create("audio"); audio_options-&gt;get_map()["mid"] = sio::string_message::create("0"); if (stream-&gt;Source().audio == owt::base::AudioSourceInfo::kScreenCast) &#123; audio_options-&gt;get_map()["source"] = sio::string_message::create("screen-cast"); &#125; else &#123; audio_options-&gt;get_map()["source"] = sio::string_message::create("mic"); &#125; tracks_ptr-&gt;get_vector().push_back(audio_options); &#125; if (video_track_count != 0) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Adding video tracks for publish."; sio::message::ptr video_options = sio::object_message::create(); video_options-&gt;get_map()["type"] = sio::string_message::create("video"); if (audio_track_count == 0) &#123; video_options-&gt;get_map()["mid"] = sio::string_message::create("0"); &#125; else &#123; video_options-&gt;get_map()["mid"] = sio::string_message::create("1"); &#125; if (stream-&gt;Source().video == owt::base::VideoSourceInfo::kScreenCast) &#123; video_options-&gt;get_map()["source"] = sio::string_message::create("screen-cast"); &#125; else &#123; video_options-&gt;get_map()["source"] = sio::string_message::create("camera"); &#125; tracks_ptr-&gt;get_vector().push_back(video_options); &#125; media_ptr-&gt;get_map()["tracks"] = tracks_ptr; options-&gt;get_map()["media"] = media_ptr; sio::message::ptr transport_ptr = sio::object_message::create(); transport_ptr-&gt;get_map()["type"] = sio::string_message::create("webrtc"); options-&gt;get_map()["transport"] = transport_ptr; SendPublishMessage(options, stream, on_failure);&#125;void ConferencePeerConnectionChannel::SendPublishMessage( sio::message::ptr options, std::shared_ptr&lt;LocalStream&gt; stream, std::function&lt;void(std::unique_ptr&lt;Exception&gt;)&gt; on_failure) &#123; signaling_channel_-&gt;SendInitializationMessage( options, stream-&gt;MediaStream()-&gt;id(), "", [stream, this](std::string session_id, std::string transport_id) &#123; SetSessionId(session_id); for (const auto&amp; track : stream-&gt;MediaStream()-&gt;GetAudioTracks()) &#123; webrtc::RtpTransceiverInit transceiver_init; transceiver_init.stream_ids.push_back(stream-&gt;MediaStream()-&gt;id()); transceiver_init.direction = webrtc::RtpTransceiverDirection::kSendOnly; AddTransceiver(track, transceiver_init); &#125; for (const auto&amp; track : stream-&gt;MediaStream()-&gt;GetVideoTracks()) &#123; webrtc::RtpTransceiverInit transceiver_init; transceiver_init.stream_ids.push_back(stream-&gt;MediaStream()-&gt;id()); transceiver_init.direction = webrtc::RtpTransceiverDirection::kSendOnly; if (configuration_.video.size() &gt; 0 &amp;&amp; configuration_.video[0].rtp_encoding_parameters.size() != 0) &#123; for (auto encoding : configuration_.video[0].rtp_encoding_parameters) &#123; webrtc::RtpEncodingParameters param; if (encoding.rid != "") param.rid = encoding.rid; if (encoding.max_bitrate_bps != 0) param.max_bitrate_bps = encoding.max_bitrate_bps; if (encoding.max_framerate != 0) param.max_framerate = encoding.max_framerate; if (encoding.scale_resolution_down_by &gt; 0) param.scale_resolution_down_by = encoding.scale_resolution_down_by; if (encoding.num_temporal_layers &gt; 0 &amp;&amp; encoding.num_temporal_layers &lt;= 4) &#123; param.num_temporal_layers = encoding.num_temporal_layers; &#125; if (encoding.priority != owt::base::NetworkPriority::kDefault) &#123; switch (encoding.priority) &#123; case owt::base::NetworkPriority::kVeryLow: param.network_priority = webrtc::Priority::kVeryLow; break; case owt::base::NetworkPriority::kLow: param.network_priority = webrtc::Priority::kLow; break; case owt::base::NetworkPriority::kMedium: param.network_priority = webrtc::Priority::kMedium; break; case owt::base::NetworkPriority::kHigh: param.network_priority = webrtc::Priority::kHigh; break; default: break; &#125; &#125; param.active = encoding.active; transceiver_init.send_encodings.push_back(param); &#125; &#125; AddTransceiver(track, transceiver_init); &#125; CreateOffer(); &#125;, on_failure);&#125; const std::string kEventNamePublish = â€œpublishâ€; publish_stream_label ä¸ä¸ºç©ºï¼Œå‘é€publish message 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475void ConferenceSocketSignalingChannel::SendInitializationMessage( sio::message::ptr options, std::string publish_stream_label, std::string subscribe_stream_label, std::function&lt;void(std::string, std::string)&gt; on_success, std::function&lt;void(std::unique_ptr&lt;Exception&gt;)&gt; on_failure) &#123; sio::message::list message_list; message_list.push(options); std::string event_name; if (publish_stream_label != "") event_name = kEventNamePublish; else if (subscribe_stream_label != "") event_name = kEventNameSubscribe; Emit(event_name, message_list, [=](sio::message::list const&amp; msg) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Received ack from server."; if (on_success == nullptr) &#123; RTC_LOG(LS_WARNING) &lt;&lt; "Does not implement success callback. Make sure " "it is what you want."; return; &#125; sio::message::ptr message = msg.at(0); if (message-&gt;get_flag() != sio::message::flag_string) &#123; RTC_LOG(LS_WARNING) &lt;&lt; "The first element of publish ack is not a string."; if (on_failure) &#123; std::unique_ptr&lt;Exception&gt; e(new Exception( ExceptionType::kConferenceInvalidParam, "Received unkown message from server.")); on_failure(std::move(e)); &#125; return; &#125; if (message-&gt;get_string() == "ok") &#123; if (msg.at(1)-&gt;get_flag() != sio::message::flag_object) &#123; RTC_DCHECK(false); return; &#125; // TODO: Spec returns &#123;transportId, publication/subscriptionId&#125; while server impl // is currently returning id and transportId. RTC_LOG(LS_ERROR) &lt;&lt; "Fetching transport ID:"; std::string session_id = msg.at(1)-&gt;get_map()["id"]-&gt;get_string(); std::string transport_id(""); auto transport_id_obj = msg.at(1)-&gt;get_map()["transportId"]; if (transport_id_obj != nullptr &amp;&amp; transport_id_obj-&gt;get_flag() == sio::message::flag_string) &#123; transport_id = transport_id_obj-&gt;get_string(); &#125; RTC_LOG(LS_ERROR) &lt;&lt; "Session ID:" &lt;&lt; session_id &lt;&lt; ", TransportID:" &lt;&lt; transport_id; if (event_name == kEventNamePublish || event_name == kEventNameSubscribe) &#123; on_success(session_id, transport_id); return; &#125; return; &#125; else if (message-&gt;get_string() == "error" &amp;&amp; msg.at(1) != nullptr &amp;&amp; msg.at(1)-&gt;get_flag() == sio::message::flag_string) &#123; if (on_failure) &#123; std::unique_ptr&lt;Exception&gt; e(new Exception( ExceptionType::kConferenceNotSupported, msg.at(1)-&gt;get_string())); on_failure(std::move(e)); &#125; &#125; else &#123; if (on_failure) &#123; std::unique_ptr&lt;Exception&gt; e(new Exception( ExceptionType::kConferenceInvalidParam, "Ack for initializing message is not expected.")); on_failure(std::move(e)); &#125; return; &#125; &#125;, on_failure);&#125; 12345678../src/talk/owt/sdk/base/PeerConnectionChannel.ccvoid PeerConnectionChannel::AddTransceiver( cricket::MediaType media_type, const webrtc::RtpTransceiverInit&amp; init) &#123; peer_connection_-&gt;AddTransceiver(media_type, init);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110.../src/third_party/webrtc/pc/peer_connection.ccRTCErrorOr&lt;rtc::scoped_refptr&lt;RtpTransceiverInterface&gt;&gt;PeerConnection::AddTransceiver( cricket::MediaType media_type, rtc::scoped_refptr&lt;MediaStreamTrackInterface&gt; track, const RtpTransceiverInit&amp; init, bool update_negotiation_needed) &#123; RTC_DCHECK_RUN_ON(signaling_thread()); if (!ConfiguredForMedia()) &#123; LOG_AND_RETURN_ERROR(RTCErrorType::UNSUPPORTED_OPERATION, "Not configured for media"); &#125; RTC_DCHECK((media_type == cricket::MEDIA_TYPE_AUDIO || media_type == cricket::MEDIA_TYPE_VIDEO)); if (track) &#123; RTC_DCHECK_EQ(media_type, (track-&gt;kind() == MediaStreamTrackInterface::kAudioKind ? cricket::MEDIA_TYPE_AUDIO : cricket::MEDIA_TYPE_VIDEO)); &#125; RTC_HISTOGRAM_COUNTS_LINEAR(kSimulcastNumberOfEncodings, init.send_encodings.size(), 0, 7, 8); size_t num_rids = absl::c_count_if(init.send_encodings, [](const RtpEncodingParameters&amp; encoding) &#123; return !encoding.rid.empty(); &#125;); if (num_rids &gt; 0 &amp;&amp; num_rids != init.send_encodings.size()) &#123; LOG_AND_RETURN_ERROR( RTCErrorType::INVALID_PARAMETER, "RIDs must be provided for either all or none of the send encodings."); &#125; if (num_rids &gt; 0 &amp;&amp; absl::c_any_of(init.send_encodings, [](const RtpEncodingParameters&amp; encoding) &#123; return !IsLegalRsidName(encoding.rid); &#125;)) &#123; LOG_AND_RETURN_ERROR(RTCErrorType::INVALID_PARAMETER, "Invalid RID value provided."); &#125; if (absl::c_any_of(init.send_encodings, [](const RtpEncodingParameters&amp; encoding) &#123; return encoding.ssrc.has_value(); &#125;)) &#123; LOG_AND_RETURN_ERROR( RTCErrorType::UNSUPPORTED_PARAMETER, "Attempted to set an unimplemented parameter of RtpParameters."); &#125; RtpParameters parameters; parameters.encodings = init.send_encodings; // Encodings are dropped from the tail if too many are provided. size_t max_simulcast_streams = media_type == cricket::MEDIA_TYPE_VIDEO ? kMaxSimulcastStreams : 1u; if (parameters.encodings.size() &gt; max_simulcast_streams) &#123; parameters.encodings.erase( parameters.encodings.begin() + max_simulcast_streams, parameters.encodings.end()); &#125; // Single RID should be removed. if (parameters.encodings.size() == 1 &amp;&amp; !parameters.encodings[0].rid.empty()) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Removing RID: " &lt;&lt; parameters.encodings[0].rid &lt;&lt; "."; parameters.encodings[0].rid.clear(); &#125; // If RIDs were not provided, they are generated for simulcast scenario. if (parameters.encodings.size() &gt; 1 &amp;&amp; num_rids == 0) &#123; rtc::UniqueStringGenerator rid_generator; for (RtpEncodingParameters&amp; encoding : parameters.encodings) &#123; encoding.rid = rid_generator(); &#125; &#125; if (UnimplementedRtpParameterHasValue(parameters)) &#123; LOG_AND_RETURN_ERROR( RTCErrorType::UNSUPPORTED_PARAMETER, "Attempted to set an unimplemented parameter of RtpParameters."); &#125; auto result = cricket::CheckRtpParametersValues(parameters); if (!result.ok()) &#123; LOG_AND_RETURN_ERROR(result.type(), result.message()); &#125; RTC_LOG(LS_INFO) &lt;&lt; "Adding " &lt;&lt; cricket::MediaTypeToString(media_type) &lt;&lt; " transceiver in response to a call to AddTransceiver."; // Set the sender ID equal to the track ID if the track is specified unless // that sender ID is already in use. std::string sender_id = (track &amp;&amp; !rtp_manager()-&gt;FindSenderById(track-&gt;id()) ? track-&gt;id() : rtc::CreateRandomUuid()); auto sender = rtp_manager()-&gt;CreateSender( media_type, sender_id, track, init.stream_ids, parameters.encodings); auto receiver = rtp_manager()-&gt;CreateReceiver(media_type, rtc::CreateRandomUuid()); auto transceiver = rtp_manager()-&gt;CreateAndAddTransceiver(sender, receiver); transceiver-&gt;internal()-&gt;set_direction(init.direction); if (update_negotiation_needed) &#123; sdp_handler_-&gt;UpdateNegotiationNeeded(); &#125; return rtc::scoped_refptr&lt;RtpTransceiverInterface&gt;(transceiver);&#125; ä»Ž mediastream èŽ·å– tracks çš„ä¿¡æ¯ï¼Œaudio &amp; video æž„é€ publish message, é€šè¿‡ signaling_channel_ å‘é€åˆ° OWT serverã€‚ publishçš„è¿‡ç¨‹æœ€ç»ˆè¿˜æ˜¯è¿›åˆ°äº† webrtcé‡Œé¢ peer_connectionçš„ AddTransceiveræ–¹æ³•ã€‚AddTransceiver åˆ›å»º transceiver ï¼ŒTransceiverè¡¨ç¤ºçš„æ˜¯æ”¶å‘ç›¸åŒmidçš„receiverå’Œsenderçš„ä¸€ä¸ªç»„åˆä½“ ï¼Œè´Ÿè´£æ”¶å‘åª’ä½“æ•°æ®ï¼Œä»¥Trackä¸ºè½½ä½“ã€‚ offerpublish æ¶ˆæ¯å‘é€æˆåŠŸä¹‹åŽï¼Œå°±æž„é€ offer message , SetLocalDescription åŽé€šè¿‡ signaling_channel_ å‘é€åˆ° OWT serverã€‚ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172../src/talk/owt/sdk/conference/ConferencePeerConnectionChannel.ccvoid ConferencePeerConnectionChannel::CreateOffer() &#123; RTC_LOG(LS_INFO) &lt;&lt; "Create offer."; scoped_refptr&lt;FunctionalCreateSessionDescriptionObserver&gt; observer = FunctionalCreateSessionDescriptionObserver::Create( std::bind(&amp;ConferencePeerConnectionChannel:: OnCreateSessionDescriptionSuccess, this, std::placeholders::_1), std::bind(&amp;ConferencePeerConnectionChannel:: OnCreateSessionDescriptionFailure, this, std::placeholders::_1)); bool rtp_no_mux = webrtc::field_trial::IsEnabled("OWT-IceUnbundle"); auto offer_answer_options = webrtc::PeerConnectionInterface::RTCOfferAnswerOptions(); offer_answer_options.use_rtp_mux = !rtp_no_mux; peer_connection_-&gt;CreateOffer(observer.get(), offer_answer_options);&#125;void ConferencePeerConnectionChannel::OnCreateSessionDescriptionSuccess( webrtc::SessionDescriptionInterface* desc) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Create sdp success."; scoped_refptr&lt;FunctionalSetSessionDescriptionObserver&gt; observer = FunctionalSetSessionDescriptionObserver::Create( std::bind(&amp;ConferencePeerConnectionChannel:: OnSetLocalSessionDescriptionSuccess, this), std::bind(&amp;ConferencePeerConnectionChannel:: OnSetLocalSessionDescriptionFailure, this, std::placeholders::_1)); std::string sdp_string; if (!desc-&gt;ToString(&amp;sdp_string)) &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Error parsing local description."; RTC_DCHECK(false); &#125; std::vector&lt;AudioCodec&gt; audio_codecs; for (auto&amp; audio_enc_param : configuration_.audio) &#123; audio_codecs.push_back(audio_enc_param.codec.name); &#125; sdp_string = SdpUtils::SetPreferAudioCodecs(sdp_string, audio_codecs); std::vector&lt;VideoCodec&gt; video_codecs; for (auto&amp; video_enc_param : configuration_.video) &#123; video_codecs.push_back(video_enc_param.codec.name); &#125; bool is_screen = published_stream_.get() ? (published_stream_-&gt;Source().video == owt::base::VideoSourceInfo::kScreenCast) : (subscribed_stream_.get() ? (subscribed_stream_-&gt;Source().video == owt::base::VideoSourceInfo::kScreenCast) : false); sdp_string = SdpUtils::SetPreferVideoCodecs(sdp_string, video_codecs, is_screen); webrtc::SessionDescriptionInterface* new_desc( webrtc::CreateSessionDescription(desc-&gt;type(), sdp_string, nullptr)); peer_connection_-&gt;SetLocalDescription(observer.get(), new_desc);&#125;void ConferencePeerConnectionChannel::OnSetLocalSessionDescriptionSuccess() &#123; RTC_LOG(LS_INFO) &lt;&lt; "Set local sdp success."; // For conference, it's now OK to set bandwidth ApplyBitrateSettings(); auto desc = LocalDescription(); string sdp; desc-&gt;ToString(&amp;sdp); sio::message::ptr message = sio::object_message::create(); message-&gt;get_map()["id"] = sio::string_message::create(session_id_); sio::message::ptr sdp_message = sio::object_message::create(); sdp_message-&gt;get_map()["type"] = sio::string_message::create(desc-&gt;type()); sdp_message-&gt;get_map()["sdp"] = sio::string_message::create(sdp); message-&gt;get_map()["signaling"] = sdp_message; signaling_channel_-&gt;SendSdp(message, nullptr, nullptr);&#125; 1234567891011121314151617181920../src/talk/owt/sdk/conference/ConferenceSocketSignalingChannel.ccvoid ConferenceSocketSignalingChannel::SendSdp( sio::message::ptr message, std::function&lt;void()&gt; on_success, std::function&lt;void(std::unique_ptr&lt;Exception&gt;)&gt; on_failure) &#123; std::weak_ptr&lt;ConferenceSocketSignalingChannel&gt; weak_this = shared_from_this(); sio::message::list message_list(message); // Add a null message for |to_to_deprecated|. Don't know its meaning. message_list.push(sio::null_message::create()); Emit(kEventNameSignalingMessage, message_list, [weak_this, on_success, on_failure](sio::message::list const&amp; msg) &#123; if (auto that = weak_this.lock()) &#123; that-&gt;OnEmitAck(msg, on_success, on_failure); &#125; &#125;, on_failure);&#125; answerå…ˆçœ‹ä¸‹ ConferenceSocketSignalingChannel channel æ–¹æ³•ä¸­ è¿™æ®µé€»è¾‘ 123456789101112../src/talk/owt/sdk/conference/ConferenceSocketSignalingChannel.ccfor (const std::string&amp; notification_name : &#123;kEventNameStreamMessage, kEventNameTextMessage, kEventNameOnUserPresence, kEventNameOnSignalingMessage, kEventNameOnDrop&#125;) &#123; socket_client_-&gt;socket()-&gt;on( notification_name, sio::socket::event_listener_aux(std::bind( &amp;ConferenceSocketSignalingChannel::OnNotificationFromServer, this, std::placeholders::_1, std::placeholders::_2))); &#125; const std::string kEventNameSignalingMessage = â€œsoacâ€; //only for soac messageconst std::string kEventNameOnSignalingMessage = â€œprogressâ€; å‘é€offer æ˜¯ kEventNameSignalingMessage soac äº‹ä»¶ï¼Œ OWT server æ”¶åˆ° offer ä¹‹åŽï¼Œä¼šé€šè¿‡ progressäº‹ä»¶ è¿”å›ž answerï¼Œ çœ‹ä¸‹ OnNotificationFromServer é€»è¾‘ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108../src/talk/owt/sdk/conference/ConferenceSocketSignalingChannel.ccvoid ConferenceSocketSignalingChannel::OnNotificationFromServer( const std::string&amp; name, sio::message::ptr const&amp; data) &#123; if (name == kEventNameStreamMessage) &#123; RTC_LOG(LS_VERBOSE) &lt;&lt; "Received stream event."; if (data-&gt;get_map()["status"] != nullptr &amp;&amp; data-&gt;get_map()["status"]-&gt;get_flag() == sio::message::flag_string &amp;&amp; data-&gt;get_map()["id"] != nullptr &amp;&amp; data-&gt;get_map()["id"]-&gt;get_flag() == sio::message::flag_string) &#123; std::string stream_status = data-&gt;get_map()["status"]-&gt;get_string(); std::string stream_id = data-&gt;get_map()["id"]-&gt;get_string(); if (stream_status == "add") &#123; auto stream_info = data-&gt;get_map()["data"]; if (stream_info != nullptr &amp;&amp; stream_info-&gt;get_flag() == sio::message::flag_object) &#123; std::lock_guard&lt;std::mutex&gt; lock(observer_mutex_); for (auto it = observers_.begin(); it != observers_.end(); ++it) &#123; (*it)-&gt;OnStreamAdded(stream_info); &#125; &#125; &#125; else if (stream_status == "update") &#123; sio::message::ptr update_message = sio::object_message::create(); update_message-&gt;get_map()["id"] = sio::string_message::create(stream_id); auto stream_update = data-&gt;get_map()["data"]; if (stream_update != nullptr &amp;&amp; stream_update-&gt;get_flag() == sio::message::flag_object) &#123; update_message-&gt;get_map()["event"] = stream_update; &#125; std::lock_guard&lt;std::mutex&gt; lock(observer_mutex_); for (auto it = observers_.begin(); it != observers_.end(); ++it) &#123; (*it)-&gt;OnStreamUpdated(update_message); &#125; &#125; else if (stream_status == "remove") &#123; sio::message::ptr remove_message = sio::object_message::create(); remove_message-&gt;get_map()["id"] = sio::string_message::create(stream_id); std::lock_guard&lt;std::mutex&gt; lock(observer_mutex_); for (auto it = observers_.begin(); it != observers_.end(); ++it) &#123; (*it)-&gt;OnStreamRemoved(remove_message); &#125; &#125; &#125; &#125; else if (name == kEventNameTextMessage) &#123; RTC_LOG(LS_VERBOSE) &lt;&lt; "Received custom message."; std::string from = data-&gt;get_map()["from"]-&gt;get_string(); std::string message = data-&gt;get_map()["message"]-&gt;get_string(); std::string to = "me"; auto target = data-&gt;get_map()["to"]; if (target != nullptr &amp;&amp; target-&gt;get_flag() == sio::message::flag_string) &#123; to = target-&gt;get_string(); &#125; std::lock_guard&lt;std::mutex&gt; lock(observer_mutex_); for (auto it = observers_.begin(); it != observers_.end(); ++it) &#123; (*it)-&gt;OnCustomMessage(from, message, to); &#125; &#125; else if (name == kEventNameOnUserPresence) &#123; RTC_LOG(LS_VERBOSE) &lt;&lt; "Received user join/leave message."; if (data == nullptr || data-&gt;get_flag() != sio::message::flag_object || data-&gt;get_map()["action"] == nullptr || data-&gt;get_map()["action"]-&gt;get_flag() != sio::message::flag_string) &#123; RTC_DCHECK(false); return; &#125; auto participant_action = data-&gt;get_map()["action"]-&gt;get_string(); if (participant_action == "join") &#123; // Get the pariticipant ID from data; auto participant_info = data-&gt;get_map()["data"]; if (participant_info != nullptr &amp;&amp; participant_info-&gt;get_flag() == sio::message::flag_object &amp;&amp; participant_info-&gt;get_map()["id"] != nullptr &amp;&amp; participant_info-&gt;get_map()["id"]-&gt;get_flag() == sio::message::flag_string) &#123; std::lock_guard&lt;std::mutex&gt; lock(observer_mutex_); for (auto it = observers_.begin(); it != observers_.end(); ++it) &#123; (*it)-&gt;OnUserJoined(participant_info); &#125; &#125; &#125; else if (participant_action == "leave") &#123; auto participant_info = data-&gt;get_map()["data"]; if (participant_info != nullptr &amp;&amp; participant_info-&gt;get_flag() == sio::message::flag_string) &#123; std::lock_guard&lt;std::mutex&gt; lock(observer_mutex_); for (auto it = observers_.begin(); it != observers_.end(); ++it) &#123; (*it)-&gt;OnUserLeft(participant_info); &#125; &#125; &#125; else &#123; RTC_DCHECK_NOTREACHED(); &#125; &#125; else if (name == kEventNameOnSignalingMessage) &#123; RTC_LOG(LS_VERBOSE) &lt;&lt; "Received signaling message from server."; std::lock_guard&lt;std::mutex&gt; lock(observer_mutex_); for (auto it = observers_.begin(); it != observers_.end(); ++it) &#123; (*it)-&gt;OnSignalingMessage(data); &#125; &#125; else if (name == kEventNameOnDrop) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Received drop message."; socket_client_-&gt;set_reconnect_attempts(0); std::lock_guard&lt;std::mutex&gt; lock(observer_mutex_); for (auto it = observers_.begin(); it != observers_.end(); ++it) &#123; (*it)-&gt;OnServerDisconnected(); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105.../src/talk/owt/sdk/conference/conferencepeerconnectionchannel.ccvoid ConferencePeerConnectionChannel::OnSignalingMessage( sio::message::ptr message) &#123; if (message == nullptr) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Ignore empty signaling message"; return; &#125; if (message-&gt;get_flag() == sio::message::flag_string) &#123; if (message-&gt;get_string() == "success") &#123; std::weak_ptr&lt;ConferencePeerConnectionChannel&gt; weak_this = shared_from_this(); if (publish_success_callback_) &#123; event_queue_-&gt;PostTask([weak_this] &#123; auto that = weak_this.lock(); std::lock_guard&lt;std::mutex&gt; lock(that-&gt;callback_mutex_); if (!that || !that-&gt;publish_success_callback_) return; that-&gt;publish_success_callback_(that-&gt;GetSessionId()); that-&gt;ResetCallbacks(); &#125;); &#125; else if (subscribe_success_callback_) &#123; bool stream_added = false; &#123; std::lock_guard&lt;std::mutex&gt; lock(sub_stream_added_mutex_); stream_added = sub_stream_added_; sub_server_ready_ = true; if (stream_added) &#123; event_queue_-&gt;PostTask([weak_this] &#123; auto that = weak_this.lock(); std::lock_guard&lt;std::mutex&gt; lock(that-&gt;callback_mutex_); if (!that || !that-&gt;subscribe_success_callback_) return; that-&gt;subscribe_success_callback_(that-&gt;GetSessionId()); that-&gt;ResetCallbacks(); &#125;); sub_server_ready_ = false; sub_stream_added_ = false; &#125; &#125; &#125; return; &#125; else if (message-&gt;get_string() == "failure") &#123; if (!connected_ &amp;&amp; failure_callback_) &#123; std::weak_ptr&lt;ConferencePeerConnectionChannel&gt; weak_this = shared_from_this(); event_queue_-&gt;PostTask([weak_this] &#123; auto that = weak_this.lock(); std::lock_guard&lt;std::mutex&gt; lock(that-&gt;callback_mutex_); if (!that || !that-&gt;failure_callback_) return; std::unique_ptr&lt;Exception&gt; e(new Exception( ExceptionType::kConferenceUnknown, "Server internal error during connection establishment.")); that-&gt;failure_callback_(std::move(e)); that-&gt;ResetCallbacks(); &#125;); &#125; &#125; return; &#125; else if (message-&gt;get_flag() != sio::message::flag_object) &#123; RTC_LOG(LS_WARNING) &lt;&lt; "Ignore invalid signaling message from server."; return; &#125; // Since trickle ICE from server is not supported, we parse the message as // SOAC message, not Canddiate message. if (message-&gt;get_map().find("type") == message-&gt;get_map().end()) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Ignore message without type from server."; return; &#125; if (message-&gt;get_map()["type"]-&gt;get_flag() != sio::message::flag_string || message-&gt;get_map()["sdp"] == nullptr || message-&gt;get_map()["sdp"]-&gt;get_flag() != sio::message::flag_string) &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Invalid signaling message"; return; &#125; const std::string type = message-&gt;get_map()["type"]-&gt;get_string(); RTC_LOG(LS_INFO) &lt;&lt; "On signaling message: " &lt;&lt; type; if (type == "answer") &#123; const std::string sdp = message-&gt;get_map()["sdp"]-&gt;get_string(); SetRemoteDescription(type, sdp); &#125; else &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Ignoring signaling message from server other than answer."; &#125;&#125;void ConferencePeerConnectionChannel::SetRemoteDescription( const std::string&amp; type, const std::string&amp; sdp) &#123; std::unique_ptr&lt;webrtc::SessionDescriptionInterface&gt; desc( webrtc::CreateSessionDescription( "answer", sdp, nullptr)); // TODO(jianjun): change answer to type.toLowerCase. if (!desc) &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Failed to create session description."; return; &#125; scoped_refptr&lt;FunctionalSetRemoteDescriptionObserver&gt; observer = FunctionalSetRemoteDescriptionObserver::Create(std::bind( &amp;ConferencePeerConnectionChannel::OnSetRemoteDescriptionComplete, this, std::placeholders::_1)); peer_connection_-&gt;SetRemoteDescription(std::move(desc), observer);&#125; 123456789101112131415161718.../src/talk/owt/sdk/base/peerconnectionchannel.ccvoid PeerConnectionChannel::OnSetRemoteDescriptionComplete( webrtc::RTCError error) &#123; if (error.ok()) &#123; OnSetRemoteSessionDescriptionSuccess(); &#125; else &#123; OnSetRemoteSessionDescriptionFailure(error.message()); &#125;&#125;void PeerConnectionChannel::OnSetRemoteSessionDescriptionSuccess() &#123; RTC_LOG(LS_INFO) &lt;&lt; "Set remote sdp success."; if (peer_connection_-&gt;remote_description() &amp;&amp; peer_connection_-&gt;remote_description()-&gt;type() == "offer") &#123; CreateAnswer(); &#125;&#125; å¦‚æžœæ”¶åˆ°å¯¹æ–¹å‘çš„offerï¼Œæ‰éœ€è¦åˆ›å»ºanswerï¼Œå¦‚æžœæ˜¯SFUæ¨¡å¼ï¼Œclient éƒ½æ˜¯ç›´æŽ¥è·Ÿ owt server äº¤äº’ï¼Œæ˜¯ä¸éœ€è¦åˆ›å»ºanswerï¼Œå¦‚æžœæ˜¯ MCUæ¨¡å¼ï¼Œå°±éœ€è¦ CreateAnswerã€‚ 12345678910111213141516171819.../src/talk/owt/sdk/conference/conferencepeerconnectionchannel.ccvoid ConferencePeerConnectionChannel::CreateAnswer() &#123; RTC_LOG(LS_INFO) &lt;&lt; "Create answer."; scoped_refptr&lt;FunctionalCreateSessionDescriptionObserver&gt; observer = FunctionalCreateSessionDescriptionObserver::Create( std::bind(&amp;ConferencePeerConnectionChannel:: OnCreateSessionDescriptionSuccess, this, std::placeholders::_1), std::bind(&amp;ConferencePeerConnectionChannel:: OnCreateSessionDescriptionFailure, this, std::placeholders::_1)); bool rtp_no_mux = webrtc::field_trial::IsEnabled("OWT-IceUnbundle"); auto offer_answer_options = webrtc::PeerConnectionInterface::RTCOfferAnswerOptions(); offer_answer_options.use_rtp_mux = !rtp_no_mux; peer_connection_-&gt;CreateAnswer(observer.get(), offer_answer_options);&#125; CreateAnswer å›žè°ƒ è·Ÿ createoffer çš„ å›žè°ƒé€»è¾‘å¤„ç†æ˜¯ä¸€æ ·çš„ OnCreateSessionDescriptionSuccessï¼Œä¸å¤šèµ˜è¿° æœ€åŽä¹Ÿä¼šé€šè¿‡signaling_channel_å‘ç»™owt server subscribe1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 OWTConferenceSubscribeOptions* subOption = [[OWTConferenceSubscribeOptions alloc] init]; subOption.video=[[OWTConferenceVideoSubscriptionConstraints alloc]init]; OWTVideoCodecParameters* h264Codec = [[OWTVideoCodecParameters alloc] init]; h264Codec.name = OWTVideoCodecH264; h264Codec.profile = @"M"; subOption.video.codecs = [NSArray arrayWithObjects:h264Codec, nil]; subOption.audio = [[OWTConferenceAudioSubscriptionConstraints alloc]init];// OWTAudioCodecParameters* pcmCodec = [[OWTAudioCodecParameters alloc] init];// pcmCodec.name = OWTAudioCodecPcma;// subOption.audio.codecs = [NSArray arrayWithObjects:pcmCodec, nil];// subOption.video.bitrateMultiplier = 2.0f; int width = INT_MAX; int height = INT_MAX; for (NSValue* value in appDelegate.mixedStream.capabilities.video.resolutions) &#123; CGSize resolution=[value CGSizeValue]; if (resolution.width == 640 &amp;&amp; resolution.height == 480) &#123; width = resolution.width; height = resolution.height; break; &#125; if (resolution.width &lt; width &amp;&amp; resolution.height != 0) &#123; width = resolution.width; height = resolution.height; &#125; &#125; [[AVAudioSession sharedInstance] overrideOutputAudioPort:AVAudioSessionPortOverrideSpeaker error:nil]; [_conferenceClient subscribe:appDelegate.mixedStream withOptions:subOption onSuccess:^(OWTConferenceSubscription* subscription) &#123; _subscription=subscription; _subscription.delegate=self; _getStatsTimer = [NSTimer timerWithTimeInterval:1.0 target:self selector:@selector(printStats) userInfo:nil repeats:YES]; [[NSRunLoop mainRunLoop] addTimer:_getStatsTimer forMode:NSDefaultRunLoopMode]; dispatch_async(dispatch_get_main_queue(), ^&#123; _remoteStream = appDelegate.mixedStream; NSLog(@"Subscribe stream success."); //[_remoteStream attach:((SFUStreamView*)self.view).remoteVideoView]; UIView&lt;RTCVideoRenderer&gt; *videoView = [_streamView addRemoteRenderer:_remoteStream]; [_remoteStream attach:videoView]; [_streamView.act stopAnimating]; _subscribedMix = YES; &#125;); &#125; onFailure:^(NSError* err) &#123; NSLog(@"Subscribe stream failed. %@", [err localizedDescription]); &#125;]; 12345678910111213141516171819202122232425262728293031323334353637383940414243.../src/talk/owt/sdk/conference/objc/OWTConferenceClient.mm- (void)subscribe:(OWTRemoteStream*)stream withOptions:(OWTConferenceSubscribeOptions*)options onSuccess:(void (^)(OWTConferenceSubscription*))onSuccess onFailure:(void (^)(NSError*))onFailure &#123; RTC_CHECK(stream); auto nativeStreamRefPtr = [stream nativeStream]; std::shared_ptr&lt;owt::base::RemoteStream&gt; nativeStream( std::static_pointer_cast&lt;owt::base::RemoteStream&gt;(nativeStreamRefPtr)); __weak OWTConferenceClient *weakSelf = self; if (options == nil) &#123; _nativeConferenceClient-&gt;Subscribe( nativeStream, [=](std::shared_ptr&lt;owt::conference::ConferenceSubscription&gt; subscription) &#123; OWTConferenceSubscription* sub = [[OWTConferenceSubscription alloc] initWithNativeSubscription:subscription]; [stream setNativeStream:nativeStream]; if (onSuccess != nil) &#123; onSuccess(sub); &#125; &#125;, [=](std::unique_ptr&lt;owt::base::Exception&gt; e) &#123; [weakSelf triggerOnFailure:onFailure withException:(std::move(e))]; &#125;); &#125; else &#123; _nativeConferenceClient-&gt;Subscribe( nativeStream, *[options nativeSubscribeOptions].get(), [=](std::shared_ptr&lt;owt::conference::ConferenceSubscription&gt; subscription) &#123; OWTConferenceSubscription* sub = [[OWTConferenceSubscription alloc] initWithNativeSubscription:subscription]; [stream setNativeStream:nativeStream]; if (onSuccess != nil) &#123; onSuccess(sub); &#125; &#125;, [=](std::unique_ptr&lt;owt::base::Exception&gt; e) &#123; [weakSelf triggerOnFailure:onFailure withException:(std::move(e))]; &#125;); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149.../src/talk/owt/sdk/conference/conferenceclient.ccvoid ConferenceClient::Subscribe( std::shared_ptr&lt;RemoteStream&gt; stream, const SubscribeOptions&amp; options, std::function&lt;void(std::shared_ptr&lt;ConferenceSubscription&gt;)&gt; on_success, std::function&lt;void(std::unique_ptr&lt;Exception&gt;)&gt; on_failure) &#123; if (!CheckSignalingChannelOnline(on_failure)) &#123; return; &#125;#ifdef OWT_ENABLE_QUIC if (stream-&gt;DataEnabled()) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Requesting subscibe of quic stream."; if (web_transport_channel_ &amp;&amp; web_transport_channel_connected_) &#123; std::weak_ptr&lt;ConferenceClient&gt; weak_this = shared_from_this(); web_transport_channel_-&gt;Subscribe( stream, [on_success, weak_this](std::string session_id) &#123; auto that = weak_this.lock(); if (!that) return; if (on_success != nullptr) &#123; // For QUIC stream we use session_id as stream_id for publication. std::shared_ptr&lt;ConferenceSubscription&gt; cp( new ConferenceSubscription(that, session_id, session_id)); &#123; std::lock_guard&lt;std::mutex&gt; lock( that-&gt;quic_subscriptions_mutex_); that-&gt;quic_subscriptions_[session_id] = cp; &#125; // Check if any pending stream for this to be attached. &#123; std::lock_guard&lt;std::mutex&gt; stream_lock( that-&gt;pending_quic_streams_mutex_); if (that-&gt;pending_incoming_streams_.find(session_id) != that-&gt;pending_incoming_streams_.end()) &#123; that-&gt;TriggerOnIncomingStream( session_id, that-&gt;pending_incoming_streams_[session_id]); that-&gt;pending_incoming_streams_.erase(session_id); &#125; &#125; on_success(cp); &#125; &#125;, on_failure); &#125; else &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Cannot subscribe a quic stream without quic client connected."; std::string failure_message( "Subscribing quic stream without quic client connected"); if (on_failure != nullptr) &#123; event_queue_-&gt;PostTask([on_failure, failure_message]() &#123; std::unique_ptr&lt;Exception&gt; e(new Exception( ExceptionType::kConferenceUnknown, failure_message)); on_failure(std::move(e)); &#125;); &#125; &#125; return; &#125;#endif if (!CheckNullPointer((uintptr_t)stream.get(), on_failure)) &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Remote stream cannot be nullptr."; return; &#125; if (added_stream_type_.find(stream-&gt;Id()) == added_stream_type_.end()) &#123; std::string failure_message( "Subscribing an invalid stream. Please check whether this stream is " "removed."); if (on_failure != nullptr) &#123; event_queue_-&gt;PostTask([on_failure, failure_message]() &#123; std::unique_ptr&lt;Exception&gt; e( new Exception(ExceptionType::kConferenceUnknown, failure_message)); on_failure(std::move(e)); &#125;); &#125; return; &#125; if (options.video.disabled &amp;&amp; options.audio.disabled) &#123; std::string failure_message( "Subscribing with both audio and video disabled is not allowed."); if (on_failure != nullptr) &#123; event_queue_-&gt;PostTask([on_failure, failure_message]() &#123; std::unique_ptr&lt;Exception&gt; e( new Exception(ExceptionType::kConferenceUnknown, failure_message)); on_failure(std::move(e)); &#125;); &#125; return; &#125; // Avoid subscribing the same stream twice. &#123; std::lock_guard&lt;std::mutex&gt; lock(subscribe_pcs_mutex_); // Search subscirbe pcs auto it = std::find_if( subscribe_pcs_.begin(), subscribe_pcs_.end(), [&amp;](std::shared_ptr&lt;ConferencePeerConnectionChannel&gt; o) -&gt; bool &#123; return o-&gt;GetSubStreamId() == stream-&gt;Id(); &#125;); if (it != subscribe_pcs_.end()) &#123; std::string failure_message( "The same remote stream has already been subscribed. Subcribe after " "it is unsubscribed"); if (on_failure != nullptr) &#123; event_queue_-&gt;PostTask([on_failure, failure_message]() &#123; std::unique_ptr&lt;Exception&gt; e(new Exception( ExceptionType::kConferenceUnknown, failure_message)); on_failure(std::move(e)); &#125;); &#125; return; &#125; &#125; // Reorder SDP according to perference list. PeerConnectionChannelConfiguration config = GetPeerConnectionChannelConfiguration(); for (auto codec : options.video.codecs) &#123; config.video.push_back(VideoEncodingParameters(codec, 0, false)); &#125; for (auto codec : options.audio.codecs) &#123; config.audio.push_back(AudioEncodingParameters(codec, 0)); &#125; std::shared_ptr&lt;ConferencePeerConnectionChannel&gt; pcc( new ConferencePeerConnectionChannel(config, signaling_channel_, event_queue_)); pcc-&gt;AddObserver(*this); &#123; std::lock_guard&lt;std::mutex&gt; lock(subscribe_pcs_mutex_); subscribe_pcs_.push_back(pcc); &#125; std::weak_ptr&lt;ConferenceClient&gt; weak_this = shared_from_this(); std::string stream_id = stream-&gt;Id(); pcc-&gt;Subscribe( stream, options, [on_success, weak_this, stream_id](std::string session_id) &#123; auto that = weak_this.lock(); if (!that) return; // map current pcc if (on_success != nullptr) &#123; std::shared_ptr&lt;ConferenceSubscription&gt; cp( new ConferenceSubscription(that, session_id, stream_id)); on_success(cp); &#125; &#125;, on_failure);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139.../src/talk/owt/sdk/conference/conferencepeerconnectionchannel.ccvoid ConferencePeerConnectionChannel::Subscribe( std::shared_ptr&lt;RemoteStream&gt; stream, const SubscribeOptions&amp; subscribe_options, std::function&lt;void(std::string)&gt; on_success, std::function&lt;void(std::unique_ptr&lt;Exception&gt;)&gt; on_failure) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Subscribe a remote stream. It has audio? " &lt;&lt; stream-&gt;has_audio_ &lt;&lt; ", has video? " &lt;&lt; stream-&gt;has_video_; if (!SubOptionAllowed(subscribe_options, stream-&gt;Settings(), stream-&gt;Capabilities())) &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Subscribe option mismatch with stream subcription capabilities."; if (on_failure != nullptr) &#123; event_queue_-&gt;PostTask([on_failure]() &#123; std::unique_ptr&lt;Exception&gt; e( new Exception(ExceptionType::kConferenceUnknown, "Unsupported subscribe option.")); on_failure(std::move(e)); &#125;); &#125; return; &#125; if (!CheckNullPointer((uintptr_t)stream.get(), on_failure)) &#123; RTC_LOG(LS_ERROR) &lt;&lt; "Remote stream cannot be nullptr."; return; &#125; if (subscribe_success_callback_) &#123; if (on_failure) &#123; event_queue_-&gt;PostTask([on_failure]() &#123; std::unique_ptr&lt;Exception&gt; e(new Exception( ExceptionType::kConferenceUnknown, "Subscribing this stream.")); on_failure(std::move(e)); &#125;); &#125; &#125; subscribe_success_callback_ = on_success; failure_callback_ = on_failure; int audio_track_count = 0, video_track_count = 0; if (stream-&gt;has_audio_ &amp;&amp; !subscribe_options.audio.disabled) &#123; webrtc::RtpTransceiverInit transceiver_init; transceiver_init.direction = webrtc::RtpTransceiverDirection::kRecvOnly; AddTransceiver(cricket::MediaType::MEDIA_TYPE_AUDIO, transceiver_init); audio_track_count = 1; &#125; if (stream-&gt;has_video_ &amp;&amp; !subscribe_options.video.disabled) &#123; webrtc::RtpTransceiverInit transceiver_init; transceiver_init.direction = webrtc::RtpTransceiverDirection::kRecvOnly; AddTransceiver(cricket::MediaType::MEDIA_TYPE_VIDEO, transceiver_init); video_track_count = 1; &#125; sio::message::ptr sio_options = sio::object_message::create(); sio::message::ptr media_options = sio::object_message::create(); sio::message::ptr tracks_options = sio::array_message::create(); if (audio_track_count &gt; 0) &#123; sio::message::ptr audio_options = sio::object_message::create(); audio_options-&gt;get_map()["type"] = sio::string_message::create("audio"); audio_options-&gt;get_map()["mid"] = sio::string_message::create("0"); audio_options-&gt;get_map()["from"] = sio::string_message::create(stream-&gt;Id()); tracks_options-&gt;get_vector().push_back(audio_options); &#125; if (video_track_count &gt; 0) &#123; sio::message::ptr video_options = sio::object_message::create(); video_options-&gt;get_map()["type"] = sio::string_message::create("video"); if (audio_track_count == 0) &#123; video_options-&gt;get_map()["mid"] = sio::string_message::create("0"); &#125; else &#123; video_options-&gt;get_map()["mid"] = sio::string_message::create("1"); &#125; auto publication_settings = stream-&gt;Settings(); if (subscribe_options.video.rid != "") &#123; for (auto video_setting : publication_settings.video) &#123; if (video_setting.rid == subscribe_options.video.rid) &#123; std::string track_id = video_setting.track_id; video_options-&gt;get_map()["from"] = sio::string_message::create(track_id); break; &#125; &#125; &#125; else &#123; video_options-&gt;get_map()["from"] = sio::string_message::create(stream-&gt;Id()); &#125; sio::message::ptr video_spec = sio::object_message::create(); sio::message::ptr resolution_options = sio::object_message::create(); if (subscribe_options.video.resolution.width != 0 &amp;&amp; subscribe_options.video.resolution.height != 0) &#123; resolution_options-&gt;get_map()["width"] = sio::int_message::create(subscribe_options.video.resolution.width); resolution_options-&gt;get_map()["height"] = sio::int_message::create(subscribe_options.video.resolution.height); video_spec-&gt;get_map()["resolution"] = resolution_options; &#125; // If bitrateMultiplier is not specified, do not include it in video spec. std::string quality_level("x1.0"); if (subscribe_options.video.bitrateMultiplier != 0) &#123; quality_level = "x" + std::to_string(subscribe_options.video.bitrateMultiplier) .substr(0, 3); &#125; if (quality_level != "x1.0") &#123; sio::message::ptr quality_options = sio::string_message::create(quality_level); video_spec-&gt;get_map()["bitrate"] = quality_options; &#125; if (subscribe_options.video.keyFrameInterval != 0) &#123; video_spec-&gt;get_map()["keyFrameInterval"] = sio::int_message::create(subscribe_options.video.keyFrameInterval); &#125; if (subscribe_options.video.frameRate != 0) &#123; video_spec-&gt;get_map()["framerate"] = sio::int_message::create(subscribe_options.video.frameRate); &#125; video_options-&gt;get_map()["parameters"] = video_spec; if (subscribe_options.video.rid != "") &#123; video_options-&gt;get_map()["simulcastRid"] = sio::string_message::create(subscribe_options.video.rid); &#125; tracks_options-&gt;get_vector().push_back(video_options); &#125; media_options-&gt;get_map()["tracks"] = tracks_options; sio_options-&gt;get_map()["media"] = media_options; sio::message::ptr transport_ptr = sio::object_message::create(); transport_ptr-&gt;get_map()["type"] = sio::string_message::create("webrtc"); sio_options-&gt;get_map()["transport"] = transport_ptr; signaling_channel_-&gt;SendInitializationMessage( sio_options, "", stream-&gt;Id(), [this](std::string session_id, std::string transport_id) &#123; // Pre-set the session's ID. SetSessionId(session_id); CreateOffer(); &#125;, on_failure); // TODO: on_failure subscribed_stream_ = stream;&#125; subscribe çš„è¿‡ç¨‹ è·Ÿ publishæœ‰å¾ˆå¤šç±»ä¼¼çš„åœ°æ–¹ï¼ŒAddTransceiver åˆ›å»º sender &amp; receiver æ”¶å‘åª’ä½“æµï¼Œæž„é€ subscribe message é€šè¿‡ signaling_channel_ å‘é€ åˆ° owt serverå‘é€æˆåŠŸä¹‹åŽï¼Œåˆ›å»ºofferã€å‘é€sdpã€setlocalsdp ã€æŽ¥å—owt server çš„answerã€setremotesdp ç­‰ç­‰è·Ÿpublishçš„è¿‡ç¨‹æ˜¯ä¸€æ ·ï¼Œä¸å†èµ˜è¿°ã€‚ signaling channelçœ‹ä¸‹åœ¨ ConferenceSocketSignalingChannel::Connect æ–¹æ³•ä¸­çš„ä¸€æ®µä»£ç  1234567891011121314151617const std::string kEventNameStreamMessage = "stream";const std::string kEventNameTextMessage = "text";const std::string kEventNameOnUserPresence = "participant";const std::string kEventNameOnSignalingMessage = "progress";const std::string kEventNameOnDrop = "drop";for (const std::string&amp; notification_name : &#123;kEventNameStreamMessage, kEventNameTextMessage, kEventNameOnUserPresence, kEventNameOnSignalingMessage, kEventNameOnDrop&#125;) &#123; socket_client_-&gt;socket()-&gt;on( notification_name, sio::socket::event_listener_aux(std::bind( &amp;ConferenceSocketSignalingChannel::OnNotificationFromServer, this, std::placeholders::_1, std::placeholders::_2))); &#125; kEventNameOnSignalingMessage è¿™ä¸ªä¹‹å‰ä»‹ç»è¿‡äº† kEventNameOnUserPresence : æœ‰ç”¨æˆ·åŠ å…¥æˆ–è€…ç¦»å¼€ï¼ˆaction åŒºåˆ†ï¼‰ï¼Œserver é€šè¿‡ participant äº‹ä»¶é€šçŸ¥ clientï¼ŒkEventNameStreamMessage : ç”¨æˆ·å‘å¸ƒæµåŽï¼Œserver é€šè¿‡ stream äº‹ä»¶é€šçŸ¥ clientkEventNameTextMessage : è‡ªå®šä¹‰æ¶ˆæ¯kEventNameOnDrop : server æ–­å¼€è¿žæŽ¥ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107.../src/talk/owt/sdk/conference/conferencesocketsignalingchannel.ccvoid ConferenceSocketSignalingChannel::OnNotificationFromServer( const std::string&amp; name, sio::message::ptr const&amp; data) &#123; if (name == kEventNameStreamMessage) &#123; RTC_LOG(LS_VERBOSE) &lt;&lt; "Received stream event."; if (data-&gt;get_map()["status"] != nullptr &amp;&amp; data-&gt;get_map()["status"]-&gt;get_flag() == sio::message::flag_string &amp;&amp; data-&gt;get_map()["id"] != nullptr &amp;&amp; data-&gt;get_map()["id"]-&gt;get_flag() == sio::message::flag_string) &#123; std::string stream_status = data-&gt;get_map()["status"]-&gt;get_string(); std::string stream_id = data-&gt;get_map()["id"]-&gt;get_string(); if (stream_status == "add") &#123; auto stream_info = data-&gt;get_map()["data"]; if (stream_info != nullptr &amp;&amp; stream_info-&gt;get_flag() == sio::message::flag_object) &#123; std::lock_guard&lt;std::mutex&gt; lock(observer_mutex_); for (auto it = observers_.begin(); it != observers_.end(); ++it) &#123; (*it)-&gt;OnStreamAdded(stream_info); &#125; &#125; &#125; else if (stream_status == "update") &#123; sio::message::ptr update_message = sio::object_message::create(); update_message-&gt;get_map()["id"] = sio::string_message::create(stream_id); auto stream_update = data-&gt;get_map()["data"]; if (stream_update != nullptr &amp;&amp; stream_update-&gt;get_flag() == sio::message::flag_object) &#123; update_message-&gt;get_map()["event"] = stream_update; &#125; std::lock_guard&lt;std::mutex&gt; lock(observer_mutex_); for (auto it = observers_.begin(); it != observers_.end(); ++it) &#123; (*it)-&gt;OnStreamUpdated(update_message); &#125; &#125; else if (stream_status == "remove") &#123; sio::message::ptr remove_message = sio::object_message::create(); remove_message-&gt;get_map()["id"] = sio::string_message::create(stream_id); std::lock_guard&lt;std::mutex&gt; lock(observer_mutex_); for (auto it = observers_.begin(); it != observers_.end(); ++it) &#123; (*it)-&gt;OnStreamRemoved(remove_message); &#125; &#125; &#125; &#125; else if (name == kEventNameTextMessage) &#123; RTC_LOG(LS_VERBOSE) &lt;&lt; "Received custom message."; std::string from = data-&gt;get_map()["from"]-&gt;get_string(); std::string message = data-&gt;get_map()["message"]-&gt;get_string(); std::string to = "me"; auto target = data-&gt;get_map()["to"]; if (target != nullptr &amp;&amp; target-&gt;get_flag() == sio::message::flag_string) &#123; to = target-&gt;get_string(); &#125; std::lock_guard&lt;std::mutex&gt; lock(observer_mutex_); for (auto it = observers_.begin(); it != observers_.end(); ++it) &#123; (*it)-&gt;OnCustomMessage(from, message, to); &#125; &#125; else if (name == kEventNameOnUserPresence) &#123; RTC_LOG(LS_VERBOSE) &lt;&lt; "Received user join/leave message."; if (data == nullptr || data-&gt;get_flag() != sio::message::flag_object || data-&gt;get_map()["action"] == nullptr || data-&gt;get_map()["action"]-&gt;get_flag() != sio::message::flag_string) &#123; RTC_DCHECK(false); return; &#125; auto participant_action = data-&gt;get_map()["action"]-&gt;get_string(); if (participant_action == "join") &#123; // Get the pariticipant ID from data; auto participant_info = data-&gt;get_map()["data"]; if (participant_info != nullptr &amp;&amp; participant_info-&gt;get_flag() == sio::message::flag_object &amp;&amp; participant_info-&gt;get_map()["id"] != nullptr &amp;&amp; participant_info-&gt;get_map()["id"]-&gt;get_flag() == sio::message::flag_string) &#123; std::lock_guard&lt;std::mutex&gt; lock(observer_mutex_); for (auto it = observers_.begin(); it != observers_.end(); ++it) &#123; (*it)-&gt;OnUserJoined(participant_info); &#125; &#125; &#125; else if (participant_action == "leave") &#123; auto participant_info = data-&gt;get_map()["data"]; if (participant_info != nullptr &amp;&amp; participant_info-&gt;get_flag() == sio::message::flag_string) &#123; std::lock_guard&lt;std::mutex&gt; lock(observer_mutex_); for (auto it = observers_.begin(); it != observers_.end(); ++it) &#123; (*it)-&gt;OnUserLeft(participant_info); &#125; &#125; &#125; else &#123; RTC_DCHECK_NOTREACHED(); &#125; &#125; else if (name == kEventNameOnSignalingMessage) &#123; RTC_LOG(LS_VERBOSE) &lt;&lt; "Received signaling message from server."; std::lock_guard&lt;std::mutex&gt; lock(observer_mutex_); for (auto it = observers_.begin(); it != observers_.end(); ++it) &#123; (*it)-&gt;OnSignalingMessage(data); &#125; &#125; else if (name == kEventNameOnDrop) &#123; RTC_LOG(LS_INFO) &lt;&lt; "Received drop message."; socket_client_-&gt;set_reconnect_attempts(0); std::lock_guard&lt;std::mutex&gt; lock(observer_mutex_); for (auto it = observers_.begin(); it != observers_.end(); ++it) &#123; (*it)-&gt;OnServerDisconnected(); &#125; &#125;&#125; observer &amp; delegateå„ç§äº‹ä»¶çš„ä¼ é€’ï¼Œé€šè¿‡ observer &amp; delegate å›žè°ƒçš„æ–¹å¼ ä»Ž c++ åˆ° OC ä»¥conferenceClientä¸¾ä¾‹ 1234567891011121314151617181920212223.../src/talk/owt/sdk/conference/objc/OWTConferenceClient.mm- (void)setDelegate:(id&lt;OWTConferenceClientDelegate&gt;)delegate &#123; if (delegate != nil) &#123; __weak OWTConferenceClient *weakSelf = self; _observer = std::unique_ptr&lt; owt::conference::ConferenceClientObserverObjcImpl, std::function&lt;void(owt::conference::ConferenceClientObserverObjcImpl*)&gt;&gt;( new owt::conference::ConferenceClientObserverObjcImpl(weakSelf, delegate), [=](owt::conference::ConferenceClientObserverObjcImpl* observer) &#123; __strong OWTConferenceClient *strongSelf = weakSelf; if (strongSelf != nil) &#123; strongSelf-&gt;_nativeConferenceClient-&gt;RemoveObserver(*observer); &#125; delete observer; &#125;); _nativeConferenceClient-&gt;AddObserver(*_observer.get()); &#125; else &#123; _observer.reset(); &#125; _delegate = delegate;&#125; é€šè¿‡ ConferenceClientObserverObjcImpl è¿™ä¸ªç±»åŒ…è£…ä¸‹ï¼Œæ‰“é€š oc è·Ÿ c++ é“¾è·¯ã€‚ç±»ä¼¼çš„ç”¨æ³• è¿˜æœ‰ ConferencePublicationObserverObjcImpl ã€ConferenceSubscriptionObserverObjcImplã€ParticipantObserverObjcImpl ä¸ä¸€ä¸€è¯´äº† å†æ¥çœ‹ä¸‹ å„ç§ observer çš„å®šä¹‰ ä»¥åŠ AddObserver &amp; RemoveObserver çš„æ–¹æ³•å£°æ˜Ž 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950.../src/talk/owt/sdk/include/cpp/owt/conference/conferenceclient.hclass OWT_EXPORT ConferenceClientObserver &#123; public: /** @brief Triggers when a stream is added. @param stream The stream which is added. */ virtual void OnStreamAdded( std::shared_ptr&lt;RemoteStream&gt; stream)&#123;&#125; /** @brief Triggers when a mixed stream is added. @param stream The stream which is added. */ virtual void OnStreamAdded( std::shared_ptr&lt;RemoteMixedStream&gt; stream)&#123;&#125; /** @brief Triggers when a message is received. @param message Message received. @param sender_id Sender's ID. @param to "all" if it is a broadcast message. "me" if it is sent only to current conference client. */ virtual void OnMessageReceived(std::string&amp; message, std::string&amp; sender_id, std::string&amp; to)&#123;&#125; /** @brief Triggers when a participant joined conference. @param user The user joined. */ virtual void OnParticipantJoined(std::shared_ptr&lt;Participant&gt;)&#123;&#125; /** @brief Triggers when server is disconnected. */ virtual void OnServerDisconnected()&#123;&#125;&#125;;/// An asynchronous class for app to communicate with a conference in MCU.class OWT_EXPORT ConferenceClient final : ConferenceSocketSignalingChannelObserver, ConferencePeerConnectionChannelObserver ... /// Add an observer for conferenc client. void AddObserver(ConferenceClientObserver&amp; observer); /// Remove an object from conference client. void RemoveObserver(ConferenceClientObserver&amp; observer); ... 12345678910111213141516.../src/talk/owt/sdk/conference/conferencepeerconnectionchannel.hclass ConferencePeerConnectionChannel : public PeerConnectionChannel, public std::enable_shared_from_this&lt;ConferencePeerConnectionChannel&gt; &#123; public: // Add a ConferencePeerConnectionChannel observer so it will be notified when // this object have some events. void AddObserver(ConferencePeerConnectionChannelObserver&amp; observer); // Remove a ConferencePeerConnectionChannel observer. If the observer doesn't // exist, it will do nothing. void RemoveObserver(ConferencePeerConnectionChannelObserver&amp; observer); ...&#125; 1234567891011121314151617181920212223242526272829.../src/talk/owt/sdk/include/cpp/owt/conference/conferenceclient.hclass OWT_EXPORT ConferenceSocketSignalingChannelObserver &#123; public: virtual ~ConferenceSocketSignalingChannelObserver()&#123;&#125; virtual void OnUserJoined(std::shared_ptr&lt;sio::message&gt; user) = 0; virtual void OnUserLeft(std::shared_ptr&lt;sio::message&gt; user) = 0; virtual void OnStreamAdded(std::shared_ptr&lt;sio::message&gt; stream) = 0; virtual void OnStreamRemoved(std::shared_ptr&lt;sio::message&gt; stream) = 0; virtual void OnStreamUpdated(std::shared_ptr&lt;sio::message&gt; stream) = 0; virtual void OnServerDisconnected() = 0; virtual void OnCustomMessage(std::string&amp; from, std::string&amp; message, std::string&amp; to) = 0; virtual void OnSignalingMessage(std::shared_ptr&lt;sio::message&gt; message) = 0; virtual void OnStreamError(std::shared_ptr&lt;sio::message&gt; stream) = 0; // Notify the ID for a published/subscribed stream. virtual void OnStreamId(const std::string&amp; id, const std::string&amp; label) = 0; virtual void OnSubscriptionId(const std::string&amp; subscription_id, const std::string&amp; stream_id) = 0;&#125;;class OWT_EXPORT ConferencePeerConnectionChannelObserver &#123; public: virtual ~ConferencePeerConnectionChannelObserver()&#123;&#125; // Triggered when an unrecoverable error happened. Error may reported by MCU // or detected by client. Currently, only errors from MCU are handled. virtual void OnStreamError( std::shared_ptr&lt;Stream&gt; stream, std::shared_ptr&lt;const Exception&gt; exception) = 0;&#125;;]]></content>
      <categories>
        <category>RTC</category>
      </categories>
      <tags>
        <tag>ios</tag>
        <tag>webrtc</tag>
        <tag>OWT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ffmpegæºç ä¹‹xxå­¦ä¹ ç¬”è®°]]></title>
    <url>%2F2023%2F01%2F16%2Fffmpeg%E6%BA%90%E7%A0%81%E4%B9%8Bxx%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[AVClass12345678910111213AVFormatContext *s;s-&gt;av_class = &amp;av_format_context_class;static const AVClass av_format_context_class = &#123; .class_name = "AVFormatContext", .item_name = format_to_name, .option = avformat_options, .version = LIBAVUTIL_VERSION_INT, .child_next = format_child_next, .child_class_iterate = format_child_class_iterate, .category = AV_CLASS_CATEGORY_MUXER, .get_category = get_category,&#125;; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#define OFFSET(x) offsetof(AVFormatContext,x)static const AVOption avformat_options[] = &#123;&#123;"avioflags", NULL, OFFSET(avio_flags), AV_OPT_TYPE_FLAGS, &#123;.i64 = DEFAULT &#125;, INT_MIN, INT_MAX, D|E, "avioflags"&#125;,&#123;"direct", "reduce buffering", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AVIO_FLAG_DIRECT &#125;, INT_MIN, INT_MAX, D|E, "avioflags"&#125;,&#123;"probesize", "set probing size", OFFSET(probesize), AV_OPT_TYPE_INT64, &#123;.i64 = 5000000 &#125;, 32, INT64_MAX, D&#125;,&#123;"formatprobesize", "number of bytes to probe file format", OFFSET(format_probesize), AV_OPT_TYPE_INT, &#123;.i64 = PROBE_BUF_MAX&#125;, 0, INT_MAX-1, D&#125;,&#123;"packetsize", "set packet size", OFFSET(packet_size), AV_OPT_TYPE_INT, &#123;.i64 = DEFAULT &#125;, 0, INT_MAX, E&#125;,&#123;"fflags", NULL, OFFSET(flags), AV_OPT_TYPE_FLAGS, &#123;.i64 = AVFMT_FLAG_AUTO_BSF &#125;, INT_MIN, INT_MAX, D|E, "fflags"&#125;,&#123;"flush_packets", "reduce the latency by flushing out packets immediately", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AVFMT_FLAG_FLUSH_PACKETS &#125;, INT_MIN, INT_MAX, E, "fflags"&#125;,&#123;"ignidx", "ignore index", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AVFMT_FLAG_IGNIDX &#125;, INT_MIN, INT_MAX, D, "fflags"&#125;,&#123;"genpts", "generate pts", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AVFMT_FLAG_GENPTS &#125;, INT_MIN, INT_MAX, D, "fflags"&#125;,&#123;"nofillin", "do not fill in missing values that can be exactly calculated", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AVFMT_FLAG_NOFILLIN &#125;, INT_MIN, INT_MAX, D, "fflags"&#125;,&#123;"noparse", "disable AVParsers, this needs nofillin too", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AVFMT_FLAG_NOPARSE &#125;, INT_MIN, INT_MAX, D, "fflags"&#125;,&#123;"igndts", "ignore dts", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AVFMT_FLAG_IGNDTS &#125;, INT_MIN, INT_MAX, D, "fflags"&#125;,&#123;"discardcorrupt", "discard corrupted frames", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AVFMT_FLAG_DISCARD_CORRUPT &#125;, INT_MIN, INT_MAX, D, "fflags"&#125;,&#123;"sortdts", "try to interleave outputted packets by dts", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AVFMT_FLAG_SORT_DTS &#125;, INT_MIN, INT_MAX, D, "fflags"&#125;,&#123;"fastseek", "fast but inaccurate seeks", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AVFMT_FLAG_FAST_SEEK &#125;, INT_MIN, INT_MAX, D, "fflags"&#125;,&#123;"nobuffer", "reduce the latency introduced by optional buffering", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AVFMT_FLAG_NOBUFFER &#125;, 0, INT_MAX, D, "fflags"&#125;,&#123;"bitexact", "do not write random/volatile data", 0, AV_OPT_TYPE_CONST, &#123; .i64 = AVFMT_FLAG_BITEXACT &#125;, 0, 0, E, "fflags" &#125;,&#123;"shortest", "stop muxing with the shortest stream", 0, AV_OPT_TYPE_CONST, &#123; .i64 = AVFMT_FLAG_SHORTEST &#125;, 0, 0, E, "fflags" &#125;,&#123;"autobsf", "add needed bsfs automatically", 0, AV_OPT_TYPE_CONST, &#123; .i64 = AVFMT_FLAG_AUTO_BSF &#125;, 0, 0, E, "fflags" &#125;,&#123;"seek2any", "allow seeking to non-keyframes on demuxer level when supported", OFFSET(seek2any), AV_OPT_TYPE_BOOL, &#123;.i64 = 0 &#125;, 0, 1, D&#125;,&#123;"analyzeduration", "specify how many microseconds are analyzed to probe the input", OFFSET(max_analyze_duration), AV_OPT_TYPE_INT64, &#123;.i64 = 0 &#125;, 0, INT64_MAX, D&#125;,&#123;"cryptokey", "decryption key", OFFSET(key), AV_OPT_TYPE_BINARY, &#123;.dbl = 0&#125;, 0, 0, D&#125;,&#123;"indexmem", "max memory used for timestamp index (per stream)", OFFSET(max_index_size), AV_OPT_TYPE_INT, &#123;.i64 = 1&lt;&lt;20 &#125;, 0, INT_MAX, D&#125;,&#123;"rtbufsize", "max memory used for buffering real-time frames", OFFSET(max_picture_buffer), AV_OPT_TYPE_INT, &#123;.i64 = 3041280 &#125;, 0, INT_MAX, D&#125;, /* defaults to 1s of 15fps 352x288 YUYV422 video */&#123;"fdebug", "print specific debug info", OFFSET(debug), AV_OPT_TYPE_FLAGS, &#123;.i64 = DEFAULT &#125;, 0, INT_MAX, E|D, "fdebug"&#125;,&#123;"ts", NULL, 0, AV_OPT_TYPE_CONST, &#123;.i64 = FF_FDEBUG_TS &#125;, INT_MIN, INT_MAX, E|D, "fdebug"&#125;,&#123;"max_delay", "maximum muxing or demuxing delay in microseconds", OFFSET(max_delay), AV_OPT_TYPE_INT, &#123;.i64 = -1 &#125;, -1, INT_MAX, E|D&#125;,&#123;"start_time_realtime", "wall-clock time when stream begins (PTS==0)", OFFSET(start_time_realtime), AV_OPT_TYPE_INT64, &#123;.i64 = AV_NOPTS_VALUE&#125;, INT64_MIN, INT64_MAX, E&#125;,&#123;"fpsprobesize", "number of frames used to probe fps", OFFSET(fps_probe_size), AV_OPT_TYPE_INT, &#123;.i64 = -1&#125;, -1, INT_MAX-1, D&#125;,&#123;"audio_preload", "microseconds by which audio packets should be interleaved earlier", OFFSET(audio_preload), AV_OPT_TYPE_INT, &#123;.i64 = 0&#125;, 0, INT_MAX-1, E&#125;,&#123;"chunk_duration", "microseconds for each chunk", OFFSET(max_chunk_duration), AV_OPT_TYPE_INT, &#123;.i64 = 0&#125;, 0, INT_MAX-1, E&#125;,&#123;"chunk_size", "size in bytes for each chunk", OFFSET(max_chunk_size), AV_OPT_TYPE_INT, &#123;.i64 = 0&#125;, 0, INT_MAX-1, E&#125;,/* this is a crutch for avconv, since it cannot deal with identically named options in different contexts. * to be removed when avconv is fixed */&#123;"f_err_detect", "set error detection flags (deprecated; use err_detect, save via avconv)", OFFSET(error_recognition), AV_OPT_TYPE_FLAGS, &#123;.i64 = AV_EF_CRCCHECK &#125;, INT_MIN, INT_MAX, D, "err_detect"&#125;,&#123;"err_detect", "set error detection flags", OFFSET(error_recognition), AV_OPT_TYPE_FLAGS, &#123;.i64 = AV_EF_CRCCHECK &#125;, INT_MIN, INT_MAX, D, "err_detect"&#125;,&#123;"crccheck", "verify embedded CRCs", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AV_EF_CRCCHECK &#125;, INT_MIN, INT_MAX, D, "err_detect"&#125;,&#123;"bitstream", "detect bitstream specification deviations", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AV_EF_BITSTREAM &#125;, INT_MIN, INT_MAX, D, "err_detect"&#125;,&#123;"buffer", "detect improper bitstream length", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AV_EF_BUFFER &#125;, INT_MIN, INT_MAX, D, "err_detect"&#125;,&#123;"explode", "abort decoding on minor error detection", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AV_EF_EXPLODE &#125;, INT_MIN, INT_MAX, D, "err_detect"&#125;,&#123;"ignore_err", "ignore errors", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AV_EF_IGNORE_ERR &#125;, INT_MIN, INT_MAX, D, "err_detect"&#125;,&#123;"careful", "consider things that violate the spec, are fast to check and have not been seen in the wild as errors", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AV_EF_CAREFUL &#125;, INT_MIN, INT_MAX, D, "err_detect"&#125;,&#123;"compliant", "consider all spec non compliancies as errors", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AV_EF_COMPLIANT | AV_EF_CAREFUL &#125;, INT_MIN, INT_MAX, D, "err_detect"&#125;,&#123;"aggressive", "consider things that a sane encoder shouldn't do as an error", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AV_EF_AGGRESSIVE | AV_EF_COMPLIANT | AV_EF_CAREFUL&#125;, INT_MIN, INT_MAX, D, "err_detect"&#125;,&#123;"use_wallclock_as_timestamps", "use wallclock as timestamps", OFFSET(use_wallclock_as_timestamps), AV_OPT_TYPE_BOOL, &#123;.i64 = 0&#125;, 0, 1, D&#125;,&#123;"skip_initial_bytes", "set number of bytes to skip before reading header and frames", OFFSET(skip_initial_bytes), AV_OPT_TYPE_INT64, &#123;.i64 = 0&#125;, 0, INT64_MAX-1, D&#125;,&#123;"correct_ts_overflow", "correct single timestamp overflows", OFFSET(correct_ts_overflow), AV_OPT_TYPE_BOOL, &#123;.i64 = 1&#125;, 0, 1, D&#125;,&#123;"flush_packets", "enable flushing of the I/O context after each packet", OFFSET(flush_packets), AV_OPT_TYPE_INT, &#123;.i64 = -1&#125;, -1, 1, E&#125;,&#123;"metadata_header_padding", "set number of bytes to be written as padding in a metadata header", OFFSET(metadata_header_padding), AV_OPT_TYPE_INT, &#123;.i64 = -1&#125;, -1, INT_MAX, E&#125;,&#123;"output_ts_offset", "set output timestamp offset", OFFSET(output_ts_offset), AV_OPT_TYPE_DURATION, &#123;.i64 = 0&#125;, -INT64_MAX, INT64_MAX, E&#125;,&#123;"max_interleave_delta", "maximum buffering duration for interleaving", OFFSET(max_interleave_delta), AV_OPT_TYPE_INT64, &#123; .i64 = 10000000 &#125;, 0, INT64_MAX, E &#125;,&#123;"f_strict", "how strictly to follow the standards (deprecated; use strict, save via avconv)", OFFSET(strict_std_compliance), AV_OPT_TYPE_INT, &#123;.i64 = DEFAULT &#125;, INT_MIN, INT_MAX, D|E, "strict"&#125;,&#123;"strict", "how strictly to follow the standards", OFFSET(strict_std_compliance), AV_OPT_TYPE_INT, &#123;.i64 = DEFAULT &#125;, INT_MIN, INT_MAX, D|E, "strict"&#125;,&#123;"very", "strictly conform to a older more strict version of the spec or reference software", 0, AV_OPT_TYPE_CONST, &#123;.i64 = FF_COMPLIANCE_VERY_STRICT &#125;, INT_MIN, INT_MAX, D|E, "strict"&#125;,&#123;"strict", "strictly conform to all the things in the spec no matter what the consequences", 0, AV_OPT_TYPE_CONST, &#123;.i64 = FF_COMPLIANCE_STRICT &#125;, INT_MIN, INT_MAX, D|E, "strict"&#125;,&#123;"normal", NULL, 0, AV_OPT_TYPE_CONST, &#123;.i64 = FF_COMPLIANCE_NORMAL &#125;, INT_MIN, INT_MAX, D|E, "strict"&#125;,&#123;"unofficial", "allow unofficial extensions", 0, AV_OPT_TYPE_CONST, &#123;.i64 = FF_COMPLIANCE_UNOFFICIAL &#125;, INT_MIN, INT_MAX, D|E, "strict"&#125;,&#123;"experimental", "allow non-standardized experimental variants", 0, AV_OPT_TYPE_CONST, &#123;.i64 = FF_COMPLIANCE_EXPERIMENTAL &#125;, INT_MIN, INT_MAX, D|E, "strict"&#125;,&#123;"max_ts_probe", "maximum number of packets to read while waiting for the first timestamp", OFFSET(max_ts_probe), AV_OPT_TYPE_INT, &#123; .i64 = 50 &#125;, 0, INT_MAX, D &#125;,&#123;"avoid_negative_ts", "shift timestamps so they start at 0", OFFSET(avoid_negative_ts), AV_OPT_TYPE_INT, &#123;.i64 = -1&#125;, -1, 2, E, "avoid_negative_ts"&#125;,&#123;"auto", "enabled when required by target format", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AVFMT_AVOID_NEG_TS_AUTO &#125;, INT_MIN, INT_MAX, E, "avoid_negative_ts"&#125;,&#123;"disabled", "do not change timestamps", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AVFMT_AVOID_NEG_TS_DISABLED &#125;, INT_MIN, INT_MAX, E, "avoid_negative_ts"&#125;,&#123;"make_non_negative", "shift timestamps so they are non negative", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AVFMT_AVOID_NEG_TS_MAKE_NON_NEGATIVE &#125;, INT_MIN, INT_MAX, E, "avoid_negative_ts"&#125;,&#123;"make_zero", "shift timestamps so they start at 0", 0, AV_OPT_TYPE_CONST, &#123;.i64 = AVFMT_AVOID_NEG_TS_MAKE_ZERO &#125;, INT_MIN, INT_MAX, E, "avoid_negative_ts"&#125;,&#123;"dump_separator", "set information dump field separator", OFFSET(dump_separator), AV_OPT_TYPE_STRING, &#123;.str = ", "&#125;, 0, 0, D|E&#125;,&#123;"codec_whitelist", "List of decoders that are allowed to be used", OFFSET(codec_whitelist), AV_OPT_TYPE_STRING, &#123; .str = NULL &#125;, 0, 0, D &#125;,&#123;"format_whitelist", "List of demuxers that are allowed to be used", OFFSET(format_whitelist), AV_OPT_TYPE_STRING, &#123; .str = NULL &#125;, 0, 0, D &#125;,&#123;"protocol_whitelist", "List of protocols that are allowed to be used", OFFSET(protocol_whitelist), AV_OPT_TYPE_STRING, &#123; .str = NULL &#125;, 0, 0, D &#125;,&#123;"protocol_blacklist", "List of protocols that are not allowed to be used", OFFSET(protocol_blacklist), AV_OPT_TYPE_STRING, &#123; .str = NULL &#125;, 0, 0, D &#125;,&#123;"max_streams", "maximum number of streams", OFFSET(max_streams), AV_OPT_TYPE_INT, &#123; .i64 = 1000 &#125;, 0, INT_MAX, D &#125;,&#123;"skip_estimate_duration_from_pts", "skip duration calculation in estimate_timings_from_pts", OFFSET(skip_estimate_duration_from_pts), AV_OPT_TYPE_BOOL, &#123;.i64 = 0&#125;, 0, 1, D&#125;,&#123;"max_probe_packets", "Maximum number of packets to probe a codec", OFFSET(max_probe_packets), AV_OPT_TYPE_INT, &#123; .i64 = 2500 &#125;, 0, INT_MAX, D &#125;,&#123;NULL&#125;,&#125;; 12int avformat_open_input(AVFormatContext **ps, const char *filename, const AVInputFormat *fmt, AVDictionary **options) ä»¥AVFormatContextæ¥åˆ†æžï¼Œav_format_context_class.option æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŸºæœ¬å¯¹åº”ç€ AVFormatContext å†…éƒ¨æˆå‘˜ã€‚option é€šè¿‡offsetå® æ¥æ‰¾åˆ°å¯¹åº”çš„æˆå‘˜çš„åç§»ä½ç½®ã€‚åœ¨avformat_open_inputæ–¹æ³•ä¸­ï¼Œä¼šéåŽ†å¤–éƒ¨ä¼ å…¥çš„optionså‚æ•°ï¼Œå¯¹AVFormatContextå®žä¾‹è¿›è¡Œå±žæ€§æˆå‘˜èµ‹å€¼ã€‚ ç±»ä¼¼çš„è¿™ç§ç”¨æ³• åœ¨ffmpegä¸­å¾ˆå¸¸è§ï¼Œæ¯”å¦‚ AVIOContextã€URLContextã€AVCodecContext â€¦ priv_data123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139typedef struct URLContext &#123; const AVClass *av_class; /**&lt; information for av_log(). Set by url_open(). */ const struct URLProtocol *prot; void *priv_data; char *filename; /**&lt; specified URL */ int flags; int max_packet_size; /**&lt; if non zero, the stream is packetized with this max packet size */ int is_streamed; /**&lt; true if streamed (no seek possible), default = false */ int is_connected; AVIOInterruptCB interrupt_callback; int64_t rw_timeout; /**&lt; maximum time to wait for (network) read/write operation completion, in mcs */ const char *protocol_whitelist; const char *protocol_blacklist; int min_packet_size; /**&lt; if non zero, the stream is packetized with this min packet size */&#125; URLContext;const URLProtocol ff_https_protocol = &#123; .name = "https", .url_open2 = http_open, .url_read = http_read, .url_write = http_write, .url_seek = http_seek, .url_close = http_close, .url_get_file_handle = http_get_file_handle, .url_get_short_seek = http_get_short_seek, .url_shutdown = http_shutdown, .priv_data_size = sizeof(HTTPContext), .priv_data_class = &amp;https_context_class, .flags = URL_PROTOCOL_FLAG_NETWORK, .default_whitelist = "http,https,tls,rtp,tcp,udp,crypto,httpproxy"&#125;;#define HTTP_CLASS(flavor) \static const AVClass flavor ## _context_class = &#123; \ .class_name = # flavor, \ .item_name = av_default_item_name, \ .option = options, \ .version = LIBAVUTIL_VERSION_INT, \&#125;#if CONFIG_HTTP_PROTOCOLHTTP_CLASS(http);typedef struct HTTPContext &#123; const AVClass *class; URLContext *hd; unsigned char buffer[BUFFER_SIZE], *buf_ptr, *buf_end; int line_count; int http_code; /* Used if "Transfer-Encoding: chunked" otherwise -1. */ uint64_t chunksize; int chunkend; uint64_t off, end_off, filesize; char *uri; char *location; HTTPAuthState auth_state; HTTPAuthState proxy_auth_state; char *http_proxy; char *headers; char *mime_type; char *http_version; char *user_agent; char *referer; char *content_type; /* Set if the server correctly handles Connection: close and will close * the connection after feeding us the content. */ int willclose; int seekable; /**&lt; Control seekability, 0 = disable, 1 = enable, -1 = probe. */ int chunked_post; /* A flag which indicates if the end of chunked encoding has been sent. */ int end_chunked_post; /* A flag which indicates we have finished to read POST reply. */ int end_header; /* A flag which indicates if we use persistent connections. */ int multiple_requests; uint8_t *post_data; int post_datalen; int is_akamai; int is_mediagateway; char *cookies; ///&lt; holds newline (\n) delimited Set-Cookie header field values (without the "Set-Cookie: " field name) /* A dictionary containing cookies keyed by cookie name */ AVDictionary *cookie_dict; int icy; /* how much data was read since the last ICY metadata packet */ uint64_t icy_data_read; /* after how many bytes of read data a new metadata packet will be found */ uint64_t icy_metaint; char *icy_metadata_headers; char *icy_metadata_packet; AVDictionary *metadata;#if CONFIG_ZLIB int compressed; z_stream inflate_stream; uint8_t *inflate_buffer;#endif /* CONFIG_ZLIB */ AVDictionary *chained_options; /* -1 = try to send if applicable, 0 = always disabled, 1 = always enabled */ int send_expect_100; char *method; int reconnect; int reconnect_at_eof; int reconnect_on_network_error; int reconnect_streamed; int reconnect_delay_max; char *reconnect_on_http_error; int listen; char *resource; int reply_code; int is_multi_client; HandshakeState handshake_step; int is_connected_server; int short_seek_size; int64_t expires; char *new_location; AVDictionary *redirect_cache; uint64_t filesize_from_content_range;&#125; HTTPContext;static int url_alloc_for_protocol(URLContext **puc, const URLProtocol *up, const char *filename, int flags, const AVIOInterruptCB *int_cb) &#123;...if (up-&gt;priv_data_size) &#123; uc-&gt;priv_data = av_mallocz(up-&gt;priv_data_size); if (!uc-&gt;priv_data) &#123; err = AVERROR(ENOMEM); goto fail; &#125; if (up-&gt;priv_data_class) &#123; char *start; *(const AVClass **)uc-&gt;priv_data = up-&gt;priv_data_class; av_opt_set_defaults(uc-&gt;priv_data);...&#125; ä»¥ URLContext æ¥åˆ†æžï¼Œåœ¨ url_alloc_for_protocol æ–¹æ³•ä¸­ï¼ŒURLContext.priv_data èµ‹å€¼çš„å…¶å®žå°±æ˜¯ å¯¹ç”¨çš„ URLProtocolçš„ priv_data_classå®žä¾‹ï¼Œä»¥http-protocolæ¥ä¸¾ä¾‹ï¼ŒURLContext.priv_data å°±æ˜¯ httpcontextï¼Œ è€Œ httpcontext ä¹Ÿç¬¦åˆä¸Šé¢avclassé‚£ä¸€å¥—ï¼Œé€šè¿‡optionå¯¹ httpcontextå®žä¾‹çš„æˆå‘˜å˜é‡èµ‹å€¼ã€‚ è¿™é‡Œæœ‰ä¸ªé—®é¢˜ï¼ŸURLContext æŒæœ‰å¯¹åº”çš„ protï¼Œä¸ºä»€ä¹ˆè¿˜è¦ å¼„ä¸€ä¸ª priv_dataå‘¢ï¼Ÿ protocolé‡Œé¢æœ‰priv_data_class ã€priv_data_sizeï¼Œä¹Ÿå¯ä»¥æžä¸€ä¸ª priv_dataï¼ŒURLContextç”¨è¿‡ protæ¥è®¿é—®priv_dataå°±å¥½äº†ã€‚ ç±»ä¼¼çš„ç”¨æ³•åœ¨ffmpegä¸­ ä¹Ÿæœ‰å¾ˆå¤šï¼Œæ¯”å¦‚AVFormatContextï¼ŒAVFormatContext.priv_dataæ˜¯å¤„ç† å°è£…è§£å°è£…çš„ä¸Šä¸‹æ–‡ï¼Œmp4æ ¼å¼å¯¹åº”çš„å°±æ˜¯MOVContext. æ¯”å¦‚ mp4æ ¼å¼çš„AVStream,AVStream.priv_dataæ˜¯ MOVStreamContext 123456789101112typedef struct AVFormatContext &#123; ... /** * Format private data. This is an AVOptions-enabled struct * if and only if iformat/oformat.priv_class is not NULL. * * - muxing: set by avformat_write_header() * - demuxing: set by avformat_open_input() */ void *priv_data; ...&#125; internalåœ¨ libavformat/internal.h æ–‡ä»¶ä¸­ï¼Œ FFFormatContext &amp; FFStream å®šä¹‰å¦‚ä¸‹ï¼š 12345678910111213141516171819typedef struct FFFormatContext &#123; /** * The public context. */ AVFormatContext pub; ...&#125;typedef struct FFStream &#123; /** * The public context. */ AVStream pub; ...&#125; AVFormatContext &amp; AVStream éƒ½æ˜¯ä½œä¸ºç¬¬ä¸€ä¸ªæˆå‘˜å­˜åœ¨äºŽFFFormatContext &amp; FFStream ç»“æž„ä½“ä¸­ã€‚ 123456789101112131415161718192021222324252627AVFormatContext *avformat_alloc_context(void)&#123; FFFormatContext *const si = av_mallocz(sizeof(*si)); AVFormatContext *s; if (!si) return NULL; s = &amp;si-&gt;pub; ...&#125;AVStream *avformat_new_stream(AVFormatContext *s, const AVCodec *c)&#123; FFStream *sti; sti = av_mallocz(sizeof(*sti)); AVStream *st; st = &amp;sti-&gt;pub; ...&#125; åˆå§‹åŒ–é€»è¾‘éƒ½æ˜¯é€šè¿‡åˆ›å»º FFFormatContext &amp; FFStream å®žä¾‹ï¼Œç„¶åŽå–æˆå‘˜pub 1234567891011121314static av_always_inline FFFormatContext *ffformatcontext(AVFormatContext *s)&#123; return (FFFormatContext*)s;&#125;static av_always_inline FFStream *ffstream(AVStream *st)&#123; return (FFStream*)st;&#125;static av_always_inline const FFStream *cffstream(const AVStream *st)&#123; return (FFStream*)st;&#125; av_always_inline æ˜¯ç¼–è¯‘å™¨ä¼˜åŒ–ï¼Œå¼ºåˆ¶å†…æ•› ç”±äºŽ AVFormatContext &amp; AVStream ä½œä¸ºç¬¬ä¸€ä¸ªæˆå‘˜ï¼Œæ‰€ä»¥äºŒè€…å¯ä»¥è·ŸFFFormatContext &amp; FFStream åšå¼ºåˆ¶ç±»åž‹è½¬æ¢ä»Žå®šä¹‰ä¸Šçœ‹ï¼Œ å¥½åƒAVFormatContext &amp; AVStream æ˜¯åº”è¯¥ä½œä¸ºinternalï¼Œä½†æ˜¯å®žé™…ç”¨æ³•ä¸Šï¼ŒFFFormatContext &amp; FFStreamæ‰æ˜¯ä½œä¸ºinternal æ¥è¾…åŠ© AVFormatContext &amp; AVStreamå­˜å‚¨ç›¸å…³ä¿¡æ¯ FFIOContext -&gt; AVIOContext , FFCodec -&gt; AVCodec ä¹Ÿæ˜¯è¿™ç§å½¢å¼ ffmepgä¸­ä¹Ÿä¸æ˜¯ æ‰€æœ‰çš„internal éƒ½æ˜¯è¿™ç§ç”¨æ³•ï¼Œ AVCodecInternalã€AVFilterInternal å°±æ˜¯ å¸¸è§„çš„ ä½œä¸º AVCodecContext &amp; AVFilterContext çš„ internal æˆå‘˜å­˜åœ¨çš„ ä¸ªäººç›®å‰ä½¿ç”¨çš„ffmepg æ˜¯ 5.xçš„versionï¼Œæ—©æœŸ4.xçš„æ—¶å€™ï¼Œavformat &amp; avstream ä¹Ÿæ˜¯ç±»ä¼¼ codec &amp; filter è¿™æ ·å¸¸è§„çš„ç”¨æ³•]]></content>
      <categories>
        <category>ffmepg</category>
      </categories>
      <tags>
        <tag>ffmepg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ffmepgæºç ä¹‹httpå­¦ä¹ ç¬”è®°]]></title>
    <url>%2F2022%2F12%2F22%2Fffmepg%E6%BA%90%E7%A0%81%E4%B9%8Bhttp%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[respectè‡´æ•¬é›·ç¥ž startä»Ž AVFormatContext ï¼ˆè§£å°è£…ç»“æž„ä½“ï¼‰ å…¥å£å¼€å§‹å§ â€¦ 123456789101112131415161718192021222324252627282930libavformat/options.cAVFormatContext *avformat_alloc_context(void)&#123; FFFormatContext *const si = av_mallocz(sizeof(*si)); AVFormatContext *s; if (!si) return NULL; s = &amp;si-&gt;pub; s-&gt;av_class = &amp;av_format_context_class; /// ioå…¥å£ s-&gt;io_open = io_open_default; s-&gt;io_close = ff_format_io_close_default; s-&gt;io_close2= io_close2_default; av_opt_set_defaults(s); si-&gt;pkt = av_packet_alloc(); si-&gt;parse_pkt = av_packet_alloc(); if (!si-&gt;pkt || !si-&gt;parse_pkt) &#123; avformat_free_context(s); return NULL; &#125; si-&gt;shortest_end = AV_NOPTS_VALUE; return s;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150libavformat/demux.cint avformat_open_input(AVFormatContext **ps, const char *filename, const AVInputFormat *fmt, AVDictionary **options)&#123; AVFormatContext *s = *ps; FFFormatContext *si; AVDictionary *tmp = NULL; ID3v2ExtraMeta *id3v2_extra_meta = NULL; int ret = 0; if (!s &amp;&amp; !(s = avformat_alloc_context())) return AVERROR(ENOMEM); si = ffformatcontext(s); if (!s-&gt;av_class) &#123; av_log(NULL, AV_LOG_ERROR, "Input context has not been properly allocated by avformat_alloc_context() and is not NULL either\n"); return AVERROR(EINVAL); &#125; if (fmt) s-&gt;iformat = fmt; if (options) av_dict_copy(&amp;tmp, *options, 0); if (s-&gt;pb) // must be before any goto fail s-&gt;flags |= AVFMT_FLAG_CUSTOM_IO; if ((ret = av_opt_set_dict(s, &amp;tmp)) &lt; 0) goto fail; if (!(s-&gt;url = av_strdup(filename ? filename : ""))) &#123; ret = AVERROR(ENOMEM); goto fail; &#125; /// åˆå§‹åŒ–è¾“å…¥æµçš„ä¿¡æ¯ã€‚è¿™é‡Œä¼šåˆå§‹åŒ–AVInputFormat if ((ret = init_input(s, filename, &amp;tmp)) &lt; 0) goto fail; s-&gt;probe_score = ret; if (!s-&gt;protocol_whitelist &amp;&amp; s-&gt;pb &amp;&amp; s-&gt;pb-&gt;protocol_whitelist) &#123; s-&gt;protocol_whitelist = av_strdup(s-&gt;pb-&gt;protocol_whitelist); if (!s-&gt;protocol_whitelist) &#123; ret = AVERROR(ENOMEM); goto fail; &#125; &#125; if (!s-&gt;protocol_blacklist &amp;&amp; s-&gt;pb &amp;&amp; s-&gt;pb-&gt;protocol_blacklist) &#123; s-&gt;protocol_blacklist = av_strdup(s-&gt;pb-&gt;protocol_blacklist); if (!s-&gt;protocol_blacklist) &#123; ret = AVERROR(ENOMEM); goto fail; &#125; &#125; if (s-&gt;format_whitelist &amp;&amp; av_match_list(s-&gt;iformat-&gt;name, s-&gt;format_whitelist, ',') &lt;= 0) &#123; av_log(s, AV_LOG_ERROR, "Format not on whitelist \'%s\'\n", s-&gt;format_whitelist); ret = AVERROR(EINVAL); goto fail; &#125; avio_skip(s-&gt;pb, s-&gt;skip_initial_bytes); /* Check filename in case an image number is expected. */ if (s-&gt;iformat-&gt;flags &amp; AVFMT_NEEDNUMBER) &#123; if (!av_filename_number_test(filename)) &#123; ret = AVERROR(EINVAL); goto fail; &#125; &#125; s-&gt;duration = s-&gt;start_time = AV_NOPTS_VALUE; /* Allocate private data. */ if (s-&gt;iformat-&gt;priv_data_size &gt; 0) &#123; if (!(s-&gt;priv_data = av_mallocz(s-&gt;iformat-&gt;priv_data_size))) &#123; ret = AVERROR(ENOMEM); goto fail; &#125; if (s-&gt;iformat-&gt;priv_class) &#123; *(const AVClass **) s-&gt;priv_data = s-&gt;iformat-&gt;priv_class; av_opt_set_defaults(s-&gt;priv_data); if ((ret = av_opt_set_dict(s-&gt;priv_data, &amp;tmp)) &lt; 0) goto fail; &#125; &#125; /* e.g. AVFMT_NOFILE formats will not have an AVIOContext */ if (s-&gt;pb) ff_id3v2_read_dict(s-&gt;pb, &amp;si-&gt;id3v2_meta, ID3v2_DEFAULT_MAGIC, &amp;id3v2_extra_meta); if (s-&gt;iformat-&gt;read_header) if ((ret = s-&gt;iformat-&gt;read_header(s)) &lt; 0) &#123; if (s-&gt;iformat-&gt;flags_internal &amp; FF_FMT_INIT_CLEANUP) goto close; goto fail; &#125; if (!s-&gt;metadata) &#123; s-&gt;metadata = si-&gt;id3v2_meta; si-&gt;id3v2_meta = NULL; &#125; else if (si-&gt;id3v2_meta) &#123; av_log(s, AV_LOG_WARNING, "Discarding ID3 tags because more suitable tags were found.\n"); av_dict_free(&amp;si-&gt;id3v2_meta); &#125; if (id3v2_extra_meta) &#123; if (!strcmp(s-&gt;iformat-&gt;name, "mp3") || !strcmp(s-&gt;iformat-&gt;name, "aac") || !strcmp(s-&gt;iformat-&gt;name, "tta") || !strcmp(s-&gt;iformat-&gt;name, "wav")) &#123; if ((ret = ff_id3v2_parse_apic(s, id3v2_extra_meta)) &lt; 0) goto close; if ((ret = ff_id3v2_parse_chapters(s, id3v2_extra_meta)) &lt; 0) goto close; if ((ret = ff_id3v2_parse_priv(s, id3v2_extra_meta)) &lt; 0) goto close; &#125; else av_log(s, AV_LOG_DEBUG, "demuxer does not support additional id3 data, skipping\n"); ff_id3v2_free_extra_meta(&amp;id3v2_extra_meta); &#125; if ((ret = avformat_queue_attached_pictures(s)) &lt; 0) goto close; if (s-&gt;pb &amp;&amp; !si-&gt;data_offset) si-&gt;data_offset = avio_tell(s-&gt;pb); si-&gt;raw_packet_buffer_size = 0; update_stream_avctx(s); if (options) &#123; av_dict_free(options); *options = tmp; &#125; *ps = s; return 0;close: if (s-&gt;iformat-&gt;read_close) s-&gt;iformat-&gt;read_close(s);fail: ff_id3v2_free_extra_meta(&amp;id3v2_extra_meta); av_dict_free(&amp;tmp); if (s-&gt;pb &amp;&amp; !(s-&gt;flags &amp; AVFMT_FLAG_CUSTOM_IO)) avio_closep(&amp;s-&gt;pb); avformat_free_context(s); *ps = NULL; return ret;&#125; 1234567891011121314151617181920212223242526272829303132333435363738libavformat/demux.cstatic int init_input(AVFormatContext *s, const char *filename, AVDictionary **options)&#123; int ret; AVProbeData pd = &#123; filename, NULL, 0 &#125;; int score = AVPROBE_SCORE_RETRY; ///åˆå§‹åŒ–çš„è¿‡ç¨‹ s-&gt;pb è¿˜æ²¡åˆ›å»ºå¥½ if (s-&gt;pb) &#123; s-&gt;flags |= AVFMT_FLAG_CUSTOM_IO; if (!s-&gt;iformat) return av_probe_input_buffer2(s-&gt;pb, &amp;s-&gt;iformat, filename, s, 0, s-&gt;format_probesize); else if (s-&gt;iformat-&gt;flags &amp; AVFMT_NOFILE) av_log(s, AV_LOG_WARNING, "Custom AVIOContext makes no sense and " "will be ignored with AVFMT_NOFILE format.\n"); return 0; &#125; /* Guess file format. */ // av_probe_input_format2 é¦–æ¬¡åˆ¤æ–­inputformatæ ¼å¼ iformatï¼Œè¿™ä¸€æ­¥é€šå¸¸åˆ¤æ–­ä¸å‡ºæ¥ if ((s-&gt;iformat &amp;&amp; s-&gt;iformat-&gt;flags &amp; AVFMT_NOFILE) || (!s-&gt;iformat &amp;&amp; (s-&gt;iformat = av_probe_input_format2(&amp;pd, 0, &amp;score)))) return score; /// io_open å°±æ˜¯å‰é¢èµ‹å€¼çš„å…¥å£å‡½æ•° io_open_default if ((ret = s-&gt;io_open(s, &amp;s-&gt;pb, filename, AVIO_FLAG_READ | s-&gt;avio_flags, options)) &lt; 0) return ret; if (s-&gt;iformat) return 0; // av_probe_input_buffer2å†æ¬¡åˆ¤æ–­inputformatæ ¼å¼ iformatï¼Œé€šè¿‡bufåª’ä½“æµæ•°æ®åˆ¤æ–­ã€‚ return av_probe_input_buffer2(s-&gt;pb, &amp;s-&gt;iformat, filename, s, 0, s-&gt;format_probesize);&#125; 1234567891011121314151617181920libavformat/options.cstatic int io_open_default(AVFormatContext *s, AVIOContext **pb, const char *url, int flags, AVDictionary **options)&#123; int loglevel; if (!strcmp(url, s-&gt;url) || s-&gt;iformat &amp;&amp; !strcmp(s-&gt;iformat-&gt;name, "image2") || s-&gt;oformat &amp;&amp; !strcmp(s-&gt;oformat-&gt;name, "image2") ) &#123; loglevel = AV_LOG_DEBUG; &#125; else loglevel = AV_LOG_INFO; av_log(s, loglevel, "Opening \'%s\' for %s\n", url, flags &amp; AVIO_FLAG_WRITE ? "writing" : "reading"); /// io-open return ffio_open_whitelist(pb, url, flags, &amp;s-&gt;interrupt_callback, options, s-&gt;protocol_whitelist, s-&gt;protocol_blacklist);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188libavformat/aviobuf.cint ffio_open_whitelist(AVIOContext **s, const char *filename, int flags, const AVIOInterruptCB *int_cb, AVDictionary **options, const char *whitelist, const char *blacklist )&#123; URLContext *h; int err; *s = NULL; /// åˆ›å»º URLContext err = ffurl_open_whitelist(&amp;h, filename, flags, int_cb, options, whitelist, blacklist, NULL); if (err &lt; 0) return err; /// åˆ›å»ºAVIOContext èµ‹å€¼ urlcontext err = ffio_fdopen(s, h); if (err &lt; 0) &#123; ffurl_close(h); return err; &#125; return 0;&#125;```clibavformat/avio.cint ffurl_alloc(URLContext **puc, const char *filename, int flags, const AVIOInterruptCB *int_cb)&#123; const URLProtocol *p = NULL; /// æ ¹æ®filename æ‰¾åˆ° http p = url_find_protocol(filename); if (p) /// åˆ›å»ºURLContext å¹¶èµ‹å€¼ URLProtocol return url_alloc_for_protocol(puc, p, filename, flags, int_cb); *puc = NULL; return AVERROR_PROTOCOL_NOT_FOUND;&#125;static int url_alloc_for_protocol(URLContext **puc, const URLProtocol *up, const char *filename, int flags, const AVIOInterruptCB *int_cb)&#123; URLContext *uc; int err;#if CONFIG_NETWORK if (up-&gt;flags &amp; URL_PROTOCOL_FLAG_NETWORK &amp;&amp; !ff_network_init()) return AVERROR(EIO);#endif if ((flags &amp; AVIO_FLAG_READ) &amp;&amp; !up-&gt;url_read) &#123; av_log(NULL, AV_LOG_ERROR, "Impossible to open the '%s' protocol for reading\n", up-&gt;name); return AVERROR(EIO); &#125; if ((flags &amp; AVIO_FLAG_WRITE) &amp;&amp; !up-&gt;url_write) &#123; av_log(NULL, AV_LOG_ERROR, "Impossible to open the '%s' protocol for writing\n", up-&gt;name); return AVERROR(EIO); &#125; /// åˆ›å»º URLContext uc = av_mallocz(sizeof(URLContext) + strlen(filename) + 1); if (!uc) &#123; err = AVERROR(ENOMEM); goto fail; &#125; uc-&gt;av_class = &amp;ffurl_context_class; uc-&gt;filename = (char *)&amp;uc[1]; strcpy(uc-&gt;filename, filename); /// èµ‹å€¼ urlprotocal uc-&gt;prot = up; uc-&gt;flags = flags; uc-&gt;is_streamed = 0; /* default = not streamed */ uc-&gt;max_packet_size = 0; /* default: stream file */ /// httpprotocal è®¾ç½®è¿‡äº† priv_data ä¸º HTTPContext if (up-&gt;priv_data_size) &#123; uc-&gt;priv_data = av_mallocz(up-&gt;priv_data_size); if (!uc-&gt;priv_data) &#123; err = AVERROR(ENOMEM); goto fail; &#125; if (up-&gt;priv_data_class) &#123; char *start; *(const AVClass **)uc-&gt;priv_data = up-&gt;priv_data_class; av_opt_set_defaults(uc-&gt;priv_data); if (av_strstart(uc-&gt;filename, up-&gt;name, (const char**)&amp;start) &amp;&amp; *start == ',') &#123; int ret= 0; char *p= start; char sep= *++p; char *key, *val; p++; if (strcmp(up-&gt;name, "subfile")) ret = AVERROR(EINVAL); while(ret &gt;= 0 &amp;&amp; (key= strchr(p, sep)) &amp;&amp; p&lt;key &amp;&amp; (val = strchr(key+1, sep)))&#123; *val= *key= 0; if (strcmp(p, "start") &amp;&amp; strcmp(p, "end")) &#123; ret = AVERROR_OPTION_NOT_FOUND; &#125; else ret= av_opt_set(uc-&gt;priv_data, p, key+1, 0); if (ret == AVERROR_OPTION_NOT_FOUND) av_log(uc, AV_LOG_ERROR, "Key '%s' not found.\n", p); *val= *key= sep; p= val+1; &#125; if(ret&lt;0 || p!=key)&#123; av_log(uc, AV_LOG_ERROR, "Error parsing options string %s\n", start); av_freep(&amp;uc-&gt;priv_data); av_freep(&amp;uc); err = AVERROR(EINVAL); goto fail; &#125; memmove(start, key+1, strlen(key)); &#125; &#125; &#125; if (int_cb) uc-&gt;interrupt_callback = *int_cb; *puc = uc; return 0;fail: *puc = NULL; if (uc) av_freep(&amp;uc-&gt;priv_data); av_freep(&amp;uc);#if CONFIG_NETWORK if (up-&gt;flags &amp; URL_PROTOCOL_FLAG_NETWORK) ff_network_close();#endif return err;&#125;int ffurl_open_whitelist(URLContext **puc, const char *filename, int flags, const AVIOInterruptCB *int_cb, AVDictionary **options, const char *whitelist, const char* blacklist, URLContext *parent)&#123; AVDictionary *tmp_opts = NULL; AVDictionaryEntry *e; /// åˆ›å»º URLContext int ret = ffurl_alloc(puc, filename, flags, int_cb); if (ret &lt; 0) return ret; if (parent) &#123; ret = av_opt_copy(*puc, parent); if (ret &lt; 0) goto fail; &#125; if (options &amp;&amp; (ret = av_opt_set_dict(*puc, options)) &lt; 0) goto fail; if (options &amp;&amp; (*puc)-&gt;prot-&gt;priv_data_class &amp;&amp; (ret = av_opt_set_dict((*puc)-&gt;priv_data, options)) &lt; 0) goto fail; if (!options) options = &amp;tmp_opts; av_assert0(!whitelist || !(e=av_dict_get(*options, "protocol_whitelist", NULL, 0)) || !strcmp(whitelist, e-&gt;value)); av_assert0(!blacklist || !(e=av_dict_get(*options, "protocol_blacklist", NULL, 0)) || !strcmp(blacklist, e-&gt;value)); if ((ret = av_dict_set(options, "protocol_whitelist", whitelist, 0)) &lt; 0) goto fail; if ((ret = av_dict_set(options, "protocol_blacklist", blacklist, 0)) &lt; 0) goto fail; if ((ret = av_opt_set_dict(*puc, options)) &lt; 0) goto fail; /// å‘èµ·é“¾æŽ¥ ret = ffurl_connect(*puc, options); if (!ret) return 0;fail: ffurl_closep(puc); return ret;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162libavformat/avio.cint ffurl_connect(URLContext *uc, AVDictionary **options)&#123; int err; AVDictionary *tmp_opts = NULL; AVDictionaryEntry *e; if (!options) options = &amp;tmp_opts; // Check that URLContext was initialized correctly and lists are matching if set av_assert0(!(e=av_dict_get(*options, "protocol_whitelist", NULL, 0)) || (uc-&gt;protocol_whitelist &amp;&amp; !strcmp(uc-&gt;protocol_whitelist, e-&gt;value))); av_assert0(!(e=av_dict_get(*options, "protocol_blacklist", NULL, 0)) || (uc-&gt;protocol_blacklist &amp;&amp; !strcmp(uc-&gt;protocol_blacklist, e-&gt;value))); if (uc-&gt;protocol_whitelist &amp;&amp; av_match_list(uc-&gt;prot-&gt;name, uc-&gt;protocol_whitelist, ',') &lt;= 0) &#123; av_log(uc, AV_LOG_ERROR, "Protocol '%s' not on whitelist '%s'!\n", uc-&gt;prot-&gt;name, uc-&gt;protocol_whitelist); return AVERROR(EINVAL); &#125; if (uc-&gt;protocol_blacklist &amp;&amp; av_match_list(uc-&gt;prot-&gt;name, uc-&gt;protocol_blacklist, ',') &gt; 0) &#123; av_log(uc, AV_LOG_ERROR, "Protocol '%s' on blacklist '%s'!\n", uc-&gt;prot-&gt;name, uc-&gt;protocol_blacklist); return AVERROR(EINVAL); &#125; if (!uc-&gt;protocol_whitelist &amp;&amp; uc-&gt;prot-&gt;default_whitelist) &#123; av_log(uc, AV_LOG_DEBUG, "Setting default whitelist '%s'\n", uc-&gt;prot-&gt;default_whitelist); uc-&gt;protocol_whitelist = av_strdup(uc-&gt;prot-&gt;default_whitelist); if (!uc-&gt;protocol_whitelist) &#123; return AVERROR(ENOMEM); &#125; &#125; else if (!uc-&gt;protocol_whitelist) av_log(uc, AV_LOG_DEBUG, "No default whitelist set\n"); // This should be an error once all declare a default whitelist if ((err = av_dict_set(options, "protocol_whitelist", uc-&gt;protocol_whitelist, 0)) &lt; 0) return err; if ((err = av_dict_set(options, "protocol_blacklist", uc-&gt;protocol_blacklist, 0)) &lt; 0) return err; err = /// uc.prot æ˜¯ http url_open2 å¯¹åº”çš„æ˜¯ http_open uc-&gt;prot-&gt;url_open2 ? uc-&gt;prot-&gt;url_open2(uc, uc-&gt;filename, uc-&gt;flags, options) : uc-&gt;prot-&gt;url_open(uc, uc-&gt;filename, uc-&gt;flags); av_dict_set(options, "protocol_whitelist", NULL, 0); av_dict_set(options, "protocol_blacklist", NULL, 0); if (err) return err; uc-&gt;is_connected = 1; /* We must be careful here as ffurl_seek() could be slow, * for example for http */ if ((uc-&gt;flags &amp; AVIO_FLAG_WRITE) || !strcmp(uc-&gt;prot-&gt;name, "file")) if (!uc-&gt;is_streamed &amp;&amp; ffurl_seek(uc, 0, SEEK_SET) &lt; 0) uc-&gt;is_streamed = 1; return 0;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859libavformat/aviobuf.cint ffio_fdopen(AVIOContext **s, URLContext *h)&#123; uint8_t *buffer = NULL; int buffer_size, max_packet_size; max_packet_size = h-&gt;max_packet_size; if (max_packet_size) &#123; buffer_size = max_packet_size; /* no need to bufferize more than one packet */ &#125; else &#123; buffer_size = IO_BUFFER_SIZE; &#125; if (!(h-&gt;flags &amp; AVIO_FLAG_WRITE) &amp;&amp; h-&gt;is_streamed) &#123; if (buffer_size &gt; INT_MAX/2) return AVERROR(EINVAL); buffer_size *= 2; &#125; buffer = av_malloc(buffer_size); if (!buffer) return AVERROR(ENOMEM); /// åˆ›å»º AVIOContext /// s-&gt;opaque = h; *s = avio_alloc_context(buffer, buffer_size, h-&gt;flags &amp; AVIO_FLAG_WRITE, h, (int (*)(void *, uint8_t *, int)) ffurl_read, (int (*)(void *, uint8_t *, int)) ffurl_write, (int64_t (*)(void *, int64_t, int))ffurl_seek); if (!*s) &#123; av_freep(&amp;buffer); return AVERROR(ENOMEM); &#125; (*s)-&gt;protocol_whitelist = av_strdup(h-&gt;protocol_whitelist); if (!(*s)-&gt;protocol_whitelist &amp;&amp; h-&gt;protocol_whitelist) &#123; avio_closep(s); return AVERROR(ENOMEM); &#125; (*s)-&gt;protocol_blacklist = av_strdup(h-&gt;protocol_blacklist); if (!(*s)-&gt;protocol_blacklist &amp;&amp; h-&gt;protocol_blacklist) &#123; avio_closep(s); return AVERROR(ENOMEM); &#125; (*s)-&gt;direct = h-&gt;flags &amp; AVIO_FLAG_DIRECT; (*s)-&gt;seekable = h-&gt;is_streamed ? 0 : AVIO_SEEKABLE_NORMAL; (*s)-&gt;max_packet_size = max_packet_size; (*s)-&gt;min_packet_size = h-&gt;min_packet_size; if(h-&gt;prot) &#123; (*s)-&gt;read_pause = (int (*)(void *, int))h-&gt;prot-&gt;url_read_pause; (*s)-&gt;read_seek = (int64_t (*)(void *, int, int64_t, int))h-&gt;prot-&gt;url_read_seek; if (h-&gt;prot-&gt;url_read_seek) (*s)-&gt;seekable |= AVIO_SEEKABLE_TIME; &#125; ((FFIOContext*)(*s))-&gt;short_seek_get = (int (*)(void *))ffurl_get_short_seek; (*s)-&gt;av_class = &amp;ff_avio_class; return 0;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427libavformat/http.c/// è¿™ä¸ªå°±æ˜¯å¯¹åº”å‰é¢çš„ protocolconst URLProtocol ff_http_protocol = &#123; .name = "http", /// * .url_open2 = http_open, .url_accept = http_accept, .url_handshake = http_handshake, .url_read = http_read, .url_write = http_write, .url_seek = http_seek, .url_close = http_close, .url_get_file_handle = http_get_file_handle, .url_get_short_seek = http_get_short_seek, .url_shutdown = http_shutdown, /// * .priv_data_size = sizeof(HTTPContext), .priv_data_class = &amp;http_context_class, .flags = URL_PROTOCOL_FLAG_NETWORK, .default_whitelist = "http,https,tls,rtp,tcp,udp,crypto,httpproxy,data"&#125;;static int http_open(URLContext *h, const char *uri, int flags, AVDictionary **options)&#123; HTTPContext *s = h-&gt;priv_data; int ret; if( s-&gt;seekable == 1 ) h-&gt;is_streamed = 0; else h-&gt;is_streamed = 1; s-&gt;filesize = UINT64_MAX; s-&gt;location = av_strdup(uri); if (!s-&gt;location) return AVERROR(ENOMEM); s-&gt;uri = av_strdup(uri); if (!s-&gt;uri) return AVERROR(ENOMEM); if (options) av_dict_copy(&amp;s-&gt;chained_options, *options, 0); if (s-&gt;headers) &#123; int len = strlen(s-&gt;headers); if (len &lt; 2 || strcmp("\r\n", s-&gt;headers + len - 2)) &#123; av_log(h, AV_LOG_WARNING, "No trailing CRLF found in HTTP header. Adding it.\n"); ret = av_reallocp(&amp;s-&gt;headers, len + 3); if (ret &lt; 0) goto bail_out; s-&gt;headers[len] = '\r'; s-&gt;headers[len + 1] = '\n'; s-&gt;headers[len + 2] = '\0'; &#125; &#125; if (s-&gt;listen) &#123; return http_listen(h, uri, flags, options); &#125; /// è¿›è¿™é‡Œ ret = http_open_cnx(h, options);bail_out: if (ret &lt; 0) &#123; av_dict_free(&amp;s-&gt;chained_options); av_dict_free(&amp;s-&gt;cookie_dict); av_dict_free(&amp;s-&gt;redirect_cache); av_freep(&amp;s-&gt;new_location); av_freep(&amp;s-&gt;uri); &#125; return ret;&#125;static int http_open_cnx(URLContext *h, AVDictionary **options)&#123; HTTPAuthType cur_auth_type, cur_proxy_auth_type; HTTPContext *s = h-&gt;priv_data; int ret, attempts = 0, redirects = 0; int reconnect_delay = 0; uint64_t off; char *cached;redo: cached = redirect_cache_get(s); if (cached) &#123; av_free(s-&gt;location); s-&gt;location = av_strdup(cached); if (!s-&gt;location) &#123; ret = AVERROR(ENOMEM); goto fail; &#125; goto redo; &#125; av_dict_copy(options, s-&gt;chained_options, 0); cur_auth_type = s-&gt;auth_state.auth_type; cur_proxy_auth_type = s-&gt;auth_state.auth_type; off = s-&gt;off; /// è¿›è¿™é‡Œ å…³é”®æ–¹æ³• ret = http_open_cnx_internal(h, options); if (ret &lt; 0) &#123; if (!http_should_reconnect(s, ret) || reconnect_delay &gt; s-&gt;reconnect_delay_max) goto fail; av_log(h, AV_LOG_WARNING, "Will reconnect at %"PRIu64" in %d second(s).\n", off, reconnect_delay); ret = ff_network_sleep_interruptible(1000U * 1000 * reconnect_delay, &amp;h-&gt;interrupt_callback); if (ret != AVERROR(ETIMEDOUT)) goto fail; reconnect_delay = 1 + 2 * reconnect_delay; /* restore the offset (http_connect resets it) */ s-&gt;off = off; ffurl_closep(&amp;s-&gt;hd); goto redo; &#125; attempts++; if (s-&gt;http_code == 401) &#123; if ((cur_auth_type == HTTP_AUTH_NONE || s-&gt;auth_state.stale) &amp;&amp; s-&gt;auth_state.auth_type != HTTP_AUTH_NONE &amp;&amp; attempts &lt; 4) &#123; ffurl_closep(&amp;s-&gt;hd); goto redo; &#125; else goto fail; &#125; if (s-&gt;http_code == 407) &#123; if ((cur_proxy_auth_type == HTTP_AUTH_NONE || s-&gt;proxy_auth_state.stale) &amp;&amp; s-&gt;proxy_auth_state.auth_type != HTTP_AUTH_NONE &amp;&amp; attempts &lt; 4) &#123; ffurl_closep(&amp;s-&gt;hd); goto redo; &#125; else goto fail; &#125; if ((s-&gt;http_code == 301 || s-&gt;http_code == 302 || s-&gt;http_code == 303 || s-&gt;http_code == 307 || s-&gt;http_code == 308) &amp;&amp; s-&gt;new_location) &#123; /* url moved, get next */ ffurl_closep(&amp;s-&gt;hd); if (redirects++ &gt;= MAX_REDIRECTS) return AVERROR(EIO); if (!s-&gt;expires) &#123; s-&gt;expires = (s-&gt;http_code == 301 || s-&gt;http_code == 308) ? INT64_MAX : -1; &#125; if (s-&gt;expires &gt; time(NULL) &amp;&amp; av_dict_count(s-&gt;redirect_cache) &lt; MAX_CACHED_REDIRECTS) &#123; redirect_cache_set(s, s-&gt;location, s-&gt;new_location, s-&gt;expires); &#125; av_free(s-&gt;location); s-&gt;location = s-&gt;new_location; s-&gt;new_location = NULL; /* Restart the authentication process with the new target, which * might use a different auth mechanism. */ memset(&amp;s-&gt;auth_state, 0, sizeof(s-&gt;auth_state)); attempts = 0; goto redo; &#125; return 0;fail: if (s-&gt;hd) ffurl_closep(&amp;s-&gt;hd); if (ret &lt; 0) return ret; return ff_http_averror(s-&gt;http_code, AVERROR(EIO));&#125;static int http_open_cnx_internal(URLContext *h, AVDictionary **options)&#123; /// lower_proto å…³é”® const char *path, *proxy_path, *lower_proto = "tcp", *local_path; char *env_http_proxy, *env_no_proxy; char *hashmark; char hostname[1024], hoststr[1024], proto[10]; char auth[1024], proxyauth[1024] = ""; char path1[MAX_URL_SIZE], sanitized_path[MAX_URL_SIZE + 1]; char buf[1024], urlbuf[MAX_URL_SIZE]; int port, use_proxy, err = 0; /// å‰é¢å®šä¹‰httpprotocalçš„æ—¶å€™è®¾ç½®è¿‡äº† HTTPContext *s = h-&gt;priv_data; av_url_split(proto, sizeof(proto), auth, sizeof(auth), hostname, sizeof(hostname), &amp;port, path1, sizeof(path1), s-&gt;location); ff_url_join(hoststr, sizeof(hoststr), NULL, NULL, hostname, port, NULL); env_http_proxy = getenv_utf8("http_proxy"); proxy_path = s-&gt;http_proxy ? s-&gt;http_proxy : env_http_proxy; env_no_proxy = getenv_utf8("no_proxy"); use_proxy = !ff_http_match_no_proxy(env_no_proxy, hostname) &amp;&amp; proxy_path &amp;&amp; av_strstart(proxy_path, "http://", NULL); freeenv_utf8(env_no_proxy); /// å¦‚æžœæ˜¯https ä¼šèµ°åˆ° tls (tls_securetransport.c &amp; tls.c) /// tls å†…éƒ¨ æœ€åŽä¹Ÿä¼šèµ°åˆ°tcpçš„ å…ˆç•¥è¿‡ å…ˆç›´æŽ¥çœ‹tcp if (!strcmp(proto, "https")) &#123; lower_proto = "tls"; use_proxy = 0; if (port &lt; 0) port = 443; /* pass http_proxy to underlying protocol */ if (s-&gt;http_proxy) &#123; err = av_dict_set(options, "http_proxy", s-&gt;http_proxy, 0); if (err &lt; 0) goto end; &#125; &#125; if (port &lt; 0) port = 80; hashmark = strchr(path1, '#'); if (hashmark) *hashmark = '\0'; if (path1[0] == '\0') &#123; path = "/"; &#125; else if (path1[0] == '?') &#123; snprintf(sanitized_path, sizeof(sanitized_path), "/%s", path1); path = sanitized_path; &#125; else &#123; path = path1; &#125; local_path = path; if (use_proxy) &#123; /* Reassemble the request URL without auth string - we don't * want to leak the auth to the proxy. */ ff_url_join(urlbuf, sizeof(urlbuf), proto, NULL, hostname, port, "%s", path1); path = urlbuf; av_url_split(NULL, 0, proxyauth, sizeof(proxyauth), hostname, sizeof(hostname), &amp;port, NULL, 0, proxy_path); &#125; /// è¿™é‡Œå…ˆä»¥tcpæ¥åˆ†æž ff_url_join(buf, sizeof(buf), lower_proto, NULL, hostname, port, NULL); if (!s-&gt;hd) &#123; /// s-&gt;hd ä¹Ÿæ˜¯ URLContextï¼Œå‘çŽ°è¿™é‡Œåˆè¿›å…¥äº†ffurl_open_whitelist å¾ªçŽ¯äº† /// buf æ˜¯ tcpäº† ä¸æ˜¯http äº†ï¼Œ å¦åˆ™å°±è·³ä¸å‡ºæ¥äº† /// æ‰€ä»¥ s-&gt;hd çš„ protocal æ˜¯ TCPProtocol err = ffurl_open_whitelist(&amp;s-&gt;hd, buf, AVIO_FLAG_READ_WRITE, &amp;h-&gt;interrupt_callback, options, h-&gt;protocol_whitelist, h-&gt;protocol_blacklist, h); &#125;end: freeenv_utf8(env_http_proxy); return err &lt; 0 ? err : http_connect( h, path, local_path, hoststr, auth, proxyauth);&#125;static int http_connect(URLContext *h, const char *path, const char *local_path, const char *hoststr, const char *auth, const char *proxyauth)&#123; HTTPContext *s = h-&gt;priv_data; int post, err; AVBPrint request; char *authstr = NULL, *proxyauthstr = NULL; uint64_t off = s-&gt;off; const char *method; int send_expect_100 = 0; av_bprint_init_for_buffer(&amp;request, s-&gt;buffer, sizeof(s-&gt;buffer)); /* send http header */ post = h-&gt;flags &amp; AVIO_FLAG_WRITE; if (s-&gt;post_data) &#123; /* force POST method and disable chunked encoding when * custom HTTP post data is set */ post = 1; s-&gt;chunked_post = 0; &#125; if (s-&gt;method) method = s-&gt;method; else method = post ? "POST" : "GET"; authstr = ff_http_auth_create_response(&amp;s-&gt;auth_state, auth, local_path, method); proxyauthstr = ff_http_auth_create_response(&amp;s-&gt;proxy_auth_state, proxyauth, local_path, method); if (post &amp;&amp; !s-&gt;post_data) &#123; if (s-&gt;send_expect_100 != -1) &#123; send_expect_100 = s-&gt;send_expect_100; &#125; else &#123; send_expect_100 = 0; /* The user has supplied authentication but we don't know the auth type, * send Expect: 100-continue to get the 401 response including the * WWW-Authenticate header, or an 100 continue if no auth actually * is needed. */ if (auth &amp;&amp; *auth &amp;&amp; s-&gt;auth_state.auth_type == HTTP_AUTH_NONE &amp;&amp; s-&gt;http_code != 401) send_expect_100 = 1; &#125; &#125; av_bprintf(&amp;request, "%s ", method); bprint_escaped_path(&amp;request, path); av_bprintf(&amp;request, " HTTP/1.1\r\n"); if (post &amp;&amp; s-&gt;chunked_post) av_bprintf(&amp;request, "Transfer-Encoding: chunked\r\n"); /* set default headers if needed */ if (!has_header(s-&gt;headers, "\r\nUser-Agent: ")) av_bprintf(&amp;request, "User-Agent: %s\r\n", s-&gt;user_agent); if (s-&gt;referer) &#123; /* set default headers if needed */ if (!has_header(s-&gt;headers, "\r\nReferer: ")) av_bprintf(&amp;request, "Referer: %s\r\n", s-&gt;referer); &#125; if (!has_header(s-&gt;headers, "\r\nAccept: ")) av_bprintf(&amp;request, "Accept: */*\r\n"); // Note: we send the Range header on purpose, even when we're probing, // since it allows us to detect more reliably if a (non-conforming) // server supports seeking by analysing the reply headers. if (!has_header(s-&gt;headers, "\r\nRange: ") &amp;&amp; !post &amp;&amp; (s-&gt;off &gt; 0 || s-&gt;end_off || s-&gt;seekable != 0)) &#123; av_bprintf(&amp;request, "Range: bytes=%"PRIu64"-", s-&gt;off); if (s-&gt;end_off) av_bprintf(&amp;request, "%"PRId64, s-&gt;end_off - 1); av_bprintf(&amp;request, "\r\n"); &#125; if (send_expect_100 &amp;&amp; !has_header(s-&gt;headers, "\r\nExpect: ")) av_bprintf(&amp;request, "Expect: 100-continue\r\n"); if (!has_header(s-&gt;headers, "\r\nConnection: ")) av_bprintf(&amp;request, "Connection: %s\r\n", s-&gt;multiple_requests ? "keep-alive" : "close"); if (!has_header(s-&gt;headers, "\r\nHost: ")) av_bprintf(&amp;request, "Host: %s\r\n", hoststr); if (!has_header(s-&gt;headers, "\r\nContent-Length: ") &amp;&amp; s-&gt;post_data) av_bprintf(&amp;request, "Content-Length: %d\r\n", s-&gt;post_datalen); if (!has_header(s-&gt;headers, "\r\nContent-Type: ") &amp;&amp; s-&gt;content_type) av_bprintf(&amp;request, "Content-Type: %s\r\n", s-&gt;content_type); if (!has_header(s-&gt;headers, "\r\nCookie: ") &amp;&amp; s-&gt;cookies) &#123; char *cookies = NULL; if (!get_cookies(s, &amp;cookies, path, hoststr) &amp;&amp; cookies) &#123; av_bprintf(&amp;request, "Cookie: %s\r\n", cookies); av_free(cookies); &#125; &#125; if (!has_header(s-&gt;headers, "\r\nIcy-MetaData: ") &amp;&amp; s-&gt;icy) av_bprintf(&amp;request, "Icy-MetaData: 1\r\n"); /* now add in custom headers */ if (s-&gt;headers) av_bprintf(&amp;request, "%s", s-&gt;headers); if (authstr) av_bprintf(&amp;request, "%s", authstr); if (proxyauthstr) av_bprintf(&amp;request, "Proxy-%s", proxyauthstr); av_bprintf(&amp;request, "\r\n"); av_log(h, AV_LOG_DEBUG, "request: %s\n", request.str); if (!av_bprint_is_complete(&amp;request)) &#123; av_log(h, AV_LOG_ERROR, "overlong headers\n"); err = AVERROR(EINVAL); goto done; &#125; /// å†™å…¥æ•°æ® å‘èµ·è¯·æ±‚ if ((err = ffurl_write(s-&gt;hd, request.str, request.len)) &lt; 0) goto done; if (s-&gt;post_data) if ((err = ffurl_write(s-&gt;hd, s-&gt;post_data, s-&gt;post_datalen)) &lt; 0) goto done; /* init input buffer */ s-&gt;buf_ptr = s-&gt;buffer; s-&gt;buf_end = s-&gt;buffer; s-&gt;line_count = 0; s-&gt;off = 0; s-&gt;icy_data_read = 0; s-&gt;filesize = UINT64_MAX; s-&gt;willclose = 0; s-&gt;end_chunked_post = 0; s-&gt;end_header = 0;#if CONFIG_ZLIB s-&gt;compressed = 0;#endif if (post &amp;&amp; !s-&gt;post_data &amp;&amp; !send_expect_100) &#123; /* Pretend that it did work. We didn't read any header yet, since * we've still to send the POST data, but the code calling this * function will check http_code after we return. */ s-&gt;http_code = 200; err = 0; goto done; &#125; /* wait for header */ err = http_read_header(h); if (err &lt; 0) goto done; if (s-&gt;new_location) s-&gt;off = off; err = (off == s-&gt;off) ? 0 : -1;done: av_freep(&amp;authstr); av_freep(&amp;proxyauthstr); return err;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162libavformat/avio.cint ffurl_write(URLContext *h, const unsigned char *buf, int size)&#123; if (!(h-&gt;flags &amp; AVIO_FLAG_WRITE)) return AVERROR(EIO); /* avoid sending too big packets */ if (h-&gt;max_packet_size &amp;&amp; size &gt; h-&gt;max_packet_size) return AVERROR(EIO); /// h-&gt;prot é€šè¿‡å‰é¢çš„åˆ†æž å°±æ˜¯TCPProtocol return retry_transfer_wrapper(h, (unsigned char *)buf, size, size, (int (*)(struct URLContext *, uint8_t *, int)) h-&gt;prot-&gt;url_write);&#125;static inline int retry_transfer_wrapper(URLContext *h, uint8_t *buf, int size, int size_min, int (*transfer_func)(URLContext *h, uint8_t *buf, int size))&#123; int ret, len; int fast_retries = 5; int64_t wait_since = 0; len = 0; while (len &lt; size_min) &#123; if (ff_check_interrupt(&amp;h-&gt;interrupt_callback)) return AVERROR_EXIT; /// å›žè°ƒ ret = transfer_func(h, buf + len, size - len); if (ret == AVERROR(EINTR)) continue; if (h-&gt;flags &amp; AVIO_FLAG_NONBLOCK) return ret; if (ret == AVERROR(EAGAIN)) &#123; ret = 0; if (fast_retries) &#123; fast_retries--; &#125; else &#123; if (h-&gt;rw_timeout) &#123; if (!wait_since) wait_since = av_gettime_relative(); else if (av_gettime_relative() &gt; wait_since + h-&gt;rw_timeout) return AVERROR(EIO); &#125; av_usleep(1000); &#125; &#125; else if (ret == AVERROR_EOF) return (len &gt; 0) ? len : AVERROR_EOF; else if (ret &lt; 0) return ret; if (ret) &#123; fast_retries = FFMAX(fast_retries, 2); wait_since = 0; &#125; len += ret; &#125; return len;&#125; 12345678910111213141516171819202122232425262728293031libavformat/tcp.cconst URLProtocol ff_tcp_protocol = &#123; .name = "tcp", .url_open = tcp_open, .url_accept = tcp_accept, .url_read = tcp_read, .url_write = tcp_write, .url_close = tcp_close, .url_get_file_handle = tcp_get_file_handle, .url_get_short_seek = tcp_get_window_size, .url_shutdown = tcp_shutdown, .priv_data_size = sizeof(TCPContext), .flags = URL_PROTOCOL_FLAG_NETWORK, .priv_data_class = &amp;tcp_class,&#125;;static int tcp_write(URLContext *h, const uint8_t *buf, int size)&#123; TCPContext *s = h-&gt;priv_data; int ret; if (!(h-&gt;flags &amp; AVIO_FLAG_NONBLOCK)) &#123; ret = ff_network_wait_fd_timeout(s-&gt;fd, 1, h-&gt;rw_timeout, &amp;h-&gt;interrupt_callback); if (ret) return ret; &#125; /// socket send ret = send(s-&gt;fd, buf, size, MSG_NOSIGNAL); return ret &lt; 0 ? ff_neterrno() : ret;&#125; æ•´ä½“çš„ä»£ç æµç¨‹å¦‚ä¸Šï¼Œå…³é”®å…¥å£éƒ½åœ¨å¯¹åº”çš„åœ°æ–¹åŠ äº†æ³¨é‡Š class relationavformat åˆå§‹åŒ– æ ¹æ® urlåè®®æ‰¾åˆ° urlprotocolï¼Œ åˆ›å»ºurlcontext &amp; aviocontext ä¸‰è€…çš„å…³ç³»å¦‚ä¸‹ 123avformatcontext.pb = aviocontextaviocontext.opaque = urlcontexturlcontext.prot = urlprotocol urlprotocol privdata æŒ‡å®šä¸º httpcontexthttpcontext å†…éƒ¨æŒæœ‰çš„urlcontext æ ¹æ® tcp æ‰¾åˆ°tcpprotocolhttpconext.hd = urlcontext åŽç»­è¿›å…¥åˆ° tcp å‘é€æ•°æ®çš„æµç¨‹ SSL/TLSä¸Šé¢ä¸ºäº†å¿«é€Ÿå¼„æ¸…æ¥šè°ƒç”¨è¿‡ç¨‹ï¼Œå½“åšhttpå¤„ç†ï¼Œç®€åŒ–äº†tlsè¿™ä¸€å—ï¼Œhttpsæ—©å·²æ™®åŠï¼Œæ‰€ä»¥https è·Ÿ tcp ä¸­é—´æœ‰ä¸€å±‚ ssl/tls ffmpeg å†…éƒ¨å¤„ç†tlsåè®®çš„æœ‰å¥½å‡ ä¸ª gnutls openssl schannel securetransport libtls mbedtlsæ ¹æ®ä¸ç”¨çš„å¹³å°ä¿ç•™å¯¹åº”çš„å“ªä¸€ä¸ªï¼Œæˆ‘çš„è®¾å¤‡æ˜¯macï¼Œå¯¹åº”çš„æ˜¯ securetransport 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208libavformat/tls_securetransport.cconst URLProtocol ff_tls_protocol = &#123; .name = "tls", .url_open2 = tls_open, .url_read = tls_read, .url_write = tls_write, .url_close = tls_close, .url_get_file_handle = tls_get_file_handle, .url_get_short_seek = tls_get_short_seek, .priv_data_size = sizeof(TLSContext), .flags = URL_PROTOCOL_FLAG_NETWORK, .priv_data_class = &amp;tls_class,&#125;;typedef struct TLSContext &#123; const AVClass *class; TLSShared tls_shared; SSLContextRef ssl_context; CFArrayRef ca_array; int lastErr;&#125; TLSContext;libavformat/tls.htypedef struct TLSShared &#123; char *ca_file; int verify; char *cert_file; char *key_file; int listen; char *host; char *http_proxy; char underlying_host[200]; int numerichost; /// tlså†…éƒ¨å°±æ˜¯tcp URLContext *tcp;&#125; TLSShared;static int tls_open(URLContext *h, const char *uri, int flags, AVDictionary **options)&#123; TLSContext *c = h-&gt;priv_data; TLSShared *s = &amp;c-&gt;tls_shared; int ret; /// tcp open if ((ret = ff_tls_open_underlying(s, h, uri, options)) &lt; 0) goto fail; /// sslcontext åˆ›å»ºè¿‡ç¨‹ è§åº•éƒ¨å¼•ç”¨çš„è‹¹æžœæ–‡æ¡£ c-&gt;ssl_context = SSLCreateContext(NULL, s-&gt;listen ? kSSLServerSide : kSSLClientSide, kSSLStreamType); if (!c-&gt;ssl_context) &#123; av_log(h, AV_LOG_ERROR, "Unable to create SSL context\n"); ret = AVERROR(ENOMEM); goto fail; &#125; if (s-&gt;ca_file) &#123; if ((ret = load_ca(h)) &lt; 0) goto fail; &#125; if (s-&gt;ca_file || !s-&gt;verify) CHECK_ERROR(SSLSetSessionOption, c-&gt;ssl_context, kSSLSessionOptionBreakOnServerAuth, true); if (s-&gt;cert_file) if ((ret = load_cert(h)) &lt; 0) goto fail; CHECK_ERROR(SSLSetPeerDomainName, c-&gt;ssl_context, s-&gt;host, strlen(s-&gt;host)); /// io å›žè°ƒ CHECK_ERROR(SSLSetIOFuncs, c-&gt;ssl_context, tls_read_cb, tls_write_cb); CHECK_ERROR(SSLSetConnection, c-&gt;ssl_context, h); while (1) &#123; OSStatus status = SSLHandshake(c-&gt;ssl_context); if (status == errSSLServerAuthCompleted) &#123; SecTrustRef peerTrust; SecTrustResultType trustResult; if (!s-&gt;verify) continue; if (SSLCopyPeerTrust(c-&gt;ssl_context, &amp;peerTrust) != noErr) &#123; ret = AVERROR(ENOMEM); goto fail; &#125; if (SecTrustSetAnchorCertificates(peerTrust, c-&gt;ca_array) != noErr) &#123; ret = AVERROR_UNKNOWN; goto fail; &#125; if (SecTrustEvaluate(peerTrust, &amp;trustResult) != noErr) &#123; ret = AVERROR_UNKNOWN; goto fail; &#125; if (trustResult == kSecTrustResultProceed || trustResult == kSecTrustResultUnspecified) &#123; // certificate is trusted status = errSSLWouldBlock; // so we call SSLHandshake again &#125; else if (trustResult == kSecTrustResultRecoverableTrustFailure) &#123; // not trusted, for some reason other than being expired status = errSSLXCertChainInvalid; &#125; else &#123; // cannot use this certificate (fatal) status = errSSLBadCert; &#125; if (peerTrust) CFRelease(peerTrust); &#125; if (status == noErr) &#123; break; &#125; else if (status != errSSLWouldBlock) &#123; av_log(h, AV_LOG_ERROR, "Unable to negotiate TLS/SSL session: %i\n", (int)status); ret = AVERROR(EIO); goto fail; &#125; &#125; return 0;fail: tls_close(h); return ret;&#125;static OSStatus tls_read_cb(SSLConnectionRef connection, void *data, size_t *dataLength)&#123; URLContext *h = (URLContext*)connection; TLSContext *c = h-&gt;priv_data; size_t requested = *dataLength; /// äº¤ç»™ä¸‹ä¸€å±‚çš„tcpåŽ»å¤„ç† read /// è¿™é‡Œè¯»åˆ°çš„æ•°æ® è¿˜æ²¡æœ‰ç»è¿‡tlsè§£ç ï¼Œä¸å¯è¯» int read = ffurl_read(c-&gt;tls_shared.tcp, data, requested); if (read &lt;= 0) &#123; *dataLength = 0; switch(AVUNERROR(read)) &#123; case ENOENT: case 0: return errSSLClosedGraceful; case ECONNRESET: return errSSLClosedAbort; case EAGAIN: return errSSLWouldBlock; default: c-&gt;lastErr = read; return ioErr; &#125; &#125; else &#123; *dataLength = read; if (read &lt; requested) return errSSLWouldBlock; else return noErr; &#125;&#125;static OSStatus tls_write_cb(SSLConnectionRef connection, const void *data, size_t *dataLength)&#123; URLContext *h = (URLContext*)connection; TLSContext *c = h-&gt;priv_data; /// äº¤ç»™ä¸‹ä¸€å±‚çš„tcpåŽ»å¤„ç† write /// data å·²ç»ç»è¿‡çš„tlsçš„åŠ å¯†å¤„ç†äº†ã€‚ä¸å¯è¯» int written = ffurl_write(c-&gt;tls_shared.tcp, data, *dataLength); if (written &lt;= 0) &#123; *dataLength = 0; switch(AVUNERROR(written)) &#123; case EAGAIN: return errSSLWouldBlock; default: c-&gt;lastErr = written; return ioErr; &#125; &#125; else &#123; *dataLength = written; return noErr; &#125;&#125;static int tls_read(URLContext *h, uint8_t *buf, int size)&#123; TLSContext *c = h-&gt;priv_data; size_t available = 0, processed = 0; int ret; SSLGetBufferedReadSize(c-&gt;ssl_context, &amp;available); if (available) size = FFMIN(available, size); /// è¯»æ•°æ®ï¼Œè¿™é‡Œè¯»åˆ°çš„æ•°æ®å·²ç»ç»è¿‡çš„tlsçš„è§£å¯†ï¼Œæ˜¯æ˜Žæ–‡äº† æ–­ç‚¹å¯ä»¥æŸ¥çœ‹æ•°æ® ret = SSLRead(c-&gt;ssl_context, buf, size, &amp;processed); ret = map_ssl_error(ret, processed); if (ret &gt; 0) return ret; if (ret == 0) return AVERROR_EOF; return print_tls_error(h, ret);&#125;static int tls_write(URLContext *h, const uint8_t *buf, int size)&#123; TLSContext *c = h-&gt;priv_data; size_t processed = 0; /// å†™æ•°æ®ï¼Œåº”ç”¨å±‚çš„æ•°æ®è¿˜æ²¡æœ‰ç»è¿‡tlsçš„åŠ å¯†ï¼Œæ–­ç‚¹å¯è¯» int ret = SSLWrite(c-&gt;ssl_context, buf, size, &amp;processed); ret = map_ssl_error(ret, processed); if (ret &gt; 0) return ret; if (ret == 0) return AVERROR_EOF; return print_tls_error(h, ret);&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465libavformat/tls.cint ff_tls_open_underlying(TLSShared *c, URLContext *parent, const char *uri, AVDictionary **options)&#123; int port; const char *p; char buf[200], opts[50] = ""; struct addrinfo hints = &#123; 0 &#125;, *ai = NULL; const char *proxy_path; char *env_http_proxy, *env_no_proxy; int use_proxy; set_options(c, uri); if (c-&gt;listen) snprintf(opts, sizeof(opts), "?listen=1"); av_url_split(NULL, 0, NULL, 0, c-&gt;underlying_host, sizeof(c-&gt;underlying_host), &amp;port, NULL, 0, uri); p = strchr(uri, '?'); if (!p) &#123; p = opts; &#125; else &#123; if (av_find_info_tag(opts, sizeof(opts), "listen", p)) c-&gt;listen = 1; &#125; ff_url_join(buf, sizeof(buf), "tcp", NULL, c-&gt;underlying_host, port, "%s", p); hints.ai_flags = AI_NUMERICHOST; if (!getaddrinfo(c-&gt;underlying_host, NULL, &amp;hints, &amp;ai)) &#123; c-&gt;numerichost = 1; freeaddrinfo(ai); &#125; if (!c-&gt;host &amp;&amp; !(c-&gt;host = av_strdup(c-&gt;underlying_host))) return AVERROR(ENOMEM); env_http_proxy = getenv_utf8("http_proxy"); proxy_path = c-&gt;http_proxy ? c-&gt;http_proxy : env_http_proxy; env_no_proxy = getenv_utf8("no_proxy"); use_proxy = !ff_http_match_no_proxy(env_no_proxy, c-&gt;underlying_host) &amp;&amp; proxy_path &amp;&amp; av_strstart(proxy_path, "http://", NULL); freeenv_utf8(env_no_proxy); if (use_proxy) &#123; char proxy_host[200], proxy_auth[200], dest[200]; int proxy_port; av_url_split(NULL, 0, proxy_auth, sizeof(proxy_auth), proxy_host, sizeof(proxy_host), &amp;proxy_port, NULL, 0, proxy_path); ff_url_join(dest, sizeof(dest), NULL, NULL, c-&gt;underlying_host, port, NULL); ff_url_join(buf, sizeof(buf), "httpproxy", proxy_auth, proxy_host, proxy_port, "/%s", dest); &#125; freeenv_utf8(env_http_proxy); ///ç†Ÿæ‚‰çš„æ–¹æ³•ï¼Œæ ¹æ®ä¸Šé¢æ‹¼æŽ¥çš„tcp:// æ‰“å¼€tcp return ffurl_open_whitelist(&amp;c-&gt;tcp, buf, AVIO_FLAG_READ_WRITE, &amp;parent-&gt;interrupt_callback, options, parent-&gt;protocol_whitelist, parent-&gt;protocol_blacklist, parent);&#125; tlsè¿™å—çš„å¤„ç†é€»è¾‘ ä½œä¸ºhttp è·Ÿ tcpçš„ä¸­é—´å±‚ï¼Œéƒ½æ˜¯éµå¾ªçš„URLProtocolåè®®ï¼Œæ‰€ä»¥æµç¨‹åŸºæœ¬è·Ÿhttpã€tcpä¸€æ ·ã€‚å…³é”®ç‚¹ä¹ŸåŒæ ·åŠ äº†å¯¹åº”çš„æ³¨é‡Šè¾…åŠ©ç†è§£ï¼Œå…³äºŽsslcontext è§ä¸‹é¢çš„è‹¹æžœæ–‡æ¡£ï¼Œ å¦‚æžœç†Ÿæ‚‰tlsçš„å››æ¬¡æ¡æ‰‹ï¼ŒåŸºæœ¬è¿˜æ˜¯å¯ä»¥ç†è§£ã€‚ summaryæ•´ä¸ªä»£ç è¿‡ç¨‹é¡ºä¸‹æ¥ï¼ŒåŸºæœ¬å°±æ˜¯ç½‘ç»œåè®®çš„è°ƒç”¨è¿‡ç¨‹ï¼Œhttp/https -&gt; ssl/tls -&gt; tcp(socket) æœ€åŽæ¥ä¸€å¼ wiresharkçš„æŠ“åŒ…ï¼Œå¾ˆæ˜Žæ˜¾çœ‹åˆ°ä»Žtcpçš„ä¸‰æ¬¡æ¡æ‰‹å¼€å§‹ï¼Œ ç´§æŽ¥ç€tlsçš„å››æ¬¡æ‚æ‰‹ï¼Œç„¶åŽå°±æ˜¯çœŸæ­£çš„è¯·æ±‚æ•°æ®çš„ä¼ è¾“äº†â€¦ reference#macos security]]></content>
      <categories>
        <category>ffmepg</category>
      </categories>
      <tags>
        <tag>ffmepg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iosèŽ·å–udid]]></title>
    <url>%2F2022%2F11%2F04%2Fios%E8%8E%B7%E5%8F%96udid%2F</url>
    <content type="text"><![CDATA[èƒŒæ™¯è‹¹æžœä¼ä¸šè´¦å·æ‰“åŒ…åˆ†å‘appï¼Œæ–¹ä¾¿å†…éƒ¨å®‰è£…æµ‹è¯•Appã€‚æœ€è¿‘å…¬å¸ä¼ä¸šè´¦å·ç»­è´¹å¤±è´¥ï¼Œç”³è¯·æ–°çš„ä¼ä¸šè´¦å·æ²¡æˆåŠŸã€‚ï¼ˆå›½å†…è¿‘2å¹´åŸºæœ¬æ²¡æœ‰ä¼ä¸šç”³è¯·æˆåŠŸï¼‰è¿™å°±è›‹ç–¼äº†ï¼Œäº†è§£åˆ°å…¶ä»–appæ˜¯é€šè¿‡å¤šå¼€å‘è€…è´¦å·ï¼Œadhocè¯ä¹¦ç™½åå•çš„æ–¹å¼æ¥åšåˆ†å‘ï¼Œadhocè¯ä¹¦æ— æ³•è§£å†³è®¾å¤‡æ•°é‡çš„é—®é¢˜ï¼Œæœ€å¤š100å°è®¾å¤‡ï¼Œè€Œä¸”è¿˜è¦æå‰æ³¨å†Œå¥½ï¼Œä¸€å¹´æ›´æ–°ä¸€æ¬¡ï¼Œæ³¨å†Œè®¾å¤‡å°±æ˜¯è¦æ‹¿åˆ°è®¾å¤‡çš„udidã€‚ èŽ·å–udidäº†è§£åˆ°è‹¹æžœå¯ä»¥é€šè¿‡safariä»¥OTA(over the air)çš„æ–¹å¼æ‹¿åˆ°udidã€‚ æ•´ä½“æµç¨‹åˆ†ä¸‰æ­¥ ä¸‹å‘udid.mobileconfigæ–‡ä»¶ æŽˆæƒå®‰è£…é…ç½®æ–‡ä»¶ å›žè°ƒè§£æžxmlæ‹¿åˆ°udid udid.mobileconfigä¸€ä¸ªxmlæ–‡ä»¶ï¼Œæ–‡ä»¶å†…å®¹å¦‚ä¸‹ 1234567891011121314151617181920212223242526272829303132333435&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;&lt;plist version="1.0"&gt; &lt;dict&gt; &lt;key&gt;PayloadContent&lt;/key&gt; &lt;dict&gt; &lt;key&gt;URL&lt;/key&gt; &lt;string&gt;https://xxx.net/udid/action&lt;/string&gt; &lt;!--æŽ¥æ”¶æ•°æ®çš„æŽ¥å£åœ°å€--&gt; &lt;key&gt;DeviceAttributes&lt;/key&gt; &lt;array&gt; &lt;string&gt;SERIAL&lt;/string&gt; &lt;string&gt;MAC_ADDRESS_EN0&lt;/string&gt; &lt;string&gt;UDID&lt;/string&gt; &lt;string&gt;IMEI&lt;/string&gt; &lt;string&gt;ICCID&lt;/string&gt; &lt;string&gt;VERSION&lt;/string&gt; &lt;string&gt;PRODUCT&lt;/string&gt; &lt;/array&gt; &lt;/dict&gt; &lt;key&gt;PayloadOrganization&lt;/key&gt; &lt;string&gt;dev.xxx.com&lt;/string&gt; &lt;!--ç»„ç»‡åç§°--&gt; &lt;key&gt;PayloadDisplayName&lt;/key&gt; &lt;string&gt;æŸ¥è¯¢è®¾å¤‡UDID&lt;/string&gt; &lt;!--å®‰è£…æ—¶æ˜¾ç¤ºçš„æ ‡é¢˜--&gt; &lt;key&gt;PayloadVersion&lt;/key&gt; &lt;integer&gt;1&lt;/integer&gt; &lt;key&gt;PayloadUUID&lt;/key&gt; &lt;string&gt;CD0BD3C5-7164-B9DA-FCBB-D81AA343C7A0&lt;/string&gt; &lt;!--è‡ªå·±éšæœºå¡«å†™çš„å”¯ä¸€å­—ç¬¦ä¸²--&gt; &lt;key&gt;PayloadIdentifier&lt;/key&gt; &lt;string&gt;dev.xxx.profile-service&lt;/string&gt; &lt;key&gt;PayloadDescription&lt;/key&gt; &lt;string&gt;æœ¬æ–‡ä»¶ä»…ç”¨æ¥èŽ·å–è®¾å¤‡ID&lt;/string&gt; &lt;!--æè¿°--&gt; &lt;key&gt;PayloadType&lt;/key&gt; &lt;string&gt;Profile Service&lt;/string&gt; &lt;/dict&gt;&lt;/plist&gt; éœ€è¦æ³¨æ„å°±æ˜¯å›žè°ƒæŽ¥å£ éœ€è¦æ”¯æŒhttpsï¼Œå¦è€…ä¼šæŠ¥ATSé”™è¯¯ the resource could not be loaded because the app transport security policy requires the use of a secure connection èµ·serviceä¸‹å‘ xml æ–‡ä»¶ï¼Œæˆ‘è¿™é‡Œä»¥java spring mvcæ¥å®žçŽ°çš„ 123456789101112131415161718@RequestMapping("/udid.mobileconfig") @ResponseBody public ResponseEntity&lt;byte[]&gt; downloadsEntity(HttpServletRequest request) throws Exception &#123; String path = Objects.requireNonNull(this.getClass().getClassLoader().getResource("udid.mobileconfig")).toURI().getPath(); File file = new File(path); if (!file.isFile()) &#123; return null; &#125; byte[] bytes = FileUtils.readFileToByteArray(file); HttpHeaders headers = new HttpHeaders(); headers.add("Content-type","application/x-apple-aspen-config; charset=utf-8"); // æŒ‰è‹¹æžœçš„è§„èŒƒ headers.add("Content-Disposition", "attachment;filename=" + "udid.mobileconfig"); HttpStatus status = HttpStatus.OK; return new ResponseEntity&lt;&gt;(bytes, headers, status); &#125; æŽˆæƒå®‰è£…ä¸‹è½½udid.mobileconfigä¹‹åŽï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åœ¨è®¾ç½®é‡Œé¢ç™»è®°è¯¥é…ç½®æ–‡ä»¶ï¼Œéœ€è¦è‡ªè¡ŒåŽ»è®¾ç½®é‡Œé¢ æŽˆæƒå®‰è£…ã€‚å®‰è£…æˆåŠŸä¹‹åŽ ä¼šå›žè°ƒ mobileconfigé‡Œé¢æä¾›çš„å›žè°ƒåœ°å€ï¼Œudidç­‰ä¿¡æ¯ä¼šä»¥å‚æ•°çš„å½¢å¼ä¸€å¹¶å¸¦ä¸Šï¼Œæ ¼å¼ä¹Ÿæ˜¯xmlæ ¼å¼ã€‚ å¦‚æžœä¸‹è½½çš„è¿‡ç¨‹æç¤ºæ— æ•ˆæ–‡ä»¶ï¼Œå¯èƒ½å°±æ˜¯mobileconfigæ–‡ä»¶å†…å®¹æœ‰é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡pcæµè§ˆå™¨æ£€æŸ¥ä¸‹æ–‡ä»¶å†…å®¹ï¼Œæˆ‘è¿™é‡Œå°±é‡åˆ°äº†æ–‡ä»¶ä¹±ç çš„æƒ…å†µ ä¸Šé¢æåˆ°æ–‡ä»¶å†…å®¹æ˜¯ä»¥å­—èŠ‚æµçš„æ–¹å¼ä¸‹å‘çš„ï¼Œé…ç½®å¥½ByteArrayHttpMessageConverterçš„é¡ºåºå°±okäº† 123456789101112131415161718192021222324252627&lt;!--è‡ªåŠ¨æ³¨å†ŒåŸºäºŽæ³¨è§£é£Žæ ¼çš„å¤„ç†å™¨ (æ•°æ®è½¬æ¢ æ ¼å¼åŒ– æ•°æ®)--&gt; &lt;mvc:annotation-driven&gt; &lt;mvc:message-converters&gt; &lt;ref bean="stringHttpMessageConverter"/&gt; &lt;!--é…ç½®ByteArrayHttpMessageConverter--&gt; &lt;bean class="org.springframework.http.converter.ByteArrayHttpMessageConverter"/&gt; &lt;bean class="com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter"&gt; &lt;property name="features"&gt; &lt;array&gt; &lt;!-- Listå­—æ®µå¦‚æžœä¸ºnull,è¾“å‡ºä¸º[],è€Œéžnul --&gt; &lt;value&gt;WriteNullListAsEmpty&lt;/value&gt; &lt;!-- å­—ç¬¦ç±»åž‹å­—æ®µå¦‚æžœä¸ºnull,è¾“å‡ºä¸ºâ€â€œ,è€Œéžnull --&gt; &lt;value&gt;WriteNullStringAsEmpty&lt;/value&gt; &lt;!-- è¿›åˆ¶å¾ªçŽ¯å¼•ç”¨ --&gt; &lt;value&gt;DisableCircularReferenceDetect&lt;/value&gt; &lt;!--Booleanå­—æ®µå¦‚æžœä¸ºnull,è¾“å‡ºä¸ºfalse,è€Œéžnull --&gt; &lt;value&gt;WriteNullBooleanAsFalse&lt;/value&gt; &lt;!--æ—¶é—´ yyyy.MM.dd hh:mm:ss --&gt; &lt;value type="com.alibaba.fastjson.serializer.SerializerFeature"&gt;WriteDateUseDateFormat&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt; &lt;/mvc:annotation-driven&gt; è§£æžudidè¿˜æ˜¯ä»¥javaå®žçŽ° 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@RequestMapping(value = "/action", method = RequestMethod.POST) @ResponseBody public ResponseEntity&lt;String&gt; action(HttpServletRequest request) throws IOException &#123; //èŽ·å–HTTPè¯·æ±‚çš„è¾“å…¥æµ InputStream is = request.getInputStream(); //å·²HTTPè¯·æ±‚è¾“å…¥æµå»ºç«‹ä¸€ä¸ªBufferedReaderå¯¹è±¡ BufferedReader br = new BufferedReader(new InputStreamReader(is,"UTF-8")); StringBuilder sb = new StringBuilder(); //è¯»å–HTTPè¯·æ±‚å†…å®¹ String buffer = null; while ((buffer = br.readLine()) != null) &#123; sb.append(buffer); &#125; String content = sb.toString().substring(sb.toString().indexOf("&lt;?xml"), sb.toString().indexOf("&lt;/plist&gt;")+8); System.out.println(content); // åˆ›å»ºxmlè§£æžå¯¹è±¡ SAXReader reader = new SAXReader(); // å®šä¹‰ä¸€ä¸ªæ–‡æ¡£ Document document = null; //å°†å­—ç¬¦ä¸²è½¬æ¢ä¸º try &#123; document = reader.read(new ByteArrayInputStream(content.getBytes("GBK"))); &#125; catch (DocumentException e) &#123; e.printStackTrace(); &#125; String udid = "ERROR"; if(document != null) &#123; Element element = (Element) document.selectNodes("/plist/dict").get(0); for(Iterator iter = element.content().iterator(); iter.hasNext();) &#123; DefaultElement next = (DefaultElement) iter.next(); String name = next.getName(); String text = next.getText(); if(StringUtils.isEquals(name,"key") &amp;&amp; StringUtils.isEquals(text,"UDID") &amp;&amp; iter.hasNext()) &#123; next = (DefaultElement) iter.next(); name = next.getName(); text = next.getText(); udid = text; &#125; &#125; &#125; HttpHeaders headers = new HttpHeaders(); headers.add("Content-type","text/html; charset=utf-8"); headers.setLocation(URI.create("https://xxx.com/udid/udid?udid="+udid)); /// è·³è½¬åˆ°æŒ‡å®šçš„é¡µé¢ å±•ç¤ºudidä¿¡æ¯ HttpStatus status = HttpStatus.MOVED_PERMANENTLY; return new ResponseEntity&lt;&gt;("", headers, status); &#125; è§£æžxmlå°±å¯ä»¥æ‹¿åˆ°udidå­—æ®µï¼Œæ³¨æ„çš„æ˜¯ é‡å®šå‘ä¸€å®šè¦ä½¿ç”¨301é‡å®šå‘ï¼ˆMOVED_PERMANENTLYï¼‰,æœ‰äº›é‡å®šå‘é»˜è®¤æ˜¯302é‡å®šå‘,è¿™æ ·å°±ä¼šå¯¼è‡´å®‰è£…å¤±è´¥,è®¾å¤‡å®‰è£…ä¼šæç¤ºâ€æ— æ•ˆçš„æè¿°æ–‡ä»¶]]></content>
      <categories>
        <category>ios</category>
      </categories>
      <tags>
        <tag>ios</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MP4ç¬”è®°]]></title>
    <url>%2F2022%2F10%2F28%2FMP4%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[MP4 BOXç¬¬ä¸€å±‚Ftypã€Moovã€Mdatã€Freeç­‰: ftyp Boxftypæ˜¯MP4æ–‡ä»¶çš„ç¬¬ä¸€ä¸ªBoxï¼ŒåŒ…å«äº†è§†é¢‘æ–‡ä»¶ä½¿ç”¨çš„ç¼–ç æ ¼å¼ã€æ ‡å‡†ç­‰ï¼Œè¿™ä¸ªBoxä½œç”¨åŸºæœ¬å°±æ˜¯MP4è¿™ç§å°è£…æ ¼å¼çš„æ ‡è¯†ï¼ŒåŒæ—¶åœ¨ä¸€ä»½MP4æ–‡ä»¶ä¸­åªæœ‰ä¸€ä¸ªè¿™æ ·çš„Boxã€‚ftyp boxé€šå¸¸æ”¾åœ¨æ–‡ä»¶çš„å¼€å§‹ï¼Œé€šè¿‡å¯¹è¯¥boxè§£æžå¯ä»¥è®©æˆ‘ä»¬çš„è½¯ä»¶ï¼ˆæ’­æ”¾å™¨ã€demuxã€è§£æžå™¨ï¼‰çŸ¥é“åº”è¯¥ä½¿ç”¨å“ªç§åè®®å¯¹è¿™è¯¥æ–‡ä»¶è§£æžï¼Œæ˜¯åŽç»­è§£è¯»æ–‡ä»¶åŸºç¡€ Moov BoxMoov Boxè¿™ä¸ªBoxä¹Ÿæ˜¯MP4æ–‡ä»¶ä¸­å¿…é¡»æœ‰ä½†æ˜¯åªå­˜åœ¨ä¸€ä¸ªçš„Box,è¿™ä¸ªBoxé‡Œé¢ä¸€èˆ¬å­˜çš„æ˜¯åª’ä½“æ–‡ä»¶çš„å…ƒæ•°æ®ï¼Œè¿™ä¸ªBoxæœ¬èº«æ˜¯å¾ˆç®€å•çš„ï¼Œæ˜¯ä¸€ç§Container Boxï¼Œé‡Œé¢çš„æ•°æ®æ˜¯å­Box,è‡ªå·±æ›´åƒæ˜¯ä¸€ä¸ªåˆ†ç•Œæ ‡è¯†ã€‚ æ‰€è°“çš„åª’ä½“å…ƒæ•°æ®ä¸»è¦åŒ…å«ç±»ä¼¼SPS PPSçš„ç¼–è§£ç å‚æ•°ä¿¡æ¯ï¼Œè¿˜æœ‰éŸ³è§†é¢‘çš„æ—¶é—´æˆ³ç­‰ä¿¡æ¯ã€‚å¯¹äºŽMP4è¿˜æœ‰ä¸€ä¸ªé‡è¦çš„é‡‡æ ·è¡¨stblä¿¡æ¯ï¼Œè¿™é‡Œé¢å®šä¹‰äº†é‡‡æ ·Sampleã€Chunkã€Trackçš„æ˜ å°„å…³ç³»ï¼Œæ˜¯MP4èƒ½å¤Ÿè¿›è¡Œéšæœºæ‹–åŠ¨å’Œæ’­æ”¾çš„å…³é”®ï¼Œä¹Ÿæ˜¯éœ€è¦å¥½å¥½ç†è§£çš„éƒ¨åˆ†ï¼Œå¯¹äºŽå®žçŽ°ä¸€äº›éŸ³è§†é¢‘ç‰¹æ®Šæ“ä½œå¾ˆæœ‰å¸®åŠ©ã€‚ Mdat BoxMdat Boxè¿™ä¸ªBoxæ˜¯å­˜å‚¨éŸ³è§†é¢‘æ•°æ®çš„Boxï¼Œè¦ä»Žè¿™ä¸ªBoxè§£å°è£…å‡ºçœŸå®žçš„åª’ä½“æ•°æ®ã€‚å½“ç„¶è¿™ä¸ªBoxä¸€èˆ¬éƒ½ä¼šå­˜åœ¨ï¼Œä½†æ˜¯ä¸æ˜¯å¿…é¡»çš„ã€‚ åœ¨å‰é¢çš„æ–‡ç« ã€ŠéŸ³è§†é¢‘åŽ‹ç¼©ï¼šH264ç æµå±‚æ¬¡ç»“æž„å’ŒNALUè¯¦è§£ã€‹ä¸­å·²ç»è®²è§£äº†H264çš„åŸºæœ¬ç»“æž„æ˜¯ç”±ä¸€ç³»åˆ—çš„NALUç»„æˆã€‚åŽŸå§‹çš„NALUå•å…ƒç»„æˆï¼š Start code + NALU header + NALU payload ä½†æ˜¯åœ¨MP4æ ¼å¼æ–‡ä»¶ä¸­ï¼ŒH264 sliceå¹¶ä¸æ˜¯ä»¥00 00 00 01 Start Codeæ¥è¿›è¡Œåˆ†å‰²ï¼Œè€Œæ˜¯å­˜å‚¨åœ¨Mdat Boxçš„Dataä¸­ã€‚ Mdat Boxçš„æ ¼å¼ï¼š Box header + Box Data Box length + Box Type + NALU length + NALU header + Nalu Dataâ€¦â€¦. NALU length + NALU header + Nalu Data Free BoxFree Boxä¸­çš„å†…å®¹æ˜¯æ— å…³ç´§è¦çš„ï¼Œå¯ä»¥è¢«å¿½ç•¥å³è¯¥boxè¢«åˆ é™¤åŽï¼Œä¸ä¼šå¯¹æ’­æ”¾äº§ç”Ÿä»»ä½•å½±å“ã€‚è¿™ç§ç±»åž‹çš„Boxä¹Ÿä¸æ˜¯å¿…é¡»çš„ï¼Œå¯æœ‰å¯æ— ï¼Œç±»ä¼¼çš„Boxè¿˜æœ‰Sikp Box.è™½ç„¶åœ¨è§£æžæ˜¯å¯ä»¥å¿½ç•¥ï¼Œä½†æ˜¯éœ€è¦æ³¨æ„è¯¥Boxçš„åˆ é™¤å¯¹å…¶å®ƒBoxçš„åç§»é‡å½±å“ï¼Œç‰¹åˆ«æ˜¯å½“Moov Boxæ”¾åˆ°Mdat BoxåŽé¢çš„æƒ…å†µã€‚ MOOVMvhd Boxè¿™ä¸ªBoxä¹Ÿæ˜¯å…¨æ–‡ä»¶å”¯ä¸€çš„ä¸€ä¸ªBox,ä¸€èˆ¬å¤„äºŽMoov Boxçš„ç¬¬ä¸€ä¸ªå­Box,è¿™ä¸ªBoxå¯¹æ•´ä¸ªåª’ä½“æ–‡ä»¶æ‰€åŒ…å«çš„åª’ä½“æ•°æ®ï¼ˆåŒ…å«Video trackå’ŒAudio Trackç­‰ï¼‰è¿›è¡Œå…¨é¢çš„æè¿°ã€‚å…¶ä¸­åŒ…å«äº†åª’ä½“çš„åˆ›å»ºå’Œä¿®æ”¹æ—¶é—´ï¼Œé»˜è®¤éŸ³é‡ã€è‰²åŸŸã€æ—¶é•¿ç­‰ä¿¡æ¯ã€‚ Trak BoxTrak Boxå®šä¹‰äº†åª’ä½“æ–‡ä»¶ä¸­åª’ä½“ä¸­ä¸€ä¸ªTrackçš„ä¿¡æ¯ï¼Œè§†é¢‘æœ‰Video Track,éŸ³é¢‘æœ‰Audio Trackï¼Œåª’ä½“æ–‡ä»¶ä¸­å¯ä»¥æœ‰å¤šä¸ªTrackï¼Œæ¯ä¸ªTrackå…·æœ‰è‡ªå·±ç‹¬ç«‹çš„æ—¶é—´å’Œç©ºé—´çš„ä¿¡æ¯ï¼Œå¯ä»¥è¿›è¡Œç‹¬ç«‹æ“ä½œã€‚ æ¯ä¸ªTrack Boxéƒ½éœ€è¦æœ‰ä¸€ä¸ªTkhd Boxå’ŒMdia Boxï¼Œå…¶å®ƒçš„Boxéƒ½æ˜¯å¯é€‰æ‹©çš„ TrakTkhd Boxè¯¥Boxæè¿°äº†è¯¥Trackçš„åª’ä½“æ•´ä½“ä¿¡æ¯åŒ…æ‹¬æ—¶é•¿ã€å›¾åƒçš„å®½åº¦å’Œé«˜åº¦ç­‰ï¼Œå®žé™…æ¯”è¾ƒé‡è¦ Mdia Boxè¿™ä¸ªBoxä¹Ÿæ˜¯Container Boxï¼Œé‡Œé¢åŒ…å«å­Boxï¼Œä¸€èˆ¬å¿…é¡»æœ‰Mdhd Boxã€Hdlr Boxã€Minf Boxã€‚åŸºæœ¬å°±æ˜¯å½“å‰Trackåª’ä½“å¤´ä¿¡æ¯å’Œåª’ä½“å¥æŸ„ä»¥åŠåª’ä½“ä¿¡æ¯ã€‚ Boxè‡ªèº«éžå¸¸ç®€å•ï¼Œå°±æ˜¯ä¸€ä¸ªæ ‡è¯†è€Œå·²ï¼Œæœ€å¤æ‚çš„è¿˜æ˜¯é‡Œé¢åŒ…å«çš„å­Box. MdiaMdhd Boxè¿™ä¸ªBoxæ˜¯Full Boxï¼Œæ„å‘³ç€Box Headeræœ‰Versionå’ŒFlagå­—æ®µï¼Œè¯¥Boxé‡Œé¢ä¸»è¦å®šä¹‰äº†è¯¥Trackçš„åª’ä½“å¤´ä¿¡æ¯ï¼Œå…¶ä¸­æˆ‘ä»¬æœ€å…³å¿ƒçš„ä¸¤ä¸ªå­—æ®µæ˜¯Time scaleå’ŒDurationï¼Œåˆ†åˆ«è¡¨ç¤ºäº†è¯¥Trackçš„æ—¶é—´æˆ³å’Œæ—¶é•¿ä¿¡æ¯ï¼Œè¿™ä¸ªæ—¶é—´æˆ³ä¿¡æ¯ä¹Ÿæ˜¯PTSå’ŒDTSçš„å•ä½ã€‚ Hdlr Boxè¿™ä¸ªBoxæ˜¯Full Boxï¼Œæ„å‘³ç€Box Headeræœ‰Versionå’ŒFlagå­—æ®µï¼Œè¯¥Boxè§£é‡Šäº†åª’ä½“çš„æ’­æ”¾è¿‡ç¨‹ä¿¡æ¯ï¼Œç”¨æ¥è®¾ç½®ä¸åŒTrackçš„å¤„ç†æ–¹å¼ï¼Œæ ‡è¯†äº†è¯¥Trackçš„ç±»åž‹ã€‚ Minf Boxè¿™ä¸ªBoxæ˜¯æˆ‘è®¤ä¸ºMoov Boxé‡Œé¢æœ€é‡è¦æœ€å¤æ‚çš„Boxï¼Œå†…éƒ¨è¿˜æœ‰å­Boxï¼Œæˆ‘ä»¬è¿˜æ˜¯ä»Žä¸Šåˆ°ä¸‹ä»Žå¤–åˆ°å†…çš„åˆ†æžå„ä¸ªBoxã€‚è¯¥Boxå»ºç«‹äº†æ—¶é—´åˆ°çœŸå®žéŸ³è§†é¢‘Sampleçš„æ˜ å°„å…³ç³»ï¼Œå¯¹äºŽéŸ³è§†é¢‘æ•°æ®æ“ä½œæ—¶å¾ˆæœ‰å¸®åŠ©çš„ã€‚ åŒæ—¶è¯¥Boxæ˜¯Container Boxï¼Œä¸‹é¢ä¸€èˆ¬å«æœ‰ä¸‰å¤§å¿…é¡»çš„å­Box: åª’ä½“ä¿¡æ¯å¤´Box: Vmhd Boxæˆ–è€…Smhd Box; æ•°æ®ä¿¡æ¯Boxï¼šDinf Box é‡‡æ ·è¡¨Boxï¼šStbl Box MinfVmhd BoxDinf BoxStbl Boxæ€Žæ ·æŠŠåª’ä½“æ•°æ®çš„Sampleå’Œæ—¶é—´è¿›è¡Œæ˜ å°„çš„ï¼Œçœ‹ä¸‹Sample-Trunk-Trackçš„ä¸‰è€…å…³ç³»ã€‚ æˆ‘ä»¬çŸ¥é“Sampleæ˜¯åª’ä½“æ•°æ®çš„å­˜å‚¨å•å…ƒï¼Œå…¶ä¸­å­˜å‚¨åœ¨Mediaçš„chunkä¸­ï¼Œåœ¨åˆ†æžMdat Boxçš„H264 NALUæ‰“åŒ…æ—¶å·²ç»ä½“çŽ°å‡ºæ¥äº† å…¶ä¸­æ¯ä¸ªSampleçš„æ—¶é—´å’Œä½ç½®ã€ç¼–è§£ç ä¿¡æ¯ã€å’Œchunkå…³ç³»ç­‰éƒ½æ˜¯ç”±Stbl Boxæ¥æè¿°çš„ï¼Œè¯¥Boxåˆç§°ä¸ºé‡‡æ ·å‚æ•°åˆ—è¡¨å³Sample Tableã€‚ Stbl BoxåŒ…å«äº†Trackä¸­mediaåª’ä½“çš„æ‰€æœ‰æ—¶é—´å’Œç´¢å¼•ï¼Œåˆ©ç”¨è¿™ä¸ªå®¹å™¨çš„Sampleä¿¡æ¯ï¼Œå°±å¯ä»¥å®šä½Sampleçš„åª’ä½“æ—¶é—´ã€ç±»åž‹ã€å¤§å°ä»¥åŠå’Œå…¶ç›¸é‚»çš„Sampleã€‚åŒæ—¶è¯¥Boxæ˜¯å¿…é¡»åœ¨Trak Boxä¸­å­˜åœ¨çš„ã€‚ å…¶ä¸€èˆ¬è¦åŒ…å«ä¸‹åˆ—å­Boxï¼š é‡‡æ ·æè¿°å®¹å™¨ï¼š Sample Descriptionå³Stsd Box é‡‡æ ·æ—¶é—´å®¹å™¨ï¼š Time To Sample å³Stts Box é‡‡æ ·åŒæ­¥å®¹å™¨ï¼š Sync Sampleå³Stss Chunké‡‡æ ·å®¹å™¨: Sample To Chunkå³Stsc é‡‡æ ·å¤§å°å®¹å™¨ï¼š Sample Sizeå³Stsz Chunkåç§»å®¹å™¨ï¼šChunk Offestå³Stco Stsd Box è¯¥Boxå­˜å‚¨äº†ç¼–ç ç±»åž‹å’Œåˆå§‹åŒ–è§£ç å™¨éœ€è¦çš„ä¿¡æ¯ï¼Œä¸Žç‰¹å®šçš„Track Typeæœ‰å…³ï¼Œæ ¹äºŽä¸åŒçš„Trackä½¿ç”¨ä¸ä¸€æ ·çš„ç¼–ç æ ‡å‡†ã€‚ box headerå’Œversionå­—æ®µåŽä¼šæœ‰ä¸€ä¸ªentry countå­—æ®µï¼Œæ ¹æ®entryçš„ä¸ªæ•°ï¼Œæ¯ä¸ªentryä¼šæœ‰typeä¿¡æ¯ï¼Œå¦‚â€œvideâ€ã€â€œsundâ€ç­‰ï¼Œæ ¹æ®typeä¸åŒsample descriptionä¼šæä¾›ä¸åŒçš„ä¿¡æ¯ï¼Œä¾‹å¦‚å¯¹äºŽvideo trackï¼Œä¼šæœ‰â€œVisualSampleEntryâ€ç±»åž‹ä¿¡æ¯ï¼Œå¯¹äºŽaudio trackä¼šæœ‰â€œAudioSampleEntryâ€ç±»åž‹ä¿¡æ¯ã€‚è§†é¢‘çš„ç¼–ç ç±»åž‹ã€å®½é«˜ã€é•¿åº¦ï¼ŒéŸ³é¢‘çš„å£°é“ã€é‡‡æ ·ç­‰ä¿¡æ¯éƒ½ä¼šå‡ºçŽ°åœ¨è¿™ä¸ªboxä¸­ã€‚ å¯¹äºŽVideo Tracké‡Œé¢è€Œè¨€ï¼ŒH264çš„SPS PPSå°±å­˜åœ¨è¯¥Boxé‡Œé¢ï¼Œå¯¹äºŽè§£ç éžå¸¸é‡è¦ã€‚ Stsd/Avc1 Box: å½“ä¸ºVideo Trackï¼Œæ‰€ä»¥VisualSampleEntryä¸ºAvc1 Boxï¼Œå†…éƒ¨å«æœ‰SPS PPS ç­‰éŸ³è§†é¢‘è§£ç ä¿¡æ¯ã€‚ Stsd/Avc1/AVCC Box è¯¥Boxåˆ™åŒ…å«äº†çœŸå®žçš„SPS PPSç­‰ä¿¡æ¯ï¼ŒåŒ…å«ç€éŸ³è§†é¢‘ç¼–è§£ç å‚æ•°ï¼š éŸ³é¢‘çš„STSDçš„Box Dataä¸»è¦ç”±mp4aå’Œesds BoxåµŒå¥—ç»„æˆï¼Œé‡Œé¢åŒ…å«äº†é€šé“ä¸ªæ•°ï¼Œé‡‡æ ·çŽ‡ã€éŸ³é¢‘AACç¼–ç çº§åˆ«ç­‰ä¿¡æ¯ Stsd/mp4a Box: Stsd/mp4a/Esds Box é‡Œé¢ä¸»è¦æ˜¯å°†éŸ³é¢‘çš„ç¼–ç ä¿¡æ¯å’ŒéŸ³é¢‘ç çŽ‡ä¿¡æ¯æ”¾åˆ°è¯¥Boxé‡Œé¢ï¼Œæ‰€ä»¥è§£ç éŸ³é¢‘æ—¶éžå¸¸å…³é”®ã€‚ Stts Box è¿™ä¸ªBoxæ˜¯sample numberå’Œè§£ç æ—¶é—´DTSä¹‹é—´çš„æ˜ å°„è¡¨ï¼Œé€šè¿‡è¿™ä¸ªè¡¨æ ¼ï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾åˆ°ä»»ä½•æ—¶é—´çš„sampleã€‚Stts Boxè¿™ä¸ªè¡¨æ ¼æœ‰ä¸¤é¡¹å€¼ï¼Œå…¶ä¸­ä¸€é¡¹æ˜¯è¿žç»­çš„æ ·ç‚¹æ•°ç›®å³sample countå’Œæ ·ç‚¹ç›¸å¯¹æ—¶é—´å·®å€¼å³sample deltaå³è¡¨æ ¼ä¸­æ¯ä¸ªæ¡ç›®æä¾›äº†åœ¨åŒä¸€ä¸ªæ—¶é—´åç§»é‡é‡Œé¢è¿žç»­çš„sampleåºå·ä»¥åŠsampleåç§»é‡ã€‚å½“ç„¶è¿™é‡Œçš„ç›¸å¯¹æ—¶é—´å·®å•ä½æ˜¯ç”±è¯¥Trackçš„Mdhd Boxæè¿°çš„æ—¶é—´å•ä½ Ctts Box è¯¥Boxä¿å­˜äº†æ¯ä¸ªsampleçš„composition timeå’Œdecode timeä¹‹é—´çš„å·®å€¼ï¼Œè¿™é‡Œé€šè¿‡Composition Timeå°±å¯ä»¥è®¡ç®—å‡ºSampleçš„PTSã€‚ ä¸å­˜åœ¨Bå¸§æƒ…å†µä¸‹PTSæ˜¯ç­‰äºŽDTSçš„ï¼Œåˆ™ä¸å«Bå¸§çš„è§†é¢‘æ–‡ä»¶æ˜¯æ²¡æœ‰Ctts Boxçš„ï¼ŒåŒæ ·éŸ³é¢‘ä¹Ÿæ²¡æœ‰Ctts Boxã€‚ Stss Box Iå¸§æ˜¯æ’­æ”¾çš„èµ·å§‹ä½ç½®ï¼Œåªæœ‰ç¼–ç å™¨æ‹¿åˆ°ç¬¬ä¸€ä¸ªIå¸§æ‰èƒ½æ¸²æŸ“å‡ºç¬¬ä¸€å¹…ç”»é¢ã€‚æ‰€ä»¥åŽç»­çš„ä¸€äº›ç‰¹æ®Šéšæœºæ“ä½œï¼Œé«˜æ ‡æ¸…åˆ‡æ¢æ—¶éƒ½éœ€è¦æ‰¾Iå¸§ï¼Œåªæœ‰éšæœºæ‰¾åˆ°Iå¸§æ‰èƒ½å®Œæˆè¿™äº›ç‰¹æ®Šæ“ä½œã€‚ å…¶ä¸­è¯¥Boxå°±æ˜¯å­˜å‚¨äº†é‚£äº›Sampleæ˜¯Iå…³é”®å¸§ï¼Œå¾ˆæ˜¾ç„¶éŸ³é¢‘Trackä¹Ÿæ˜¯ä¸å­˜åœ¨è¿™ä¸ªBoxçš„ã€‚ Stsc Box MP4ä¸­å­˜åœ¨Track-Trunk-Sampleæ¦‚å¿µï¼Œè®²åˆ°çŽ°åœ¨Trackå’ŒSampleå·²ç»éƒ½è®²åˆ°äº†ï¼Œä½†æ˜¯è¿˜æ²¡æœ‰è®²è§£Trunkå’ŒSampleçš„æ˜ å°„å…³ç³»ï¼Œè¿™ä¸ªBoxå°±æ˜¯è¯´æ˜Žé‚£äº›Sampleå¯ä»¥åˆ’åˆ†ä¸ºä¸€ä¸ªTrunkã€‚ åª’ä½“æ•°æ®è¢«åˆ†ä¸ºè‹¥å¹²ä¸ªchunk, chunkå¯ä»¥æœ‰ä¸åŒçš„å¤§å°ï¼ŒåŒä¸€ä¸ªchunkä¸­çš„æ ·ç‚¹sampleä¹Ÿå…è®¸æœ‰ä¸åŒçš„å¤§å°ï¼›é€šè¿‡æœ¬è¡¨å¯ä»¥å®šä½ä¸€ä¸ªæ ·ç‚¹çš„chunkä½ç½®,åŒæ—¶è¯¥Boxé‡Œé¢çš„Box Dataé‡Œé¢æœ‰ä¸‰ä¸ªå­—æ®µï¼Œåˆ†åˆ«æ˜¯first chunkã€sample per chunkã€sample description indexã€‚ fist chunk: å…·æœ‰ç›¸åŒé‡‡æ ·ç‚¹sampleå’Œsample_description_indexçš„chunkä¸­ï¼Œç¬¬ä¸€ä¸ªchunkçš„ç´¢å¼•å€¼,ä¹Ÿå°±æ˜¯è¯´è¯¥chunkç´¢å¼•å€¼ä¸€ç›´åˆ°ä¸‹ä¸€ä¸ªç´¢å¼•å€¼ä¹‹é—´çš„æ‰€æœ‰chunkéƒ½å…·æœ‰ç›¸åŒçš„sampleä¸ªæ•°ï¼ŒåŒæ—¶è¿™äº›sampleçš„æè¿°descriptionä¹Ÿä¸€æ ·ï¼› samples per chunk: ä¸Šé¢æ‰€æœ‰chunkçš„sampleä¸ªæ•° sample description index: æè¿°é‡‡æ ·ç‚¹çš„é‡‡æ ·æè¿°é¡¹çš„ç´¢å¼•å€¼ï¼ŒèŒƒå›´ä¸º1åˆ°æ ·æœ¬æè¿°è¡¨ä¸­çš„è¡¨é¡¹æ•°ç›®ï¼› è¿™ 3 ä¸ªå­—æ®µå®žé™…ä¸Šå†³å®šäº†ä¸€ä¸ª MP4 ä¸­æœ‰å¤šå°‘ä¸ª chunksï¼Œæ¯ä¸ª chunks æœ‰å¤šå°‘ä¸ª samplesã€‚ Stsz Box å‰é¢åˆ†æžäº†sampleçš„PTSã€DTSç­‰ï¼Œä¹Ÿåˆ†æžäº†chunké‡Œé¢sampleçš„ä¿¡æ¯ï¼Œä½†æ˜¯æ²¡æœ‰åˆ†æžsampleçš„å¤§å°ï¼Œè¿™æ˜¯æˆ‘ä»¬åœ¨æ–‡ä»¶è¯»å–å’Œè§£æžSampleçš„å…³é”®ã€‚è¿™é‡Œç»™å‡ºæ¯ä¸ªSampleçš„Sizeå³åŒ…å«çš„å­—èŠ‚æ•°ã€‚ åŒ…å«äº†åª’ä½“ä¸­å…¨éƒ¨sampleçš„æ•°ç›®å’Œä¸€å¼ ç»™å‡ºæ¯ä¸ªsampleå¤§å°çš„è¡¨ã€‚è¿™ä¸ªboxç›¸å¯¹æ¥è¯´ä½“ç§¯æ˜¯æ¯”è¾ƒå¤§çš„ã€‚ Stco Boxè¯¥Boxå­˜å‚¨äº†Chunk Offsetï¼Œè¡¨ç¤ºäº†æ¯ä¸ªChunkåœ¨æ–‡ä»¶ä¸­çš„ä½ç½®ï¼Œè¿™æ ·æˆ‘ä»¬å°±èƒ½æ‰¾åˆ°äº†chunkåœ¨æ–‡ä»¶çš„åç§»é‡ï¼Œç„¶åŽæ ¹æ®å…¶å®ƒè¡¨çš„å…³è”å…³ç³»å°±å¯ä»¥è¯»å–æ¯ä¸ªSampleçš„å¤§å°ã€‚ H.264æ•°æ®æ‰“åŒ…MP4æ–‡ä»¶æ­¥éª¤ æž„é€ Ftyp Boxï¼Œè¿™æ˜¯MP4æ–‡ä»¶çš„åŸºæœ¬æ ‡è¯†ï¼ŒåŸºæœ¬æŒ‰ç…§è§„èŒƒæž„é€ å³å¯ï¼› æž„é€ Mdat Boxï¼Œè¿™é‡Œé¢éƒ½æ˜¯éŸ³è§†é¢‘åª’ä½“æ•°æ®ï¼Œå°†NALUæ•°æ®å°è£…æˆä¸€ä¸ªä¸ªSampleï¼Œä»Žä¸Šåˆ°ä¸‹æŽ’åˆ—èµ·æ¥å³å¯ï¼› æž„é€ Moov Box,è¿™ä¸ªBoxï¼Œå…ˆæž„é€ é™¤äº†stblçš„å…¶å®ƒBox,è¿™æ ·ä»Žå­Boxï¼Œä¸€ç›´æŒ‰ç…§å±‚æ¬¡æž„é€ ä¸Šæ¥ï¼Œè¿™äº›Boxçš„åŸºæœ¬ä¿¡æ¯æ˜¯æ˜Žç¡®çš„ï¼Œä¸ªåˆ«ä¿¡æ¯é€šè¿‡è§£æžSPSã€PPSæ˜¯å¯ä»¥æ˜Žç¡®çŸ¥é“çš„ï¼Œæ‰€ä»¥ä¸Šæ–‡å·²ç»æ˜Žç¡®äº†è¿™äº›Boxçš„å­—æ®µï¼Œæ‰€ä»¥æž„é€ èµ·æ¥å¹¶ä¸éš¾ï¼› æž„é€ Moov Boxçš„Stbléƒ¨åˆ†ï¼Œè¿™éƒ¨åˆ†è¦å°è£…ï¼š SPSã€PPSçš„NALUæ•°æ® ä¹Ÿè¦æž„é€ æ—¶é—´æˆ³PTSå’ŒDTSä¿¡æ¯ Sampleçš„å¤§å°å’Œæ•°é‡ Chunkçš„æ•°é‡å’Œåœ¨æ–‡ä»¶åç§»é‡ Sampleå’ŒChunkçš„æ˜ å°„å…³ç³»ç­‰ï¼Œ éœ€è¦ä»”ç»†å¤„ç†ï¼Œä¸€æ—¦æž„é€ é”™è¯¯éƒ½ä¼šæ’­æ”¾å¤±è´¥ï¼› å…¶ä¸­Moovåˆ°åº•æ˜¯æ”¾åˆ°Mdat Boxå‰é¢è¿˜æ˜¯åŽé¢ï¼Œéœ€è¦åœ¨å°è£…æ‰“åŒ…å‰ç¡®å®šåŽï¼Œå› ä¸ºä¼šç‰µä¸€å‘åŠ¨å…¨èº«ï¼Œé‡Œé¢çš„ä¿¡æ¯éƒ½ä¾èµ–åœ¨å…·ä½“æ–‡ä»¶çš„ä½ç½®ï¼Œè‡³äºŽå‰é¢åŽé¢åŒºåˆ«è§ä¸‹ç¯‡æ–‡ç« ï¼› å†å¡«å……ä¸€äº›ä½ æ„Ÿå…´è¶£çš„éžå¿…è¦ä¿¡æ¯Boxï¼Œè‡³æ­¤ç»„è£…æˆæ•´ä¸ªMP4æ–‡ä»¶å³å¯ï¼› reference# MP4æ ¸å¿ƒBoxè¯¦è§£]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>media</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[H264ç¬”è®°]]></title>
    <url>%2F2022%2F10%2F26%2FH264%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[H264H264æ˜¯è§†é¢‘ç¼–ç è§„èŒƒï¼Œåœ¨è¿™ä¸ªè§„èŒƒä¸‹H264ç æµæœ‰ä¸¤ç§æ–¹å¼ï¼šAnnexBæ ¼å¼ &amp;&amp; AVCCæ ¼å¼ AnnexB AnnexB çš„åŽŸç†æ˜¯åœ¨æ¯ä¸ª NALU å‰é¢å†™ä¸Šä¸€ä¸ªç‰¹æ®Šçš„èµ·å§‹ç ï¼Œé€šè¿‡è¿™ä¸ªèµ·å§‹ç æ¥å½“åš NALU çš„åˆ†éš”ç¬¦ï¼Œä»Žè€Œåˆ†å‰²æ¯ä¸ª NALU [start code] NALU [start code] NALU [start code] NALU AVCC avcC åˆ™é‡‡ç”¨äº†å¦å¤–ä¸€ç§æ–¹å¼ã€‚é‚£å°±æ˜¯åœ¨ NALU å‰é¢å†™ä¸Šå‡ ä¸ªå­—èŠ‚ï¼Œè¿™å‡ ä¸ªå­—èŠ‚ç»„æˆä¸€ä¸ªæ•´æ•°ï¼ˆå¤§ç«¯å­—èŠ‚åºï¼‰è¿™ä¸ªæ•´æ•°è¡¨ç¤ºäº†æ•´ä¸ª NALU çš„é•¿åº¦ [extra data] [length] NALU [length] NALU [length] NALU NALUNALU (Network Abstraction Layer Unit) ç¿»è¯‘è¿‡æ¥å°±æ˜¯ç½‘ç»œæŠ½è±¡å±‚å•å…ƒã€‚åœ¨ H.264/AVC è§†é¢‘ç¼–ç æ ‡å‡†ä¸­ï¼Œæœ€å¤–é¢ä¸€å±‚å«åš NAL(Network Abstract Layer) ç½‘ç»œæŠ½è±¡å±‚ã€‚æ‰€æœ‰çš„ç æµæ•°æ®ï¼Œæœ€ç»ˆéƒ½è¢«å°è£…æˆäº†ä¸€ä¸ªä¸€ä¸ªçš„ NALUï¼ˆNetwork Abstract Layer Unitï¼‰å°±æ˜¯ç½‘ç»œæŠ½è±¡å±‚å•å…ƒã€‚ å¯¹åº”çš„NAL è¿˜æœ‰ä¸€ä¸ªè§†é¢‘ç¼–ç å±‚VCL(video code layer)ï¼Œè§†é¢‘ç¼–ç åŽçš„åŽŸå§‹æ•°æ® SODB ï¼ˆString Of Data Bitsï¼‰ è§†é¢‘ç¼–ç å±‚ï¼ˆVCLï¼‰ï¼Œæ˜¯å¯¹è§†é¢‘ç¼–ç æ ¸å¿ƒç®—æ³•è¿‡ç¨‹ã€å­å®å—ã€å®å—ã€ç‰‡ç­‰æ¦‚å¿µçš„å®šä¹‰ã€‚è¿™å±‚ä¸»è¦æ˜¯ä¸ºäº†å°½å¯èƒ½çš„ç‹¬ç«‹äºŽç½‘ç»œæ¥é«˜æ•ˆçš„å¯¹è§†é¢‘å†…å®¹è¿›è¡Œç¼–ç ã€‚ç¼–ç å®ŒæˆåŽï¼Œè¾“å‡ºçš„æ•°æ®æ˜¯ SODBï¼ˆString Of Data Bitsï¼‰ã€‚ ç½‘ç»œé€‚é…å±‚ï¼ˆNALï¼‰ï¼Œæ˜¯å¯¹å›¾åƒåºåˆ—ã€å›¾åƒç­‰ç‰‡çº§åˆ«ä»¥ä¸Šçš„æ¦‚å¿µçš„å®šä¹‰ã€‚è¿™å±‚è´Ÿè´£å°† VCL äº§ç”Ÿçš„æ¯”ç‰¹å­—ç¬¦ä¸²é€‚é…åˆ°å„ç§å„æ ·çš„ç½‘ç»œå’Œå¤šå…ƒçŽ¯å¢ƒä¸­ã€‚è¯¥å±‚å°† VCL å±‚è¾“å‡ºçš„ SODB æ•°æ®æ‰“åŒ…æˆ RBSPï¼ˆRaw Byte Sequence Payloadï¼‰ã€‚SODB æ˜¯ç¼–ç åŽçš„åŽŸå§‹æ•°æ®ï¼ŒRBSP æ˜¯åœ¨åŽŸå§‹ç¼–ç æ•°æ®åŽé¢æ·»åŠ äº†ç»“å°¾æ¯”ç‰¹ï¼Œä¸€ä¸ªæ¯”ç‰¹ 1 å’Œè‹¥å¹²ä¸ªæ¯”ç‰¹ 0ï¼Œç”¨äºŽå­—èŠ‚å¯¹é½ã€‚ç„¶åŽå†åœ¨ RBSP å¤´éƒ¨åŠ ä¸Š NAL Header æ¥ç»„æˆä¸€ä¸ªä¸€ä¸ªçš„ NAL å•å…ƒã€‚ sps &amp; ppsSPSï¼ˆSequence Paramater Setï¼‰ åºåˆ—å‚æ•°é›† PPSï¼ˆPicture Paramater Setï¼‰ å›¾åƒå‚æ•°é›† SPS å’Œ PPS å­˜æ”¾çš„çš„ä¿¡æ¯æ˜¯ç æµä¸­çš„å‚æ•°ä¿¡æ¯ï¼ŒåŽç»­çš„è§£ç æµç¨‹æ˜¯è¦ä¾èµ–ç€é‡Œé¢çš„å‚æ•°çš„ï¼Œæ‰€ä»¥è§£ç å™¨åœ¨è§£ç ä¸€è·¯ç æµçš„æ—¶å€™ï¼Œæ€»æ˜¯è¦é¦–å…ˆè¯»å…¥ SPS å’Œ PPS AnnexB æ ¼å¼çš„ç æµï¼Œsps è·Ÿ pps æ˜¯ä½œä¸ºnaluå­˜åœ¨çš„ï¼Œä¸€èˆ¬éƒ½æœ€å‰é¢AVCCæ ¼å¼çš„ç æµï¼Œsps è·Ÿ pps æ˜¯æ”¾åœ¨extra dataä¸­ã€‚ NALU header nalu çš„ç¬¬ä¸€ä¸ªå­—èŠ‚ï¼Œå…¶å®žå°±æ˜¯nalu header forbidden_zero_bit nal_ref_idc nal_unit_type forbidden_zero_bit å ç”¨ 1 ä½ï¼Œnal_ref_idc å ç”¨ 2 ä½ï¼Œnal_unit_type å ç”¨ 5 ä½ã€‚ä¸‰ä¸ªå…ƒç´ ä¸€å…±å ç”¨ 8 ä½ï¼Œä¹Ÿå°±æ˜¯ä¸€ä¸ªå­—èŠ‚ forbidden_zero_bit ç¦æ­¢ä½ï¼Œæ­£å¸¸æƒ…å†µä¸‹ä¸º 0ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¦‚æžœ NALU å‘ç”Ÿä¸¢å¤±æ•°æ®çš„æƒ…å†µï¼Œå¯ä»¥å°†è¿™ä¸€ä½ç½®ä¸º 1ï¼Œä»¥ä¾¿æŽ¥æ”¶æ–¹çº é”™æˆ–ä¸¢æŽ‰è¯¥å•å…ƒ nal_ref_idc è¯¥å…ƒç´ è¡¨ç¤ºè¿™ä¸ª NALU çš„é‡è¦æ€§ã€‚å¯èƒ½çš„å€¼æœ‰ 4 ä¸ªï¼Œè¶Šé‡è¦çš„ NALU è¶Šä¸èƒ½ä¸¢å¼ƒ nal_ref_idc é‡è¦æ€§ 3 HIGHEST 2 HIGH 1 LOW 0 DISPOSABLE nal_unit_type nal_unit_type NALU ç±»åž‹ 0 æœªå®šä¹‰ 1 éž IDR SLICE slice_layer_without_partitioning_rbsp( ) 2 éž IDR SLICEï¼Œé‡‡ç”¨ A ç±»æ•°æ®åˆ’åˆ†ç‰‡æ®µ slice_data_partition_a_layer_rbsp( ) 3 éž IDR SLICEï¼Œé‡‡ç”¨ B ç±»æ•°æ®åˆ’åˆ†ç‰‡æ®µ slice_data_partition_b_layer_rbsp( ) 4 éž IDR SLICEï¼Œé‡‡ç”¨ C ç±»æ•°æ®åˆ’åˆ†ç‰‡æ®µ slice_data_partition_c_layer_rbsp( ) 5 IDR SLICE slice_layer_without_partitioning_rbsp( ) 6 è¡¥å……å¢žå¼ºä¿¡æ¯ SEI sei_rbsp( ) 7 åºåˆ—å‚æ•°é›† SPS seq_parameter_set_rbsp( ) 8 å›¾åƒå‚æ•°é›† PPS pic_parameter_set_rbsp( ) 9 åˆ†éš”ç¬¦ access_unit_delimiter_rbsp( ) 10 åºåˆ—ç»“æŸç¬¦ end_of_seq_rbsp( ) 11 ç æµç»“æŸç¬¦ end_of_stream_rbsp( ) 12 å¡«å……æ•°æ® filler_data_rbsp( ) 13 åºåˆ—å‚æ•°æ‰©å±•é›† seq_parameter_set_extension_rbsp( ) 14~18 ä¿ç•™ 19 æœªåˆ†å‰²çš„è¾…åŠ©ç¼–ç å›¾åƒçš„ç¼–ç æ¡å¸¦ slice_layer_without_partitioning_rbsp( ) 20~23 ä¿ç•™ 24~31 æœªæŒ‡å®š sliceæˆ‘ä»¬ä¹‹å‰ä»‹ç»è¿‡ SPS å’Œ PPSï¼ŒSPS å’Œ PPS ä¸­å‚¨å­˜çš„ä¿¡æ¯æ˜¯ä¸€äº›å‚æ•°é¡¹ï¼Œä¾‹å¦‚ï¼Œå›¾åƒçš„é•¿å®½ï¼Œå›¾åƒçš„ profile ä¿¡æ¯ç­‰ã€‚é‚£ä¹ˆåœ¨ Slice ä¸­ï¼Œå­˜æ”¾çš„ä¿¡æ¯å°±æ˜¯ç¼–ç åŽçš„å›¾åƒä¿¡æ¯äº†ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œè§£ç  Sliceï¼Œæˆ‘ä»¬å°±èƒ½è¿˜åŽŸå‡ºæ¥å›¾åƒäº†ã€‚ ä¸€ä¸ª Slice é€šå¸¸è¢«åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼ŒSlice Header å’Œ Slice Body Slice Header Slice Body slice_type å€¼ å«ä¹‰ 0 P(P Slice) 1 B(B Slice) 2 I(I Slice) 3 SP(SP Slice) 4 SI(SI Slice) 5 P(P Slice) 6 B(B Slice) 7 I(I Slice) 8 SP(SP Slice) 9 SI(SI Slice) å¯ä»¥çœ‹åˆ° slice_type è§„å®šäº† slice çš„ç±»åž‹ï¼Œè¿™ä¹Ÿè§£é‡Šäº†ä¹‹å‰çš„ä¸€äº›è¯¯åŒºã€‚æœ‰äººè¯´æ ¹æ® NALU çš„ç±»åž‹å°±èƒ½åˆ¤è¯»æ˜¯ I Slice è¿˜æ˜¯ P Slice è¿˜æ˜¯ B Sliceã€‚å…¶å®žæ˜¯é”™è¯¯çš„ï¼Œè¦åˆ¤æ–­è¿™äº›å¿…é¡»è¦è¯»åˆ° slice_type æ‰è¡Œ pic_parameter_set_id slice_type ä¹‹åŽï¼Œæ˜¯ pic_parameter_set_idï¼Œè¿™ä¸ªå±žæ€§è¡¨æ˜Žè¯¥ Slice è¦ä¾èµ–çš„ PPS çš„ idã€‚æˆ‘ä»¬åœ¨è§£æž PPS çš„æ—¶å€™ï¼ŒPPS é‡Œé¢æœ‰ä¸€ä¸ª pic_parameter_set_id çš„å±žæ€§ã€‚å½“ä½ è§£æžå‡º Slice ä¸­çš„ pic_parameter_set_id ä¹‹åŽï¼Œæ‹¿ç€è¿™ä¸ª id æ‰¾åˆ°ä¸Žä¹‹å¯¹åº”çš„ PPS å°±å¯ä»¥äº†ã€‚ç„¶åŽ PPS é‡Œè¿˜æœ‰ä¸ª seq_parameter_set_idï¼Œç”¨è¿™ä¸ª id å°±å¯ä»¥æ‰¾åˆ°ä¾èµ–çš„ SPS çš„ idã€‚è¿™æ ·ï¼Œä½ å°±å¯ä»¥ä¸ºè¿™ä¸ª Slice æŸ¥æ‰¾åˆ°åˆé€‚çš„ SPS å’Œ PPS äº†ã€‚ MP4h264ç¼–ç ä¹‹åŽçš„ç æµï¼Œæœ€ç»ˆè¿˜æ˜¯ä¼šå°è£…åˆ°å„ç§åª’ä½“æ–‡ä»¶ä¸­ï¼Œè¿™é‡Œå°±åªäº†è§£ä¸‹æœ€å¸¸ç”¨çš„mp4. Mdat Boxè¿™ä¸ªBoxæ˜¯å­˜å‚¨éŸ³è§†é¢‘æ•°æ®çš„Boxï¼Œè¦ä»Žè¿™ä¸ªBoxè§£å°è£…å‡ºçœŸå®žçš„åª’ä½“æ•°æ®ã€‚å½“ç„¶è¿™ä¸ªBoxä¸€èˆ¬éƒ½ä¼šå­˜åœ¨ï¼Œä½†æ˜¯ä¸æ˜¯å¿…é¡»çš„ã€‚ä½†æ˜¯åœ¨MP4æ ¼å¼æ–‡ä»¶ä¸­ï¼ŒH264 sliceå¹¶ä¸æ˜¯ä»¥00 00 00 01 Start Codeæ¥è¿›è¡Œåˆ†å‰²ï¼Œè€Œæ˜¯å­˜å‚¨åœ¨Mdat Boxçš„Dataä¸­ã€‚ Mdat Boxçš„æ ¼å¼ï¼š Box header + Box Data Box length + Box Type + NALU length + NALU header + Nalu Dataâ€¦â€¦. NALU length + NALU header + Nalu Data Mdaté‡Œçš„NALUä¸€èˆ¬ä¸å†åŒ…å«SPS PPSç­‰æ•°æ®ï¼Œè¿™äº›æ•°æ®å·²ç»æ”¾åˆ°Moov Boxé‡Œé¢äº† mp4é‡Œçš„NALUå…¶å®žå°±æ˜¯AVCCæ ¼å¼çš„ referencesæ·±å…¥æµ…å‡ºç†è§£è§†é¢‘ç¼–ç  H264 ç»“æž„æœ€è¯¦å°½çš„ H.264 ç¼–ç ç›¸å…³æ¦‚å¿µä»‹ç»è‡ªå·±åŠ¨æ‰‹å†™ H.264 è§£ç å™¨H.264 åª’ä½“æµ AnnexB å’Œ AVCC æ ¼å¼åˆ†æž åŠ FFmpeg è§£æžmp4çš„H.264ç æµæ–¹æ³•]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>media</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å½¢çŠ¶ç‰¹æ•ˆ]]></title>
    <url>%2F2022%2F10%2F14%2F%E5%BD%A2%E7%8A%B6%E7%89%B9%E6%95%88%2F</url>
    <content type="text"><![CDATA[å½¢çŠ¶ç‰¹æ•ˆåˆæ¬¡æŽ¥è§¦åˆ°å½¢çŠ¶ç‰¹æ•ˆæ˜¯åœ¨å‰ªæ˜ ï¼Œå‰ªæ˜ ä¸­å«è’™ç‰ˆï¼Œå°±æ˜¯åˆ—ä¸¾äº†ä¸€äº›å¸¸è§å½¢çŠ¶çš„è’™å±‚æ•ˆæžœï¼Œé™¤äº†å¸¸è§„çš„æ—‹è½¬ã€ç¼©æ”¾ã€ä½ç§»ç­‰æ“ä½œå¤–ï¼Œè¿˜æœ‰ä¸ªè™šåŒ–çš„æ•ˆæžœã€‚å¯ä»¥åŽ»å‰ªæ˜ æ„Ÿå—ä¸‹ã€‚ æŽ¥è§¦åˆ°è¿™ä¸œè¥¿ï¼Œè§‰å¾—æ•ˆæžœæŒºä¸é”™ï¼Œæ‰“ç®—ç ”ç©¶ä¸‹ï¼Œæ­£å¥½æ‰‹å¤´çš„ç¼–è¾‘å·¥å…·é¡¹ç›®ä¹Ÿå¯ä»¥ç”¨ä¸Šã€‚çº¿æ€§ã€åœ†å½¢ã€çŸ©å½¢ï¼Œè¿™å‡ ä¸ªè§„èŒƒçš„ï¼Œé€šè¿‡å¹³æ–¹æ ¹å…¬å¼ è·Ÿ ä¸‰è§’å½¢ä½™å¼¦å®šç†åŸºæœ¬éƒ½å¯ä»¥æŽ¨ç®—å‡ºæ¥(å¯ä»¥å‚è€ƒgithub shader)ï¼Œé‡ç‚¹æ¥äº†ï¼Œçˆ±å¿ƒ &amp; äº”è§’æ˜Ÿ æ€Žä¹ˆæžï¼Ÿ ç‰¹æ®Šå½¢çŠ¶çˆ±å¿ƒ ã€äº”è§’æ˜Ÿï¼Œä¸€å¼€å§‹è§‰å¾—å¯èƒ½æ˜¯é€šè¿‡ ä¸‰è§’å‡½æ•°ã€å…³é”®ç‚¹ã€è´å¡žå°”æ›²çº¿ ç­‰æ•°å­¦è®¡ç®—å®žçŽ°çš„ï¼Ÿ æƒ³æƒ³è§‰å¾—è¿™æ ·æ˜¯ä¸æ˜¯è¿‡äºŽå¤æ‚ï¼Œ ä¸€ç¿»googleä¹‹åŽï¼Œè¿˜æ˜¯æ²¡å•¥æ€è·¯ã€‚æ”¾å¤§æ‹›æŠ“åŒ…ï¼Œå‰ªæ˜ çš„ç´ æéƒ½æ˜¯ä¸‹å‘çš„ï¼Œå¿…ç„¶ä¼šæœ‰ç½‘ç»œè¯·æ±‚çš„ï¼Œä¸€é¡¿æ“ä½œä¹‹åŽï¼Œå¦‚æ„¿æ‹¿åˆ°äº†èµ„æºåŒ…ã€‚ çˆ±å¿ƒ äº”è§’æ˜Ÿ çœ‹åˆ°äº†è¿™ä¸¤ä¸ªï¼Œå¾ˆæ˜Žæ˜¾ä¸æ˜¯é€šè¿‡å¤æ‚æ•°å­¦è®¡ç®—å¾—åˆ°çš„ã€‚ ä½†æ˜¯è¿™ä¸€å±‚ä¸€å±‚çš„æ¸å˜çº¢ç»¿å›¾ æ˜¯ä»€ä¹ˆé¬¼ï¼Ÿèµ„æºåŒ…é‡Œè¿˜æœ‰shaderæ–‡ä»¶çš„ðŸ˜„ float alpha = (col.r * 4.0 * 256.0 + col.g * 255.0) / 781.0; é‡ç‚¹çš„å°±æ˜¯è¿™è¡Œè®¡ç®—é€»è¾‘ï¼Œè¿˜æ˜¯æ‡µçš„ã€‚ col.r col.g å¯¹åº”å›¾ä¸Šçš„çº¢ç»¿åˆ†é‡å¯ä»¥ç†è§£*4 /781 æ˜¯ä»€ä¹ˆé¬¼ï¼Ÿ 4 å¯¹åº” å›¾ä¸Šçš„å››å±‚? ç”¨é¢œè‰²å–è‰²å™¨å–è‰²çœ‹çœ‹ï¼Œè¿™ä¸€çœ‹å°±æ˜Žç™½äº†ã€‚ 1234567ç¬¬1å±‚c00d00 ç¬¬2å±‚800000~80ff00 ç¬¬3å±‚400000~40ff00 ç¬¬4å±‚000000~00ff00R * 4 + G ç®—ä¸‹æ¥ ä»Ž 0 åˆ° 781 781 = 12(c0) * 16 * 4 + 13(0d) æ¯å±‚çº¢è‰²åˆ†é‡å›ºå®š(00/40/80/c0)ï¼Œç»¿è‰²åˆ†é‡æ¸å˜0åˆ°255(00-ff)ï¼Œæ‰€ä»¥æ•´ä¸ªå›¾å±‚è§£æžä¸‹æ¥å°±æ˜¯ ä»Ž0 åˆ° 781. alpha è®¡ç®—ä¸‹æ¥å°±æœ‰ 256 *3 + 1 = 769 ä¸ªå€¼ï¼Œæœ€é‡Œé¢çš„ä¸€å±‚æœ€å°çš„ï¼Œå›ºå®šä¸º1ï¼Œä¿éšœæ— è™šåŒ–çš„æ—¶å€™ä¹Ÿæœ‰æœ€åŸºæœ¬çš„å½¢çŠ¶æ•ˆæžœã€‚ æžæ˜Žç™½ä¹‹åŽï¼Œé¡¿æ—¶è§‰å¾—ç§’å•Šï¼Œ å›žå¤´ä¸€æƒ³ï¼Œä¸ºä»€ä¹ˆè¦æžçš„é‚£ä¹ˆå¤šå¤æ‚å‘¢ï¼Ÿ åæ­£æ˜¯ä¸ºäº†è®¡ç®—alphaï¼Œç›´æŽ¥æžä¸ªç°åº¦å›¾ ä»Žé»‘åˆ°ç™½ï¼Œä¸å°±å¥½äº†ï¼Ÿä»”ç»†ä¸€æƒ³ï¼Œç°åº¦å›¾ä¸€ä¸ªåˆ†é‡æœ€å¤š256ä¸ªï¼Œæœ€ç»ˆçš„æ•ˆæžœå‰²è£‚æ„Ÿä¼šå¾ˆæ˜Žæ˜¾ï¼Œæ‰€ä»¥ç”¨åˆ°äº†rã€g ä¸¤ä¸ªåˆ†é‡ï¼Œè®©æ•ˆæžœæ›´ä¸æ»‘ï¼Œå®žé™…ä¸Šå¦‚æžœä½ æƒ³ ä¹Ÿå¯ä»¥ç”¨rbgä¸‰ä¸ªåˆ†é‡ï¼Œé‡æ–°è®¾è®¡ä¸‹è®¡ç®—å…¬å¼ è®©èŒƒå›´æ›´å¤§æ›´ä¸æ»‘ã€‚ ä¸¾ä¸€åä¸‰å­¦ä»¥è‡´ç”¨ï¼Œé‚£å¿…é¡»ä¸¾ä¸€åä¸‰ä¸‹äº†ã€‚ èŠ±åž‹ ç”¨äº”è§’æ˜Ÿå›¾åŽ»æ‰¾è®¾è®¡å¸ˆï¼Œå‚è€ƒä¸€ä¸‹åšä¸€ä¸ªèŠ±åž‹çš„ã€‚è®¾è®¡å¸ˆä¹Ÿä¸€ä¸‹æ²¡æŽŒæ¡ç²¾é«“ï¼Œç…§ç€æžäº†ä¸€ä¸ªä½†ä¸æ˜¯æˆ‘æƒ³è¦çš„ã€‚æ‰€ä»¥æœ‰äº†äººç”Ÿç¬¬ä¸€æ¬¡æŒ‡å¯¼è®¾è®¡å¸ˆç”»å›¾äº†ï¼Œä¸€ç¿»æ“ä½œä¹‹åŽ æžå®šäº† æœ€åŽçš„shader 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#iUniform float iReverse = 0.#iUniform float _X = 0.5#iUniform float _Y = 0.5#iUniform float _S = 0.25#iUniform float _A = 0.#iUniform float _F = 0.00#iUniform float iPlatform_iOS = 1.0const float PI = 3.1415926;#iChannel0 &quot;file://followw813654.jpeg&quot;#iChannel1 &quot;file://mask1.png&quot;vec2 rotation(vec2 uv, float angle, float ratio)&#123; vec2 center = vec2(0.5, 0.5); mat2 zRotation = mat2(cos(angle), sin(angle), -sin(angle) * ratio, cos(angle) * ratio); vec2 centeredPoint = uv - center; vec2 newUv = zRotation * centeredPoint; return vec2(newUv.x, newUv.y / ratio) + center;&#125;vec2 scale(vec2 uv, vec2 scale)&#123; vec2 newPos = vec2(0.5) + (uv - vec2(0.5)) / scale; return newPos;&#125;vec2 offset(vec2 uv, vec2 offset)&#123; return uv + offset;&#125;void main()&#123; highp vec2 textureCoordinate = gl_FragCoord.xy/iResolution.xy; float radio = iResolution.x / iResolution.y; bool ls = (radio &gt; 1.0); vec4 base = texture(iChannel0, textureCoordinate); float _Radio = 1.0; float _Scale = _S * 5.; _Scale = ls ? _Scale / radio : _Scale; float _Angle = 360. * PI / 180. * _A; vec2 _Offset = vec2(_X * 2.0 - 1.0, (_Y * 2.0 - 1.0)); vec2 newUV = offset(textureCoordinate, vec2(-_Offset.x, _Offset.y)); newUV = scale(newUV, vec2(1. * _Scale, radio * _Scale)); newUV = rotation(newUV, _Angle, _Radio); newUV.y = (iPlatform_iOS == 1.) ? newUV.y : (1. - newUV.y); vec4 mask = texture(iChannel1, newUV) * step(newUV.x, 1.) * step(newUV.y, 1.) * step(0., newUV.x) * step(0., newUV.y); vec2 col = mask.rg; // æ€Žä¹ˆç†è§£ ï¼Ÿ æ ¹æ® maskå›¾çš„ ä½œå›¾é¢œè‰²æ­é… åŠ¨æ€è°ƒæ•´ // ç¬¬1å±‚c00d00 ç¬¬2å±‚800000~80ff00 ç¬¬3å±‚400000~40ff00 ç¬¬4å±‚000000~00ff00 // R * 4 + G ç®—ä¸‹æ¥ ä»Ž 0 åˆ° 781 // 781 = 12 * 16 * 4 + 13 float alpha = (col.r * 4.0 * 256.0 + col.g * 255.0) / 781.0; alpha = smoothstep(0.49 - abs(sin(iTime/2.)), 0.51 + abs(sin(iTime/2.)), alpha); if (iReverse &gt; .5) &#123; alpha = 1.0 - alpha; &#125; gl_FragColor = mix(vec4(0, 0, 0, alpha), base, alpha);&#125; å®Œæ•´æ•ˆæžœ]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>media</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[åŠ¨æ€æ»¤é•œ]]></title>
    <url>%2F2022%2F10%2F14%2F%E5%8A%A8%E6%80%81%E6%BB%A4%E9%95%9C%2F</url>
    <content type="text"><![CDATA[æ»¤é•œéŸ³è§†é¢‘ç¼–è¾‘å·¥å…·ä¸­ï¼Œå¯¹å›¾åƒæˆ–è€…è§†é¢‘åŠ æ»¤é•œæ˜¯ä¸€ç§å¸¸è§çš„åšæ³•ï¼Œæ™®é€šæ»¤é•œå¾ˆå¥½ç†è§£ï¼Œä¸€å¼ LUTå›¾å°±æžå®šäº†ï¼ŒLUTå›¾ä¸€èˆ¬è®¾è®¡å¸ˆä¼šæä¾›å¥½ï¼Œå¼€å‘æ‹¿è¿‡æ¥è½¬æˆçº¹ç†ï¼Œopenglåšä¸‹é¢œè‰²è½¬æ¢å°±å¥½äº†ï¼Œè¿™é‡Œå°±ä¸å¤šè¯´äº†ã€‚ ä½†æ˜¯ä»Šå¤©æƒ³è®²çš„æ˜¯åŠ¨æ€æ»¤é•œï¼Œä¹Ÿæœ‰å«ç‰¹æ•ˆçš„ï¼ŒåŠ¨æ•ˆç­‰ç­‰ã€‚æ¯”å¦‚å°çº¢ä¹¦/å‰ªæ˜  ç­‰ç­‰,æ„Ÿå—ä¸€ä¸‹å°±å¤§æ¦‚çŸ¥é“äº†ã€‚ åŠ¨æ€æ»¤é•œå…ˆä¸Šä¸€ä¸ªæ•ˆæžœæ„Ÿå—ä¸‹ï¼š è§†é¢‘ï¼š å¾ˆæ˜Žæ˜¾åŠ¨æ€æ»¤é•œè·Ÿæ™®é€šæ»¤é•œæ ¹æœ¬ä¸Šå°±ä¸æ˜¯ä¸€å›žäº‹äº†ï¼Œæ‰€ä»¥æ›´åƒæ˜¯åŠ¨æ•ˆ ç‰¹æ•ˆäº†ï¼Œè¿™é‡Œä¸çº ç»“å«ä»€ä¹ˆï¼Œé‡ç‚¹æ˜¯å…³æ³¨ä¸‹æ€Žä¹ˆåšçš„å‘¢ï¼Ÿç›´è§‚æ„Ÿå—å°±æ˜¯é™æ€å›¾ç‰‡ä¸Šè¦†ç›–äº†ä¸€å¸§å¸§çš„é€æ˜Žå›¾ç‰‡ï¼Œç¡®å®žå°±æ˜¯è¿™ä¹ˆä¸€å›žäº‹ã€‚ ç”¨ä¸€å¸§å¸§çš„å¸¦alphaé€šé“çš„å›¾ç‰‡é›†ï¼Œé€šè¿‡opengl blendä¸€å¸§å¸§èžåˆä¹Ÿå¯ä»¥å®žçŽ°ï¼Œ å¼Šç«¯å¾ˆæ˜Žæ˜¾ï¼Œè™½ç„¶è¿™ç§åŠ¨æ€æ•ˆæžœä¸€èˆ¬ä¹Ÿåªæœ‰å‡ ç§’ï¼ŒæŒ‰30fpsï¼Œä¹Ÿéœ€è¦ç™¾æ¥å¼ å›¾ï¼Œå›¾ç‰‡èµ„æºå¾ˆå¤§ï¼Œgifæ ¼å¼ä¹Ÿä¼šå­˜åœ¨åŒæ ·çš„é—®é¢˜ã€‚å¦‚æžœç”¨è§†é¢‘å‘¢ï¼Ÿ ä½†æ˜¯è§†é¢‘æ²¡æœ‰alphaé€šé“ã€‚ã€‚ æ–¹æ¡ˆå‚è€ƒè…¾è®¯åŠ¨ç”»æ–¹æ¡ˆ vap æˆ‘ä»¬ç”¨ä¸€ç§ç‰¹æ®Šçš„è§†é¢‘ï¼Œè§†é¢‘çš„ä¸€åŠè¡¨ç¤ºrgb å¦ä¸€åŠè¡¨ç¤ºalphaé€šé“ã€‚ è¡¨ç¤ºalphaé€šé“çš„ rgb ä¸‰ä¸ªåˆ†é‡å€¼ä¸€æ ·ï¼Œæ‰€ä»¥æ˜¯ç°åº¦å›¾æ•ˆæžœï¼ŒçŸ¥é“è¿™ç§ç‰¹æ®Šçš„è§†é¢‘æž„æˆ æŽ¥ä¸‹æ¥å°±å¥½å¤„ç†äº† 123456789101112( precision mediump float; varying highp vec2 textureCoordinate; uniform sampler2D inputImageTexture; void main() &#123; vec4 textureColor = texture2D(inputImageTexture,textureCoordinate); vec4 leftColor = texture2D(inputImageTexture,vec2(textureCoordinate.x / 2.0,textureCoordinate.y)); vec4 rightColor = texture2D(inputImageTexture,vec2(textureCoordinate.x / 2.0 + 0.5,textureCoordinate.y)); gl_FragColor = vec4(leftColor.rgb * rightColor.b ,rightColor.b); &#125;); å®žé™…åº”ç”¨ä¸­ï¼Œå€Ÿç”¨GPUImageMoiveæ¥è§£ç ä¸€åŠä¸€åŠçš„è§†é¢‘ï¼Œç„¶åŽè‡ªå®šä¹‰filterï¼Œfragmentshader å°±æ˜¯ä¸Šé¢çš„è¿™æ®µï¼Œæœ€åŽæ¸²æŸ“åˆ°GPUImageViewä¸Šï¼Œå°±è¾¾åˆ°äº†åœ¨é™æ€å›¾ç‰‡ä¸Šæ’­æ”¾é€æ˜Žè§†é¢‘çš„æ•ˆæžœã€‚ 12345678910111213141516171819@interface GPUImageCustomFilter : GPUImageFilter@end@implementation GPUImageCustomFilter- (id)init &#123; if (self = [super initWithFragmentShaderFromString:kGPUImageCustomFragmentShaderString]) &#123; &#125; return self;&#125;/// size width / 2- (void)setInputSize:(CGSize)newSize atIndex:(NSInteger)textureIndex &#123; [super setInputSize:CGSizeMake(newSize.width / 2.0, newSize.height) atIndex:textureIndex];&#125;@end ä½¿ç”¨customFilter 123456789101112131415161718NSURL *url = [NSURL fileURLWithPath:videoPath];CGRect frame = previewView.bounds;GPUImageView *gpuImageView = [[GPUImageView alloc] init];gpuImageView.backgroundColor = [UIColor clearColor];gpuImageView.fillMode = kGPUImageFillModePreserveAspectRatioAndFill;gpuImageView.frame = frame;GPUImageMovie *movie = [[GPUImageMovie alloc] initWithURL:url];movie.shouldRepeat = YES;movie.playAtActualSpeed = YES;movie.runBenchmark = YES;GPUImageCustomFilter *customFilter = [[GPUImageCustomFilter alloc] init];[movie addTarget:customFilter];[customFilter addTarget:gpuImageView];[movie startProcessing];]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>media</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å›¾åƒæè¾¹]]></title>
    <url>%2F2022%2F09%2F10%2F%E5%9B%BE%E5%83%8F%E6%8F%8F%E8%BE%B9%2F</url>
    <content type="text"><![CDATA[image borderæœ€è¿‘é¡¹ç›®ä¸­æžäº†ä¸ªå›¾åƒæè¾¹çš„éœ€æ±‚ï¼Œå¸¸è§çš„ç¾Žå›¾å·¥å…·Appéƒ½æœ‰ç±»ä¼¼çš„åŠŸèƒ½ï¼Œå…¸åž‹çš„å¦‚ç¾Žå›¾ç§€ç§€ï¼Œä¸€å¼€å§‹è§‰å¾—åº”è¯¥ä¸å¤ªå¤æ‚ï¼Œæ­£å¸¸è¯„ä¼°æ—¶é—´ï¼Œå®žé™…åšçš„æ—¶å€™ï¼Œå‘çŽ°é—®é¢˜æ¯”æƒ³è±¡ä¸­çš„å¤æ‚å¤šäº†ï¼Œç»“æžœé¡¹ç›®ä¸å¾—ä¸å»¶æœŸ ðŸ˜­ï¼Œæ‰€ä»¥æœ‰å¿…è¦æžç¯‡æ–‡ç« æ¥æ€»ç»“ä¸‹æ•™è®­ã€‚ å…ˆè¯´æ•´ä½“çš„æµç¨‹ï¼š 1ã€åŽŸå›¾ -&gt; 2ã€æŠ å›¾ -&gt; 3ã€è¾¹ç¼˜æ£€æµ‹ -&gt; 4ã€ç»˜åˆ¶è¾¹ç¼˜ -&gt; 5ã€ç»“æžœå¯¼å‡º è¿™ä¸ªæµç¨‹è¿˜æ˜¯å¾ˆå®¹æ˜“æƒ³åˆ°ï¼Œä½†æ˜¯é™¤äº†æœ€åŽä¸€æ­¥ç›¸å¯¹æ¥è¯´å®¹æ˜“ç‚¹ï¼Œ2ã€3ã€4éƒ½æ˜¯ä¸€è·¯å‘ ðŸ˜ž image mattingé¦–å…ˆæ˜¯æŠ å›¾ï¼Œå°±æ˜¯è¿™æ ·çš„ è·Ÿæˆ‘ä»¬è¿™è¾¹çš„ç®—æ³•åŒå­¦å¯¹æŽ¥ï¼Œçˆ¬è™«æ”¶é›†å›¾åƒã€æ ‡æ³¨ã€æ¨¡åž‹è®­ç»ƒ ä¸€å¥—ç»„åˆä¸‹æ¥ï¼Œæ•ˆæžœä¸ç†æƒ³ï¼Œç”Ÿäº§çŽ¯å¢ƒä¸å¯ç”¨ï¼Œç¬¬ä¸€æ­¥å°±å¡ä½äº† ðŸ˜ž ä¸ºäº†èµ¶é¡¹ç›®å‘¨æœŸï¼Œæœ€åŽä½¿ç”¨äº†é˜¿é‡Œäº‘çš„æ–¹æ¡ˆï¼Œè¿™é‡Œå°±ä¸å¤šè¯´äº†ï¼Œç®—æ³•åŒå­¦æŒç»­ä¼˜åŒ–æ¨¡åž‹ï¼Œå¾…æˆç†Ÿä¹‹åŽæ›¿æ¢é˜¿é‡Œäº‘ã€‚ Edge detectionè¿™ä¸€æ­¥ç›¸å¯¹æ¥è¯´æ˜¯æœ€å¤æ‚çš„ï¼Œè¿™é‡Œé‡åˆ°çš„é—®é¢˜ä¹Ÿæ˜¯æœ€å¤§ï¼Œè€—æ—¶æœ€ä¹… æœ€åˆçš„æ–¹æ¡ˆå¤§è‡´æ˜¯è¿™æ ·çš„ï¼šæŠ å›¾ç»“æžœ-&gt;é‡‡æ ·ç¼©æ”¾å›¾åƒ-&gt;éåŽ†å›¾åƒbitmapå–æ»¡è¶³æ¡ä»¶çš„ç‚¹ï¼Œæ¡ä»¶ç®€å•çš„ç†è§£å°±æ˜¯ç‚¹å‘¨å›´3x3èŒƒå›´çš„ç‚¹åƒç´ å€¼å–å¹³å‡å€¼ã€‚ä¸ºä»€ä¹ˆè¦æ£€æµ‹è¾¹ç¼˜ï¼Œæ˜¯å› ä¸ºè¦åšè™šçº¿æè¾¹ï¼ŒèŽ·å–è¿žç»­çš„è¾¹ç¼˜ç‚¹ä¹‹åŽç„¶åŽåœ¨ç”»å¸ƒä¸Šè¿žæŽ¥ç‚¹ç”»å‡ºæ¥ã€‚ ä»£ç å¤§æ¦‚æ˜¯è¿™æ ·çš„â€¦ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647+ (NSArray *)imageFindContours:(UIImage *)image &#123; NSMutableArray *points = [[NSMutableArray array] init]; UIImage *newImage = [image mediumResolution:CGSizeMake(30, 30)]; CFDataRef imageData = CGDataProviderCopyData(CGImageGetDataProvider(newImage.CGImage)); const uint8_t *data = CFDataGetBytePtr(imageData); int w = newImage.size.width; int h = newImage.size.height; unsigned char *bitmap = malloc(w * h * 4); memcpy(bitmap, data, w * h * 4); CGFloat leftmost = 1; CGFloat rightmost = 0; for (int i = 1; i &lt; h - 1; i += 2) &#123; for (int j = 1; j &lt; w - 1; j += 2) &#123; unsigned int left = [WDImageBorder valueForBitmap:data stride:w position:CGPointMake(i, j) offsets:CGSizeMake(-1, 0)]; unsigned int right = [WDImageBorder valueForBitmap:data stride:w position:CGPointMake(i, j) offsets:CGSizeMake(1, 0)]; unsigned int up = [WDImageBorder valueForBitmap:data stride:w position:CGPointMake(i, j) offsets:CGSizeMake(0, -1)]; unsigned int down = [WDImageBorder valueForBitmap:data stride:w position:CGPointMake(i, j) offsets:CGSizeMake(0, 1)]; unsigned int leftUp = [WDImageBorder valueForBitmap:data stride:w position:CGPointMake(i, j) offsets:CGSizeMake(-1, -1)]; unsigned int rightUp = [WDImageBorder valueForBitmap:data stride:w position:CGPointMake(i, j) offsets:CGSizeMake(1, -1)]; unsigned int leftDown = [WDImageBorder valueForBitmap:data stride:w position:CGPointMake(i, j) offsets:CGSizeMake(-1, 1)]; unsigned int rightDown = [WDImageBorder valueForBitmap:data stride:w position:CGPointMake(i, j) offsets:CGSizeMake(1, 1)]; unsigned int center = [WDImageBorder valueForBitmap:data stride:w position:CGPointMake(i, j) offsets:CGSizeMake(0, 0)]; unsigned int avg = (left + right + up + down + leftUp + rightUp + leftDown + rightDown + center) / 9; int offset = i * w + j; if ((avg &gt;= (255. * 0.4) &amp;&amp; avg &lt;= (255. * 0.9)) &amp;&amp; center &gt; 65) &#123; bitmap[offset * 4] = 255; bitmap[offset * 4 + 1] = 0; bitmap[offset * 4 + 2] = 0; bitmap[offset * 4 + 3] = 255; CGFloat scale = 1.15; CGFloat x = (CGFloat)((((float) j / w) - 0.5) * scale + 0.5); CGFloat y = (CGFloat)((((float) i / h) - 0.5) * scale + 0.5); CGPoint point = CGPointMake(x, y); [points addObject:[NSValue valueWithCGPoint:point]]; if (x &lt;= leftmost) leftmost = x; if (x &gt;= rightmost) rightmost = x; &#125; &#125; &#125; ...&#125; è¿™ä¸ªæœ‰ä¸ªè‡´å‘½çš„é—®é¢˜ï¼Œå°±æ˜¯æ‰¾åˆ°ç‚¹ä¹‹åŽï¼Œä½†æ˜¯æ²¡åŠžæ³•æœ‰åºçš„è¿žèµ·æ¥ï¼Œä¹Ÿè¯•è¿‡ä¸€äº›æ–¹æ¡ˆï¼Œä½†æ˜¯å›¾åƒçš„è¾¹ç¼˜æƒ…å†µå¤ªå¤æ‚äº†ï¼Œæ€»æ˜¯æœ‰é—®é¢˜ï¼Œè¿™é‡Œå°±ä¸å¤šè¯´äº†ã€‚ æŽ¥ä¸‹æ¥å°±éœ€æ±‚å…¶ä»–çš„æ–¹æ¡ˆï¼Œå¤§åé¼Žé¼Žçš„OpenCVå‡ºåœºäº†ï¼Œå‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼Œç¼–è¯‘äº§ç‰©ï¼ŒæŽ¥å…¥app è°ƒè¯•ä¸‹æ¥å°±èƒ½èŽ·å–æ­£ç¡®çš„ç»“æžœäº†ï¼Œè¿™é‡Œå°±ä¸å¤šè¯´äº†ï¼Œç›´æŽ¥çœ‹ä¸‹ä»£ç ï¼Œå¯¹åº”çš„èŠ‚ç‚¹æœ‰æ³¨é‡Šè¯´æ˜Ž 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859+ (NSArray *)findContours:(UIImage *)image &#123; Mat src; Mat src_gray; src = [self cvMatFromUIImage:image]; cvtColor(src, src_gray, COLOR_BGR2GRAY); //UIImage *grayImg = [self UIImageFromCVMat:src_gray]; blur(src_gray, src_gray, cv::Size(3, 3)); //UIImage *blurgrayImg = [self UIImageFromCVMat:src_gray]; /// åˆ©ç”¨é˜ˆå€¼äºŒå€¼åŒ– threshold(src_gray,src_gray,128,255,cv::THRESH_BINARY); /// ç”¨Cannyç®—å­æ£€æµ‹è¾¹ç¼˜ //Canny(src_gray, src_gray, 128, 255 , 3); //UIImage *canny_outputImg = [self UIImageFromCVMat:src_gray]; vector&lt;vector&lt;cv::Point&gt; &gt; contours; vector&lt;Vec4i&gt; hierarchy; /// å¯»æ‰¾è½®å»“ findContours(src_gray, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, cv::Point(0, 0)); /// ç»˜å‡ºè½®å»“ Mat drawing = Mat::zeros(src_gray.size(), CV_8UC3); for (int i = 0; i &lt; contours.size(); i++) &#123; Scalar color = Scalar(255, 255, 255); drawContours(drawing, contours, i, color, 1, 8, hierarchy, 0, cv::Point()); &#125; //UIImage *contoursImg = [self UIImageFromCVMat:drawing]; NSMutableArray *array = [NSMutableArray arrayWithCapacity:contours.size()]; for (int i = 0; i &lt; contours.size(); i++) &#123; if (hierarchy[i][3] &gt;= 0 || hierarchy[i][2] &gt;= 0) &#123; continue; &#125; vector&lt;cv::Point&gt; vect = contours[i]; std::vector&lt;cv::Point&gt;::const_iterator it; // declare a read-only iterator it = vect.cbegin(); // assign it to the start of the vector while (it != vect.cend()) &#123; // while it hasn't reach the end //std::cout &lt;&lt; it-&gt;x &lt;&lt;' '&lt;&lt; it-&gt;y &lt;&lt;' '; // print the value of the element it points to [array addObject:@(CGPointMake(it-&gt;x / image.size.width, it-&gt;y / image.size.height))]; ++it; // and iterate to the next element &#125; &#125; return @[array];&#125; è¿™ä¸ªæ–¹æ¡ˆå”¯ä¸€çš„ç¼ºé™·å°±æ˜¯éœ€è¦å¼•å…¥OpenCVé™æ€åº“ï¼Œå¢žåŠ åŒ…å¤§å°ï¼Œä¹Ÿæƒ³è¿‡å’±åªç”¨åˆ°äº†è¾¹ç¼˜æ£€æµ‹ï¼Œå…¶ä»–çš„ç‰›é€¼åŠŸèƒ½æš‚æ—¶ä¹Ÿç”¨ä¸åˆ°ï¼Œè£å‰ªä¸‹åªä¿ç•™éœ€è¦çš„ç±»æ˜¯ä¸æ˜¯å°±å¯ä»¥ï¼Œä½†æ˜¯å¤§è‡´ç¿»äº†ä¸‹ï¼Œç‰µæ‰¯çš„å¤ªå¤šï¼Œæœ€ç»ˆæ”¾å¼ƒäº†, æœ€åŽä¹Ÿå¹¶æ²¡æœ‰ä½¿ç”¨OpenCVçš„æ–¹æ¡ˆã€‚ å› ä¸ºå‘çŽ°äº†æ›´è½»é‡çº§çš„æ–¹æ¡ˆï¼ŒSuzukiè¾¹ç¼˜æ£€æµ‹ç®—æ³•ï¼ŒåŽé¢ä¹Ÿäº†è§£è¯¥ç®—æ³•å…¶å®žå°±æ˜¯OpenCVå†…éƒ¨çš„ä¸€ç§è¾¹ç¼˜æ£€æµ‹æ–¹æ¡ˆã€‚ æ°å¥½AndroidåŒå­¦æ‰¾åˆ°äº†ä¸€ä¸ªå¼€æºåº“ï¼Œjavaç‰ˆæœ¬çš„Suzukiè¾¹ç¼˜æ£€æµ‹ç®—æ³•ã€‚ä»£ç æ‹‰ä¸‹æ¥ç»“åˆç®—æ³•æ–‡æ¡£æ¥å›žæ’¸å‡ éï¼Œå¤§è‡´èƒ½ç†è§£äº†ï¼Œandroidç›´æŽ¥javaæ‹–è¿›åŽ»ç”¨ä¸Šï¼Œiosç¿»è¯‘æˆOCï¼Œä¹Ÿä¸å¤æ‚ï¼Œå› ä¸ºç®—æ³•æ ¸å¿ƒæ–¹æ³•ä¹Ÿä¸è¿‡å‡ åè¡Œä»£ç ï¼Œå°±ç®—ä¸ç†è§£ï¼Œç¡¬ç¿»ä¹Ÿèƒ½ç¿»è¯‘è¿‡æ¥ã€‚ è´´ä¸€ä¸‹ç¿»è¯‘æˆOCçš„ä»£ç ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212+ (NSArray *)findContours:(UIImage *)img threshold:(CGFloat)threshold &#123; img = [self blurImage:img blur:0.2]; /// è®°å½•åŽŸå›¾å°ºå¯¸ int ow = (int) img.size.width; int w = ow; int h = (int) img.size.height; /// è€ƒè™‘å­—èŠ‚å¯¹é½ w è¦é‡æ–°è®¡ç®— CFDataRef imageData = CGDataProviderCopyData(CGImageGetDataProvider(img.CGImage)); const uint8_t *data = CFDataGetBytePtr(imageData); w = (int) CFDataGetLength(imageData) / (h*4); char *F = malloc((size_t) CFDataGetLength(imageData)/4); /// äºŒå€¼åŒ–å¤„ç† threshold *= 255.f; for (int i = 0; i &lt; h; i++) &#123; for (int j = 0; j &lt; w; j++) &#123; if (data[(i * w + j) * 4] &gt; threshold) &#123; F[i * w + j] = 1; &#125; else &#123; F[i * w + j] = 0; &#125; &#125; &#125; NSMutableArray&lt;Contour *&gt; *contours = [NSMutableArray array]; for (int i = 1; i &lt; h - 1; i++) &#123; F[i * w] = 0; F[i * w + w - 1] = 0; &#125; for (int i = 0; i &lt; w; i++) &#123; F[i] = 0; F[w * h - 1 - i] = 0; &#125; int nbd = 1; int lnbd = 1; for (int i = 1; i &lt; h - 1; i++) &#123; lnbd = 1; for (int j = 1; j &lt; w - 1; j++) &#123; int i2 = 0, j2 = 0; if (F[i * w + j] == 0) &#123; continue; &#125; //(a) If fij = 1 and fi, j-1 = 0, then decide that the pixel //(i, j) is the border following starting point of an outer //border, increment NBD, and (i2, j2) &lt;- (i, j - 1). if (F[i * w + j] == 1 &amp;&amp; F[i * w + (j - 1)] == 0) &#123; nbd++; i2 = i; j2 = j - 1; //(b) Else if fij &gt;= 1 and fi,j+1 = 0, then decide that the //pixel (i, j) is the border following starting point of a //hole border, increment NBD, (i2, j2) &lt;- (i, j + 1), and //LNBD + fij in case fij &gt; 1. &#125; else if (F[i * w + j] &gt;= 1 &amp;&amp; F[i * w + j + 1] == 0) &#123; nbd++; i2 = i; j2 = j + 1; if (F[i * w + j] &gt; 1) &#123; lnbd = F[i * w + j]; &#125; &#125; else &#123; //(c) Otherwise, go to (4). //(4) If fij != 1, then LNBD &lt;- |fij| and resume the raster //scan from pixel (i,j+1). The algorithm terminates when the //scan reaches the lower right corner of the picture if (F[i * w + j] != 1) &#123; lnbd = ABS(F[i * w + j]); &#125; continue; &#125; //(2) Depending on the types of the newly found border //and the border with the sequential number LNBD //(i.e., the last border met on the current row), //decide the parent of the current border as shown in Table 1. // TABLE 1 // Decision Rule for the Parent Border of the Newly Found Border B // ---------------------------------------------------------------- // Type of border B' // \ with the sequential // \ number LNBD // Type of B \ Outer border Hole border // --------------------------------------------------------------- // Outer border The parent border The border B' // of the border B' // // Hole border The border B' The parent border // of the border B' // ---------------------------------------------------------------- Contour *B = [Contour new]; B.points = [NSMutableArray array]; [B.points addObject:[NSValue valueWithCGPoint:CGPointMake(j * 1.f / ow, i * 1.f / h)]]; B.isHole = (j2 == (j + 1)); B.idx = nbd; [contours addObject:B]; Contour *B0 = [Contour new]; for (int c = 0; c &lt; contours.count; c++) &#123; if (contours[c].idx == lnbd) &#123; B0 = contours[c]; break; &#125; &#125; if (B0.isHole) &#123; if (B.isHole) &#123; B.parentIdx = B0.parentIdx; &#125; else &#123; B.parentIdx = lnbd; &#125; &#125; else &#123; if (B.isHole) &#123; B.parentIdx = lnbd; &#125; else &#123; B.parentIdx = B0.parentIdx; &#125; &#125; //(3) From the starting point (i, j), follow the detected border: //this is done by the following substeps (3.1) through (3.5). //(3.1) Starting from (i2, j2), look around clockwise the pixels //in the neigh- borhood of (i, j) and tind a nonzero pixel. //Let (i1, j1) be the first found nonzero pixel. If no nonzero //pixel is found, assign -NBD to fij and go to (4). int i1j1[2] = &#123;-1, -1&#125;; cwNon0(F, w, h, i, j, i2, j2, 0, i1j1); if (i1j1[0] == -1 &amp;&amp; i1j1[1] == -1) &#123; F[i * w + j] = -nbd; //go to (4) if (F[i * w + j] != 1) &#123; lnbd = ABS(F[i * w + j]); &#125; continue; &#125; int i1 = i1j1[0]; int j1 = i1j1[1]; // (3.2) (i2, j2) &lt;- (i1, j1) ad (i3,j3) &lt;- (i, j). i2 = i1; j2 = j1; int i3 = i; int j3 = j; while (true) &#123; //(3.3) Starting from the next elementof the pixel (i2, j2) //in the counterclock- wise order, examine counterclockwise //the pixels in the neighborhood of the current pixel (i3, j3) //to find a nonzero pixel and let the first one be (i4, j4). int i4j4[2] = &#123;-1, -1&#125;; ccwNon0(F, w, h, i3, j3, i2, j2, 1, i4j4); int i4 = i4j4[0]; int j4 = i4j4[1]; [contours[contours.count - 1].points addObject:[NSValue valueWithCGPoint:CGPointMake(j4 * 1.f / ow, i4 * 1.f / h)]]; //(a) If the pixel (i3, j3 + 1) is a O-pixel examined in the //substep (3.3) then fi3, j3 &lt;- -NBD. if (F[i3 * w + j3 + 1] == 0) &#123; F[i3 * w + j3] = (char) -nbd; //(b) If the pixel (i3, j3 + 1) is not a O-pixel examined //in the substep (3.3) and fi3,j3 = 1, then fi3,j3 &lt;- NBD. &#125; else if (F[i3 * w + j3] == 1) &#123; F[i3 * w + j3] = (char) nbd; &#125; else &#123; //(c) Otherwise, do not change fi3, j3. &#125; //(3.5) If (i4, j4) = (i, j) and (i3, j3) = (i1, j1) //(coming back to the starting point), then go to (4); if (i4 == i &amp;&amp; j4 == j &amp;&amp; i3 == i1 &amp;&amp; j3 == j1) &#123; if (F[i * w + j] != 1) &#123; lnbd = ABS(F[i * w + j]); &#125; break; //otherwise, (i2, j2) + (i3, j3),(i3, j3) + (i4, j4), //and go back to (3.3). &#125; else &#123; i2 = i3; j2 = j3; i3 = i4; j3 = j4; &#125; &#125; &#125; &#125; free(F); ...&#125; SDFä¸Šé¢æåˆ°è¾¹ç¼˜æ£€æµ‹æ‰¾è¿žç»­çš„è¾¹ç¼˜ç‚¹åªæ˜¯ä¸ºäº†è§£å†³è™šçº¿æè¾¹ï¼Œå…¶ä»–çš„æè¾¹æƒ…å†µå…¶å®žæ˜¯ç”¨ä¸åˆ°è¿™äº›ç‚¹çš„ï¼Œä½†æ˜¯è¿™é‡Œä¹Ÿé‡åˆ°é—®é¢˜äº†ã€‚ ä¸€å¼€å§‹çš„æƒ³æ³•è·Ÿä¸Šé¢é€šè¿‡3x3èŒƒå›´å–å¹³å‡å€¼ï¼Œé€šè¿‡æ¡ä»¶è¿‡æ»¤æ¥åšçš„ï¼Œkernel codeå¤§æ¦‚æ˜¯è¿™æ · 12345678910111213141516171819static NSString *KernelString = @&quot;\kernel vec4 borderDraw(sampler image, sampler mask, sampler source, vec4 rgba, float midpoint, float width) \&#123;\ vec2 uv = destCoord();\ vec4 color = sample(image, samplerTransform(image, uv));\ vec4 sumColor = vec4(0.0);\ float radiu = 2 * width;\ for (float m = -radiu; m &lt;= radiu; m += 2) &#123;\ for (float n = -radiu; n &lt;= radiu; n += 2) &#123;\ vec4 rgba = sample(image, samplerTransform(image, vec2(uv.x + m, uv.y + n)));\ sumColor += rgba;\ &#125;\ &#125;\ float avg = sumColor.a / float(radiu * radiu / 2.0);\ if (color.a &lt; 1.0 &amp;&amp; (avg &gt; .05 &amp;&amp; avg &lt; 1.)) &#123;\ return rgba;\ &#125;\ return color;\&#125;&quot;; è¿™å¥—æ–¹æ¡ˆåšdemoçš„æ—¶å€™ï¼Œæ„Ÿè§‰æ•ˆæžœè¿˜è¡Œï¼Œä¸€ç‚¹ç‚¹æ¯›ç–µï¼Œä»¥ä¸ºæ˜¯æ¡ä»¶åˆ¤æ–­ä¸ä¸¥è°¨ï¼Œä»¥ä¸ºåŽç»­è°ƒæ•´ä¸‹å¯ä»¥è§£å†³ï¼Œè¿˜æœ‰ä¸ªä¸¥é‡çš„é—®é¢˜ï¼Œå°±æ˜¯è¿™ä¸ªæ–¹æ¡ˆè®¡ç®—é‡å¤ªå¤§ï¼Œå›¾ç‰‡åˆ†è¾¨çŽ‡1080å·¦å³ï¼Œè¡¨çŽ°å°±æœ‰ç‚¹å¡ï¼Œå°¤å…¶æ˜¯æ‹–åŠ¨æ»‘ç«¿è°ƒæ•´ï¼Œæè¾¹ç²—ç»† ã€é—´è· ï¼Œå®žæ—¶æ¸²æŸ“æœ‰æ˜Žæ˜¾çš„å¡é¡¿ï¼Œä½†æ˜¯æˆ‘ä»¬åˆä¸èƒ½é™ä½Žå›¾ç‰‡è´¨é‡ï¼Œæ‰€ä»¥è¿™ä¸ªæ–¹æ¡ˆæœ€ç»ˆä¹Ÿå°±æ˜¯åœç•™åœ¨demoé˜¶æ®µäº†ã€‚ å› ä¸ºè®¡ç®—é‡å¤ªå¤§ï¼Œæ‰€ä»¥æƒ³åŠžæ³•é™ä½Žåƒç´ è®¡ç®—é‡ï¼ŒSDFå‡ºåœºäº†ï¼Œé€šè¿‡è·ç¦»åœºï¼Œå¯ä»¥ç”Ÿæˆä¸€å¼ å›¾ï¼Œè¿™å¼ å›¾å¯ä»¥å‘ŠçŸ¥åƒç´ è¾¹ç•Œä¿¡æ¯ï¼Œç›´æŽ¥é€šè¿‡è¾¹ç•Œä¿¡æ¯ï¼ŒçœåŽ»äº†æžå¤§çš„è®¡ç®—é‡ã€‚ SDF ï¼šsigned distance filed æœ‰å‘è·ç¦»åœºsdfæœ‰ä¸¤ç§æ–¹å¼ï¼Œä¸€ç§æ˜¯å¾ªçŽ¯ï¼ˆæ¨ªå‘xçºµå‘ï¼‰ ä¸€ç§æ˜¯åŒçº¿æ€§ï¼ˆæ¨ªå‘+çºµå‘ï¼‰ï¼Œå¾ˆæ˜Žæ˜¾å‰ä¸€ç§è®¡ç®—é‡è¿œè¿œå¤§äºŽåŽä¸€ç§ï¼Œè”è°ƒä¸‹æ¥ç¬¬äºŒç§æ–¹æ¡ˆå®žé™…æ•ˆæžœä¹Ÿæ˜¯ç›¸å½“ä¸é”™äº†ã€‚ è¿™é‡Œè¿˜è¦è€ƒè™‘ä¸€ä¸ªé—®é¢˜ï¼Œå› ä¸ºæè¾¹æ˜¯æœ‰ç²—ç»†è·Ÿé—´è·çš„ï¼Œæ‰€ä»¥å¯ä»¥é€šè¿‡è°ƒæ•´è·ç¦»å‚æ•°ç”Ÿæˆå›¾ï¼Œå¾ˆå¥½çš„è§£å†³äº†æè¾¹ç²—ç»†è·Ÿé—´è·é—®é¢˜çš„ï¼ŒSDFæ–¹æ¡ˆåœ¨è™šçº¿æè¾¹çš„caseä¹Ÿæ˜¯æœ‰ç”¨çš„ï¼Œé€šè¿‡æŠŠSDFç”Ÿæˆå›¾æ‹¿åŽ»åšè¾¹ç¼˜æ£€æµ‹æ‰¾è¿žç»­ç‚¹ã€‚ æ¥çœ‹ä¸‹SDFç”Ÿæˆå›¾çš„æ•ˆæžœ æŠ å›¾æ¨ªå‘SDFç»“æžœæŽ¥çºµå‘SDFç»“æžœ è´´ä¸€ä¸‹Metalç‰ˆæœ¬çš„SDFè®¡ç®—é€»è¾‘ æ¨ªå‘SDF 12345678910111213141516171819202122232425262728293031323334353637383940extern "C" &#123; namespace coreimage &#123; constant float threshold = 0.5; float source(sampler image,float2 uv) &#123; return image.sample(image.transform(uv)).a - threshold; &#125; float4 sdfhor(sampler image,float width,destination dest) &#123; float D2 = width * 2.0 + 1.0; // èŽ·å–å½“å‰ç‚¹åæ ‡ float2 uv = dest.coord(); float s = sign(source(image,uv)); float d = 0.; for(int i= 0; i &lt; width; i++) &#123; d ++; float sp = sign(source(image,float2(uv.x + d, uv.y))); if(s * sp &lt; 0.) &#123; break; &#125; sp = sign(source(image,float2(uv.x - d, uv.y))); if(s * sp &lt; 0.) &#123; break; &#125; &#125; float sd = -s * d / D2 ; return float4(float3(sd),1.0); &#125; &#125;&#125; çºµå‘SDF 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758extern "C" &#123; namespace coreimage &#123; float sd(sampler image,float2 uv,float width) &#123; float D2 = float(width * 2 + 1); float x = image.sample(image.transform(uv)).x; return x * D2; &#125; float4 sdf(sampler image,float width,destination dest) &#123; // èŽ·å–å½“å‰ç‚¹åæ ‡ float2 uv = dest.coord(); float dx = sd(image,uv,width); float dMin = abs(dx); float dy = 0.0; for(int i= 0; i &lt; width; i++)&#123; dy += 1.0; float2 offset = float2(0.0, dy); float dx1 = sd(image,uv+offset,width); //sign switch if(dx1 * dx &lt; 0.)&#123; dMin = dy; break; &#125; dMin = min(dMin, length (float2(dx1, dy))); float dx2 = sd(image,uv-offset,width); //sign switch if(dx2 * dx &lt; 0.)&#123; dMin = dy; break; &#125; dMin = min(dMin, length (float2(dx2, dy))); if(dy &gt; dMin)break; &#125; float D2 = float(width * 2 + 1); dMin *= sign(dx); float d = dMin/D2; d = 1.0 - d; d = smoothstep(0.5 ,1.0, d); return float4(float3(d),1.0); &#125; &#125;&#125; borderæœ‰äº†è·ç¦»åœºï¼Œæè¾¹çš„å·¥ä½œå°±ä¸€ä¸‹å­ç®€å•å¤šäº†ã€‚ ç›®å‰å®žçŽ°çš„äº”ç§æè¾¹æ•ˆæžœå°±æ˜¯è¿™æ ·å¼çš„ é¡¹ç›®ä¸­ä½¿ç”¨coreimageè‡ªå®šä¹‰kernelåšçš„ï¼Œå½“ç„¶ä¹Ÿå¯ä»¥metalæžå®š sdfsourceKernelString å¯¹åº”ä¸Šé¢ç¬¬ä¸‰ä¸ªæ•ˆæžœ 12345678910111213141516171819202122232425262728293031static NSString *sdfsourceKernelString = @"\kernel vec4 borderDraw(sampler image, sampler sdf, sampler source, float d1, float d2) \&#123;\ vec2 uv = destCoord();\ vec4 color = sample(image, samplerTransform(image, uv));\ vec4 sdfcolor = sample(sdf, samplerTransform(sdf, uv));\ vec4 sourcecolor = sample(source, samplerTransform(source, uv));\ if (sdfcolor.x &gt;= d1 &amp;&amp; sdfcolor.x &lt;= d2) &#123;\ return sourcecolor;\ &#125;\ return color;\&#125;";static NSString *sdfKernelString = @"\kernel vec4 borderDraw(sampler image, sampler sdf, sampler source, vec4 rgba, vec2 offset, float d1, float d2) \&#123;\ vec2 uv = destCoord();\ vec4 color = sample(image, samplerTransform(image, uv));\ vec4 offsetColor = sample(image, samplerTransform(image, uv-offset));\ vec4 sdfcolor = sample(sdf, samplerTransform(sdf, uv));\ vec4 sourcecolor = sample(source, samplerTransform(source, uv));\ if(offset.x != 0.0 || offset.y != 0.0) &#123;\ if(color.a &lt; 0.5 &amp;&amp; offsetColor.a &gt; 0.5 ) &#123;\ return mix(rgba,color,color.a);\ &#125;\ &#125; else if (sdfcolor.x &gt;= d1 &amp;&amp; sdfcolor.x &lt;= d2) &#123;\ return mix(rgba,sourcecolor,offsetColor.a);\ &#125;\ return color;\&#125;"; æœ€åŽä¸€ä¸ªè™šçº¿æè¾¹å°±æ˜¯å¸¸è§„çš„è¿žæŽ¥è¾¹ç¼˜ç‚¹å®‰æŽ’ç”»å¸ƒç»˜åˆ¶ï¼Œç„¶åŽè·ŸæŠ å›¾åšä¸€ä¸ªåˆå¹¶å¯¼å‡ºï¼Œå°±ä¸å±•å¼€è¯´äº†ã€‚ Othteræœ€åŽè¿˜æœ‰ä¸€äº›æ³¨æ„ç‚¹ï¼Œæ¯”å¦‚æŠ å›¾å›¾åƒæ˜¯åœ¨è¾¹ç¼˜ï¼Œåˆ™éœ€è¦è€ƒè™‘ä¸‹é¢„ç•™æè¾¹ç©ºé—´ï¼Œåˆ¤æ–­æ˜¯å¦æœ‰è½åœ¨è¾¹ç¼˜ï¼Œå¦‚æžœæœ‰åˆ™è¡¥å……ç‚¹ç©ºé—´ã€‚è¿˜æœ‰ä¸€ä¸ªå°±æ˜¯æœ€å°åŒ…å›´ç›’ï¼ŒæŠ å›¾å¾ˆå¯èƒ½åªå æ®åŽŸå›¾çš„ä¸€éƒ¨åˆ†é¢„æœŸï¼Œä¸ºäº†å±•ç¤ºæ•ˆæžœï¼Œéœ€è¦æŠŠæŠ å›¾çš„æœ€å°åŒ…å›´ç›’æ‰¾åˆ°ï¼Œæ‰¾è¿™ä¸ªæœ€å°åŒ…å›´ç›’ï¼Œä¸éœ€è¦é‚£ä¹ˆç²¾ç¡®ï¼Œæ‰¾å‡ºä¸€ä¸ªå·®ä¸å¤šçš„æœ€å°çŸ©å½¢æ¡†å°±è¡Œï¼Œé¡¹ç›®ä¸Šç”¨çš„å°±æ˜¯ç²—æš´çš„åƒç´ éåŽ†ï¼Œæ‰¾å››ä¸ªè§’çš„ä½ç½®å°±å¯ä»¥äº†ï¼Œé€šè¿‡æœ€å°åŒ…å›´ç›’ï¼Œä¹Ÿèƒ½åˆ¤æ–­æŠ å›¾æ˜¯å¦é è¿‘è¾¹ç¼˜ã€‚ The Lastç»¼ä¸Šï¼Œå…³é”®çš„å‡ ä¸ªæ­¥éª¤åŸºæœ¬éƒ½å°è¯•äº†å¤šç§æ–¹å¼ï¼Œåˆ†æžæ¯”è¾ƒå¾—å‡ºæœ€åˆé€‚é¡¹ç›®éœ€æ±‚çš„æŠ€æœ¯æ–¹æ¡ˆï¼Œ æœ€ç»ˆä»Žæ€§èƒ½ã€ä½“éªŒç­‰ç»´åº¦æ‹¿åˆ°ç›¸å¯¹ä¸é”™çš„ç»“æžœï¼Œå•çº¯ä»Žæè¾¹åŠŸèƒ½ä¸Šæ¥è¯´ï¼Œå¯¹æ¯”ä¿®å¤å·¥å…·ä¹Ÿä¸è¾“ O(âˆ©_âˆ©)Oå“ˆå“ˆ~ referencePContourSDFåŒçº¿æ€§SDF]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>media</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[camera orientation]]></title>
    <url>%2F2022%2F09%2F09%2Fcamera-orientation%2F</url>
    <content type="text"><![CDATA[cameraæ‰‹æœºç›¸æœºå½•è§†é¢‘æˆ–è€…æ‹ç…§ï¼Œéœ€è¦è€ƒè™‘è®¾å¤‡çš„æ–¹å‘ï¼Œä¸»è¦åœ¨ä¸¤æ–¹é¢ é‡‡é›†è¿‡ç¨‹ä¸­ï¼Œæ— è®ºæ‰‹æœºä»€ä¹ˆæ–¹å‘é‡‡é›†ï¼Œé‡‡é›†ç”»é¢éƒ½æ˜¯æ­£ç€çœ‹ï¼Œä¸ç”¨ä¾§å¤´ å½•åˆ¶/æˆ–è€…æ‹ç…§åŽï¼Œè§†é¢‘/å›¾ç‰‡åœ¨æ­£å¸¸æ‰‹æŒè®¾å¤‡çš„æƒ…å†µä¸‹æ­£å¸¸æ˜¾ç¤ºï¼Œä¸ç”¨æ¨ªç€æ‰‹æœº æ­£å¸¸æ‰‹æŒä¸€èˆ¬éƒ½æ˜¯ç«–ç€æ‹¿æ‰‹æœºï¼Œæ‰€ä»¥å°±ç®—æ¨ªç€æ‹æ‘„ï¼Œç«–ç€æ‹¿æ‰‹æœºä¹Ÿéœ€è¦æ­£å¸¸æ˜¾ç¤ºï¼Œä¸ç†è§£å¯ä»¥å‚è€ƒä¸‹ç³»ç»Ÿç›¸æœºã€‚ æ‰€ä»¥è¿™é‡Œå°±å­˜åœ¨ä¸€ä¸ªæ–¹å‘ä¿®æ­£çš„é—®é¢˜ã€‚ device orientationè‹¹æžœæ‰‹æœºï¼Œå¦‚æžœè®¾ç½®é‡Œé”å®šäº†æ–¹å‘ï¼Œæ˜¯æ²¡åŠžæ³•é€šè¿‡ [UIDevice currentDevice].orientationè¿™ä¸ªæ–¹æ³•æ‹¿åˆ°çš„ï¼ŒåŒæ ·UIDeviceOrientationDidChangeNotificationè¿™ä¸ªé€šçŸ¥ä¹ŸèŽ·å–ä¸åˆ°ã€‚åŒç† [[UIApplication sharedApplication] statusBarOrientation]; è·Ÿ **UIApplicationDidChangeStatusBarOrientationNotification** ä¹Ÿæ˜¯ä¸å¯ç”¨çš„ã€‚ å¯ä»¥é€šè¿‡ CMMotionManager ç›‘å¬è®¾å¤‡çš„æ–¹å‘ 12345678910111213141516171819202122232425262728293031323334_motionManager = [[CMMotionManager alloc] init];_motionManager.deviceMotionUpdateInterval = 1/15.0;if (!_motionManager.deviceMotionAvailable) &#123; _motionManager = nil; return self;&#125;OBJC_WEAK(self)[_motionManager startDeviceMotionUpdatesToQueue:[NSOperationQueue currentQueue] withHandler: ^(CMDeviceMotion*motion, NSError *error)&#123; [weak_self performSelectorOnMainThread:@selector(handleDeviceMotion:) withObject:motion waitUntilDone:YES];&#125;];- (void)handleDeviceMotion:(CMDeviceMotion *)deviceMotion &#123; double x = deviceMotion.gravity.x; double y = deviceMotion.gravity.y; if (fabs(y) &gt;= fabs(x)) &#123; if (y &gt;= 0) &#123; _deviceOrientation = UIDeviceOrientationPortraitUpsideDown; _videoOrientation = AVCaptureVideoOrientationPortraitUpsideDown; &#125; else &#123; _deviceOrientation = UIDeviceOrientationPortrait; _videoOrientation = AVCaptureVideoOrientationPortrait; &#125; &#125; else &#123; if (x &gt;= 0) &#123; _deviceOrientation = UIDeviceOrientationLandscapeRight; _videoOrientation = AVCaptureVideoOrientationLandscapeRight; &#125; else &#123; _deviceOrientation = UIDeviceOrientationLandscapeLeft; _videoOrientation = AVCaptureVideoOrientationLandscapeLeft; &#125; &#125;&#125; captureé¡¹ç›®ä¸­éœ€è¦æ”¯æŒè®¾ç½®æ»¤é•œã€ç‰¹æ•ˆç­‰ç­‰ï¼Œæ‰€ä»¥æ˜¾ç¤ºé‡‡é›†çš„å›¾åƒéœ€è¦è‡ªå·±æ¸²æŸ“ï¼Œé€šè¿‡å®˜æ–¹çš„AVCaptureSessioné…ç½®å¥½é‡‡é›†æµç¨‹ï¼Œä¸ç®¡æ˜¯ç«–ç€è¿˜æ˜¯æ¨ªç€é‡‡é›†ï¼ŒèŽ·å–åˆ°çš„pixelBufferéƒ½æ˜¯æ¨ªå‘çš„ï¼Œå› ä¸ºé»˜è®¤å°±æ˜¯homeé”®åœ¨å³è¾¹é‡‡é›†å›¾åƒï¼Œä½†æ˜¯æ˜¾ç¤ºçš„è§†å›¾ä¸€èˆ¬éƒ½æ˜¯ç«–å‘ï¼Œæ‰€ä»¥è¿™é‡Œè¦åšä¸€ä¸ª90Â°çš„æ—‹è½¬å¤„ç†,OPENGL å°±æ˜¯ä¸€ä¸ªæ—‹è½¬çŸ©é˜µã€‚ 123456789101112void main()&#123; // z mat4 rotationMatrix = mat4(cos(angle) , sin(angle) , 0.0, 0.0, -sin(angle) , cos(angle) , 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0); vec4 outPosition = rotationMatrix * position; gl_Position = outPosition; textureCoordinate = inputTextureCoordinate.xy;&#125; å¦‚æžœåªæ˜¯è§£å†³é‡‡é›†ç”»é¢æ˜¾ç¤ºï¼Œä¹Ÿå¯ä»¥é€šè¿‡è®¾ç½®connection.videoOrientation = [self currentVideoOrientation]; æ¥è§£å†³é¡¹ç›®ä¸­æ²¡æœ‰ç”¨è¿™ä¸ªï¼Œå› ä¸ºåŽé¢è¿˜éœ€è¦å½•åˆ¶è§†é¢‘å¯¼å‡ºè§†é¢‘æ–‡ä»¶ã€‚ 12345678910111213141516171819202122// å½“å‰è®¾å¤‡å–å‘- (AVCaptureVideoOrientation)currentVideoOrientation&#123; AVCaptureVideoOrientation orientation; switch (self.motionManager.deviceOrientation) &#123; case UIDeviceOrientationPortrait: orientation = AVCaptureVideoOrientationPortrait; break; case UIDeviceOrientationLandscapeLeft: orientation = AVCaptureVideoOrientationLandscapeRight; break; case UIDeviceOrientationLandscapeRight: orientation = AVCaptureVideoOrientationLandscapeLeft; break; case UIDeviceOrientationPortraitUpsideDown: orientation = AVCaptureVideoOrientationPortraitUpsideDown; break; default: orientation = AVCaptureVideoOrientationPortrait; break; &#125; return orientation;&#125; Recordå½•åˆ¶è¿‡ç¨‹é€šè¿‡AVAssetWriterInput *writerInput = [AVAssetWriterInput assetWriterInputWithMediaType:obj outputSettings:options]; å’Œ[self.mPixelBufferAdaptor appendPixelBuffer:pixelBuffer withPresentationTime:ts] æ¥ç§¯ç´¯pixelBufferï¼Œ ä¸ºäº†ä¿éšœå¯¼å‡ºçš„è§†é¢‘å¯ä»¥æ­£å¸¸æ˜¾ç¤ºï¼Œéœ€è¦è®°å½•è§†é¢‘çš„æ–¹å‘ï¼Œé€šè¿‡è®¾ç½®writerInput.transform[ = self transformFromCurrentVideoOrientationToOrientation:AVCaptureVideoOrientationPortrait],ç³»ç»Ÿè‡ªåŠ¨å¸®æˆ‘ä»¬åšè½¬æ¢ 1234567891011121314151617181920212223242526272829303132// æ—‹è½¬è§†é¢‘æ–¹å‘å‡½æ•°å®žçŽ°- (CGAffineTransform)transformFromCurrentVideoOrientationToOrientation:(AVCaptureVideoOrientation)orientation &#123; CGFloat orientationAngleOffset = [self angleOffsetFromPortraitOrientationToOrientation:orientation]; CGFloat videoOrientationAngleOffset = [self angleOffsetFromPortraitOrientationToOrientation:self.currentOrientation]; CGFloat angleOffset; if (self.position == AVCaptureDevicePositionBack) &#123; angleOffset = videoOrientationAngleOffset - orientationAngleOffset + M_PI_2; &#125; else &#123; angleOffset = orientationAngleOffset - videoOrientationAngleOffset + M_PI_2; &#125; CGAffineTransform transform = CGAffineTransformMakeRotation(angleOffset); return transform;&#125;- (CGFloat)angleOffsetFromPortraitOrientationToOrientation:(AVCaptureVideoOrientation)orientation &#123; CGFloat angle = 0.0; switch (orientation) &#123; case AVCaptureVideoOrientationPortrait: angle = 0.0; break; case AVCaptureVideoOrientationPortraitUpsideDown: angle = M_PI; break; case AVCaptureVideoOrientationLandscapeRight: angle = -M_PI_2; break; case AVCaptureVideoOrientationLandscapeLeft: angle = M_PI_2; break; &#125; return angle;&#125; ä¸»è¦å°±æ˜¯é€šè¿‡å½•åˆ¶è§†é¢‘æ—¶å€™çš„è®¾å¤‡æ–¹å‘è·Ÿæ˜¾ç¤ºæ–¹å‘è®¡ç®—ä¸€ä¸‹transform Picæ‹ç…§ç”Ÿæˆå›¾ç‰‡æ˜¯åŒæ ·çš„é“ç†ï¼Œç›´æŽ¥ç»™å‡ºæ–¹æ³•ï¼Œä¸»è¦å°±æ˜¯å›¾ç‰‡æ–¹å‘çš„æ—‹è½¬ 123456789101112131415161718- (UIImageOrientation)getImageRotationOrientationFromCaptureVideoOrientation:(AVCaptureVideoOrientation)orientation &#123; UIImageOrientation imageOrientation; switch (orientation) &#123; case AVCaptureVideoOrientationPortrait: imageOrientation = UIImageOrientationRight; break; case AVCaptureVideoOrientationPortraitUpsideDown: imageOrientation = UIImageOrientationLeft; break; case AVCaptureVideoOrientationLandscapeRight: imageOrientation = UIImageOrientationUp; break; case AVCaptureVideoOrientationLandscapeLeft: imageOrientation = UIImageOrientationDown; break; &#125; return imageOrientation;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455+ (UIImage *)image:(UIImage *)image rotation:(UIImageOrientation)orientation &#123; long double rotate = 0.0; CGRect rect; float translateX = 0; float translateY = 0; float scaleX = 1.0; float scaleY = 1.0; switch (orientation) &#123; case UIImageOrientationLeft: rotate = M_PI_2; rect = CGRectMake(0, 0, image.size.height, image.size.width); translateX = 0; translateY = -rect.size.width; scaleY = rect.size.width/rect.size.height; scaleX = rect.size.height/rect.size.width; break; case UIImageOrientationRight: rotate = -M_PI_2; rect = CGRectMake(0, 0, image.size.height, image.size.width); translateX = -rect.size.height; translateY = 0; scaleY = rect.size.width/rect.size.height; scaleX = rect.size.height/rect.size.width; break; case UIImageOrientationDown: rotate = M_PI; rect = CGRectMake(0, 0, image.size.width, image.size.height); translateX = -rect.size.width; translateY = -rect.size.height; break; default: rotate = 0.0; rect = CGRectMake(0, 0, image.size.width, image.size.height); translateX = 0; translateY = 0; break; &#125; UIGraphicsBeginImageContext(rect.size); CGContextRef context = UIGraphicsGetCurrentContext(); //åšCTMå˜æ¢ CGContextTranslateCTM(context, 0.0, rect.size.height); CGContextScaleCTM(context, 1.0, -1.0); CGContextRotateCTM(context, rotate); CGContextTranslateCTM(context, translateX, translateY); CGContextScaleCTM(context, scaleX, scaleY); //ç»˜åˆ¶å›¾ç‰‡ CGContextDrawImage(context, CGRectMake(0, 0, rect.size.width, rect.size.height), image.CGImage); UIImage *newPic = UIGraphicsGetImageFromCurrentImageContext(); return newPic;&#125;]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>camera</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[__has_include]]></title>
    <url>%2F2022%2F09%2F06%2Fhas-include%2F</url>
    <content type="text"><![CDATA[VSåœ¨æžéŸ³è§†é¢‘çš„è¿‡ç¨‹ä¸­ï¼Œæ—©æœŸä¸ºäº†å¿«é€Ÿå®žçŽ°åŠŸèƒ½ï¼Œä¼šç”¨åˆ°ä¸€äº›å¼€æºåº“ï¼Œæ¯”å¦‚FFMpegã€OpenCVã€LibYUV ç­‰ï¼Œè¿™äº›å¤§åé¼Žé¼Žçš„å¼€æºåº“èƒ½å¤Ÿè§£å†³éŸ³è§†é¢‘é¢†åŸŸçš„å¾ˆå¤šé—®é¢˜ï¼Œç¼–è§£ç ã€è¾¹ç¼˜æ£€æµ‹ã€RGB-YUVæ ¼å¼è½¬æ¢ç­‰ç­‰ã€‚ è¿™å‡ ä¸ªå¼€æºåº“è¿˜éƒ½æ˜¯C/C++çš„ï¼Œå®Œç¾Žè§£å†³è·¨å¹³å°çš„é—®é¢˜ï¼Œæ‰€ä»¥æ—©æœŸå¯ä»¥å¿«é€Ÿä¸Šçº¿ï¼Œä½†ä¹Ÿä¼šå¸¦æ¥å¢žåŠ åŒ…å¤§å°çš„é—®é¢˜ï¼Œè¿™æ˜¯æœ€æ˜Žæ˜¾çš„ï¼Œå¦å¤–å¼€æºæ–¹æ¡ˆä¹Ÿå¹¶éžæ²¡æœ‰BUGã€‚å¯¹å¼€æºåº“åšè£å‰ªå‡å°‘å¤§å°/æissueç­‰å¾…å®˜æ–¹å¤„ç†ã€è‡ªå·±å¤„ç†BUGç­‰è¿™äº›æˆæœ¬ç›¸å¯¹ä¹Ÿä¸å°ã€‚ å¦ä¸€ä¸ªé€‰æ‹©å°±æ˜¯ä½¿ç”¨å…¶ä»–çš„æ›¿ä»£æ–¹æ¡ˆï¼šæ¯”å¦‚åŽŸç”Ÿçš„æŠ€æœ¯å®žçŽ°ã€è§£å†³æŒ‡å®šé—®é¢˜ç‹¬ç«‹æ¨¡å—ç®—æ³•ã€DIY \ ç¼–è§£ç  è¾¹ç¼˜æ£€æµ‹ æ ¼å¼è½¬æ¢ å¼€æºæ–¹æ¡ˆ FFmpeg OpenCV LibYUV æ›¿ä»£æ–¹æ¡ˆ VideoToolBox/MediaCodec è¾¹ç•Œè·Ÿè¸ªç®—æ³•Suzuki85 DIY è¯´æ˜Ž è½¯è§£-&gt; ç¡¬è§£ è¾¹ç•Œè·Ÿè¸ªç®—æ³•Suzuki85 å°±æ˜¯ OpenCV å†…éƒ¨çš„ä¸€ç§è¾¹ç¼˜æ£€æµ‹æ–¹æ¡ˆ è‡ªå·±å¤„ç†åƒç´ æ•°æ® åŽæœŸé€šè¿‡æ›¿ä»£æ–¹æ¡ˆå¯ä»¥è§£å†³ä¸Šé¢æåˆ°çš„é—®é¢˜ï¼Œä¸»è¦æ˜¯åŒ…å¤§å°é—®é¢˜ã€‚å¦å¤–ä¹Ÿå¯ä»¥è‡ªå·±åŠ¨æ‰‹åŠ æ·±äº†è§£å¼€æºçš„æŠ€æœ¯æ–¹æ¡ˆ __has_includeé€šè¿‡æ›¿ä»£æ–¹æ¡ˆå¯ä»¥ç§»é™¤å¼€æºåº“ï¼Œä½†æ˜¯æŽ¥å…¥å¼€æºæ–¹æ¡ˆå®žçŽ°åŠŸèƒ½çš„ç›¸å…³ä»£ç å°±æ²¡å¿…è¦ç§»é™¤äº†ã€‚æ‰€ä»¥å¯ä»¥é€šè¿‡æ¡ä»¶ç¼–è¯‘åšä¸€ä¸ªåŒºåˆ†ã€‚æ­£å¥½__has_includeè¿™ä¸ªå®å¯ä»¥æ»¡è¶³è¦æ±‚ æè¿°æ­¤å®ä¼ å…¥ä¸€ä¸ªä½ æƒ³å¼•å…¥æ–‡ä»¶çš„åç§°ä½œä¸ºå‚æ•°ï¼Œå¦‚æžœè¯¥æ–‡ä»¶èƒ½å¤Ÿè¢«å¼•å…¥åˆ™è¿”å›ž1ï¼Œå¦åˆ™è¿”å›ž0ã€‚ ç”¨æ³• 12345#if __has_include(&lt;XXX/XXX.h&gt;)#import &lt;XXX/XXX.h&gt;#else#import "YYY.h"#endif é¡¹ç›®ä¸­çš„å®žé™…ç”¨æ³•ï¼š 123456789#if __cplusplus &amp;&amp; __has_include(&lt;Libyuv/libyuv.h&gt;)#include &lt;Libyuv/libyuv.h&gt;#endif#if __cplusplus &amp;&amp; __has_include(&lt;Libyuv/libyuv.h&gt;)...#else...#endif 12345#if __has_include(&lt;opencv2/imgcodecs/ios.h&gt;) contourArr = [OpenCVWrapper findContours:image];#else contourArr = [PContour findContours:image threshold:threshold];#endif 12345678910111213141516#if __cplusplus &amp;&amp; __has_include(&lt;ffmpeg/avformat.h&gt;)extern "C" &#123;#include "ffmpeg/timestamp.h"#include "ffmpeg/avformat.h"#include "ffmpeg/bsf.h"#include "ffmpeg/swscale.h"#include "ffmpeg/swresample.h"#include "ffmpeg/avformat.h"#include "ffmpeg/imgutils.h"#include "ffmpeg/samplefmt.h"&#125;#endif ...#endif]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>media</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RGB2YUV]]></title>
    <url>%2F2022%2F09%2F05%2FRGB2YUV%2F</url>
    <content type="text"><![CDATA[RGB2YUVå¤„ç†éŸ³è§†é¢‘ï¼Œå¯¹YUV RGBè‚¯å®šä¸é™Œç”Ÿï¼Œè¿™é‡Œè®°å½•ä¸‹ç»è¿‡OpenGLå¤„ç†åŽçš„ RGB æ ¼å¼çš„pixelBuffer è½¬æˆ YUV æ ¼å¼å¯¼å‡ºè§†é¢‘ã€‚ DIYè‡ªå·±å¤„ç†çŸ©é˜µçš„è®¡ç®—ï¼ŒYUVçš„å­˜å‚¨æ ¼å¼ï¼Œå¯ä»¥åŠ æ·±å¯¹YUVçš„ç†è§£ï¼Œ ç±»ä¼¼çš„åè¿‡æ¥å¤„ç†ï¼Œæˆ–è€…å¤„ç†å…¶ä»–æ ¼å¼çš„YUV 422 444ç­‰ï¼Œä¹Ÿæ˜¯ä¸€æ ·çš„ã€‚æ‰€ä»¥è¿˜æ˜¯æœ‰å¿…è¦äº†è§£ä¸€ä¸‹ï¼ŒDO IT YOURSELF. é‡ç‚¹æ˜¯æ³¨æ„å†…å­˜å¯¹é½ï¼ŒYUV420é‡‡æ ·å­˜å‚¨æ–¹å¼å°±å¥½äº†ï¼Œå…¶ä»–æ²¡ä»€ä¹ˆå¤æ‚çš„ã€‚ è½¬æ¢åŽ å¦‚æžœå‡ºçŽ°è¿™ç§åƒç´ é”™ä½çš„æƒ…å†µï¼Œä¸€èˆ¬æ˜¯å†…å­˜å¯¹é½ å¯¼è‡´çš„è¡¥ä½æ²¡æœ‰è€ƒè™‘åˆ°ï¼Œå‚è€ƒä¸‹ä»£ç é‡Œé¢çš„ strideå­—æ®µ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109CFDictionaryRef CreateCFDictionary(CFTypeRef* keys, CFTypeRef* values, size_t size) &#123; return CFDictionaryCreate(kCFAllocatorDefault, keys, values, size, &amp;kCFTypeDictionaryKeyCallBacks, &amp;kCFTypeDictionaryValueCallBacks); &#125;static void bt709_rgb2yuv8bit_TV(uint8_t R, uint8_t G, uint8_t B, uint8_t &amp;Y, uint8_t &amp;U, uint8_t &amp;V) &#123; Y = 0.183 * R + 0.614 * G + 0.062 * B + 16; U = -0.101 * R - 0.339 * G + 0.439 * B + 128; V = 0.439 * R - 0.399 * G - 0.040 * B + 128; &#125;CVPixelBufferRef RGB2YCbCr8Bit(CVPixelBufferRef pixelBuffer) &#123; CVPixelBufferLockBaseAddress(pixelBuffer, 0); uint8_t *baseAddress = (uint8_t *)CVPixelBufferGetBaseAddress(pixelBuffer); int w = (int) CVPixelBufferGetWidth(pixelBuffer); int h = (int) CVPixelBufferGetHeight(pixelBuffer); int stride = (int) CVPixelBufferGetBytesPerRow(pixelBuffer) / 4; OSType pixelFormat = kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange; CVPixelBufferRef pixelBufferCopy = NULL; const size_t attributes_size = 1; CFTypeRef keys[attributes_size] = &#123; kCVPixelBufferIOSurfacePropertiesKey, &#125;; CFDictionaryRef io_surface_value = CreateCFDictionary(nullptr, nullptr, 0); CFTypeRef values[attributes_size] = &#123;io_surface_value&#125;; CFDictionaryRef attributes = CreateCFDictionary(keys, values, attributes_size); CVReturn status = CVPixelBufferCreate(kCFAllocatorDefault, w, h, pixelFormat, attributes, &amp;pixelBufferCopy); if (status != kCVReturnSuccess) &#123; std::cout &lt;&lt; "YUVBufferCopyWithPixelBuffer :: failed" &lt;&lt; std::endl; return nullptr; &#125; if (attributes) &#123; CFRelease(attributes); attributes = nullptr; &#125; CVPixelBufferLockBaseAddress(pixelBufferCopy, 0); size_t y_stride = CVPixelBufferGetBytesPerRowOfPlane(pixelBufferCopy, 0); size_t uv_stride = CVPixelBufferGetBytesPerRowOfPlane(pixelBufferCopy, 1); int plane_h1 = (int) CVPixelBufferGetHeightOfPlane(pixelBufferCopy, 0); int plane_h2 = (int) CVPixelBufferGetHeightOfPlane(pixelBufferCopy, 1); uint8_t *y = (uint8_t *) CVPixelBufferGetBaseAddressOfPlane(pixelBufferCopy, 0); memset(y, 0x80, plane_h1 * y_stride); uint8_t *uv = (uint8_t *) CVPixelBufferGetBaseAddressOfPlane(pixelBufferCopy, 1); memset(uv, 0x80, plane_h2 * uv_stride); int y_bufferSize = w * h; int uv_bufferSize = w * h / 4; uint8_t *y_planeData = (uint8_t *) malloc(y_bufferSize * sizeof(uint8_t)); uint8_t *u_planeData = (uint8_t *) malloc(uv_bufferSize * sizeof(uint8_t)); uint8_t *v_planeData = (uint8_t *) malloc(uv_bufferSize * sizeof(uint8_t)); int u_offset = 0; int v_offset = 0; uint8_t R, G, B; uint8_t Y, U, V; for (int i = 0; i &lt; h; i ++) &#123; for (int j = 0; j &lt; w; j ++) &#123; int offset = i * stride + j; B = baseAddress[offset * 4]; G = baseAddress[offset * 4 + 1]; R = baseAddress[offset * 4 + 2]; bt709_rgb2yuv8bit_TV(R, G, B, Y, U, V); y_planeData[i * w + j] = Y; //éš”è¡Œæ‰«æ å¶æ•°è¡Œçš„å¶æ•°åˆ—å–U å¥‡æ•°è¡Œçš„å¶æ•°åˆ—å–V if (j % 2 == 0) &#123; (i % 2 == 0) ? u_planeData[u_offset++] = U : v_planeData[v_offset++] = V; &#125; &#125; &#125; for (int i = 0; i &lt; plane_h1; i ++) &#123; memcpy(y + i * y_stride, y_planeData + i * w, w); if (i &lt; plane_h2) &#123; for (int j = 0 ; j &lt; w ; j+=2) &#123; //NV12 å’Œ NV21 æ ¼å¼éƒ½å±žäºŽ YUV420SP ç±»åž‹ã€‚å®ƒä¹Ÿæ˜¯å…ˆå­˜å‚¨äº† Y åˆ†é‡ï¼Œä½†æŽ¥ä¸‹æ¥å¹¶ä¸æ˜¯å†å­˜å‚¨æ‰€æœ‰çš„ U æˆ–è€… V åˆ†é‡ï¼Œè€Œæ˜¯æŠŠ UV åˆ†é‡äº¤æ›¿è¿žç»­å­˜å‚¨ã€‚ //NV12 æ˜¯ IOS ä¸­æœ‰çš„æ¨¡å¼ï¼Œå®ƒçš„å­˜å‚¨é¡ºåºæ˜¯å…ˆå­˜ Y åˆ†é‡ï¼Œå† UV è¿›è¡Œäº¤æ›¿å­˜å‚¨ã€‚ memcpy(uv + i * y_stride + j, u_planeData + i * w/2 + j/2, 1); memcpy(uv + i * y_stride + j + 1, v_planeData + i * w/2 + j/2, 1); &#125; &#125; &#125; free(y_planeData); free(u_planeData); free(v_planeData); CVPixelBufferUnlockBaseAddress(pixelBuffer, 0); CVPixelBufferUnlockBaseAddress(pixelBufferCopy, 0); return pixelBufferCopy; &#125; LibYUVçœ‹è¿‡äº†ä¸Šä¸€ç§æ–¹å¼ï¼ŒLibYUVå°±æ›´å¥½ç†è§£äº†ï¼Œè¿™é‡Œä¸»è¦é€šè¿‡pod ä¾èµ–ä¸‹ LibYUV-iosï¼Œ å°±ä¸è‡ªå·±ç¼–è¯‘äº†ã€‚ pod &#39;Libyuv&#39;,&#39;1703&#39; LibYUV ä¸èƒ½ç›´æŽ¥RGBè½¬æˆNV12 ,éœ€è¦é€šè¿‡I420è¿‡åº¦ä¸‹ã€‚ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990CVPixelBufferLockBaseAddress(pixelBuffer, 0); uint8_t *baseAddress = (uint8_t *)CVPixelBufferGetBaseAddress(pixelBuffer); size_t bgraStride = CVPixelBufferGetBytesPerRowOfPlane(pixelBuffer,0); int w = (int) CVPixelBufferGetWidth(pixelBuffer); int h = (int) CVPixelBufferGetHeight(pixelBuffer); OSType pixelFormat = kCVPixelFormatType_420YpCbCr8Planar; CVPixelBufferRef pixelBufferCopy = NULL; const size_t attributes_size = 1; CFTypeRef keys[attributes_size] = &#123; kCVPixelBufferIOSurfacePropertiesKey &#125;; CFDictionaryRef io_surface_value = vtc::CreateCFDictionary(nullptr, nullptr, 0); CFTypeRef values[attributes_size] = &#123;io_surface_value&#125;; CFDictionaryRef attributes = vtc::CreateCFDictionary(keys, values, attributes_size); CVReturn status = CVPixelBufferCreate(kCFAllocatorDefault, w, h, pixelFormat, attributes, &amp;pixelBufferCopy); if (status != kCVReturnSuccess) &#123; std::cout &lt;&lt; "YUVBufferCopyWithPixelBuffer :: failed" &lt;&lt; std::endl; return nullptr; &#125; if (attributes) &#123; CFRelease(attributes); attributes = nullptr; &#125; CVPixelBufferLockBaseAddress(pixelBufferCopy, 0); unsigned char* y = (unsigned char*)CVPixelBufferGetBaseAddressOfPlane(pixelBufferCopy,0); unsigned char* u = (unsigned char*)CVPixelBufferGetBaseAddressOfPlane(pixelBufferCopy,1); unsigned char* v = (unsigned char*)CVPixelBufferGetBaseAddressOfPlane(pixelBufferCopy,2); int32_t width = (int32_t)CVPixelBufferGetWidth(pixelBufferCopy); int32_t height = (int32_t)CVPixelBufferGetHeight(pixelBufferCopy); size_t y_stride = CVPixelBufferGetBytesPerRowOfPlane(pixelBufferCopy,0); size_t u_stride = CVPixelBufferGetBytesPerRowOfPlane(pixelBufferCopy,1); size_t v_stride = CVPixelBufferGetBytesPerRowOfPlane(pixelBufferCopy,2); libyuv::ARGBToI420(baseAddress, (int)bgraStride, y, (int)y_stride, u, (int)u_stride, v, (int)v_stride, width, height); CVPixelBufferRef pixelBufferNV12 = NULL; const size_t size = 1; CFTypeRef _keys[size] = &#123; kCVPixelBufferIOSurfacePropertiesKey &#125;; CFDictionaryRef _io_surface_value = vtc::CreateCFDictionary(nullptr, nullptr, 0); CFTypeRef _values[size] = &#123;_io_surface_value&#125;; CFDictionaryRef _attributes = vtc::CreateCFDictionary(_keys, _values, size); CVReturn _status = CVPixelBufferCreate(kCFAllocatorDefault, w, h, kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange, _attributes, &amp;pixelBufferNV12); if (_status != kCVReturnSuccess) &#123; std::cout &lt;&lt; "YUVBufferCopyWithPixelBuffer :: failed" &lt;&lt; std::endl; return nullptr; &#125; if (_attributes) &#123; CFRelease(_attributes); _attributes = nullptr; &#125; CVPixelBufferLockBaseAddress(pixelBufferNV12, 0); unsigned char* _y = (unsigned char*)CVPixelBufferGetBaseAddressOfPlane(pixelBufferNV12,0); unsigned char* _uv = (unsigned char*)CVPixelBufferGetBaseAddressOfPlane(pixelBufferNV12,1); size_t _y_stride = CVPixelBufferGetBytesPerRowOfPlane(pixelBufferNV12, 0); size_t _uv_stride = CVPixelBufferGetBytesPerRowOfPlane(pixelBufferNV12, 1); int32_t _width = (int32_t)CVPixelBufferGetWidth(pixelBufferNV12); int32_t _height = (int32_t)CVPixelBufferGetHeight(pixelBufferNV12); libyuv::I420ToNV12(y, (int)y_stride, u, (int)u_stride, v, (int)v_stride, _y, (int)_y_stride, _uv, (int)_uv_stride, _width, _height); CVPixelBufferUnlockBaseAddress(pixelBuffer, 0); CVPixelBufferUnlockBaseAddress(pixelBufferCopy, 0); CVPixelBufferUnlockBaseAddress(pixelBufferNV12, 0); CVPixelBufferRelease(pixelBufferCopy); RGB-&gt;NV21æ›´æ–°ä¸‹:ä¸Šæ¬¡ä½¿ç”¨libyuvçš„æ—¶å€™ çœ‹æ¼äº†ï¼Œå…¶å®žæœ‰argbè½¬nv21çš„ 123456789101112131415161718192021222324252627282930313233343536373839404142CVPixelBufferLockBaseAddress(pixelBuffer, 0);uint8_t *baseAddress = (uint8_t *)CVPixelBufferGetBaseAddress(pixelBuffer);size_t bgraStride = CVPixelBufferGetBytesPerRowOfPlane(pixelBuffer,0);int w = (int) CVPixelBufferGetWidth(pixelBuffer);int h = (int) CVPixelBufferGetHeight(pixelBuffer);CVPixelBufferRef pixelBufferNV12 = NULL;const size_t attributes_size = 1;CFTypeRef keys[attributes_size] = &#123; kCVPixelBufferIOSurfacePropertiesKey&#125;;CFDictionaryRef io_surface_value = vtc::CreateCFDictionary(nullptr, nullptr, 0);CFTypeRef values[attributes_size] = &#123;io_surface_value&#125;;CFDictionaryRef attributes = vtc::CreateCFDictionary(keys, values, attributes_size);CVReturn status = CVPixelBufferCreate(kCFAllocatorDefault, w, h, kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange, attributes, &amp;pixelBufferNV12);if (status != kCVReturnSuccess) &#123; std::cout &lt;&lt; "YUVBufferCopyWithPixelBuffer :: failed" &lt;&lt; std::endl; return nullptr;&#125;if (attributes) &#123; CFRelease(attributes); attributes = nullptr;&#125;CVPixelBufferLockBaseAddress(pixelBufferNV12, 0);unsigned char* y = (unsigned char*)CVPixelBufferGetBaseAddressOfPlane(pixelBufferNV12,0);unsigned char* uv = (unsigned char*)CVPixelBufferGetBaseAddressOfPlane(pixelBufferNV12,1);size_t y_stride = CVPixelBufferGetBytesPerRowOfPlane(pixelBufferNV12, 0);size_t uv_stride = CVPixelBufferGetBytesPerRowOfPlane(pixelBufferNV12, 1);int32_t width = (int32_t)CVPixelBufferGetWidth(pixelBufferNV12);int32_t height = (int32_t)CVPixelBufferGetHeight(pixelBufferNV12);// ARGB-&gt;NV21libyuv::ARGBToNV12(baseAddress, (int)bgraStride, y, (int)y_stride, uv, (int)uv_stride, width, height)CVPixelBufferUnlockBaseAddress(pixelBuffer, 0);CVPixelBufferUnlockBaseAddress(pixelBufferNV12, 0);return pixelBufferNV12;]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>YUV</tag>
        <tag>media</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flutter Display P3]]></title>
    <url>%2F2022%2F08%2F31%2Fflutter-Display-P3%2F</url>
    <content type="text"><![CDATA[Display P3Display P3 æ˜¯è‹¹æžœæ‰‹æœºç›¸æœºä½¿ç”¨çš„ä¸€ç§è‰²åŸŸï¼ŒæŸ¥çœ‹å›¾ç‰‡ä¿¡æ¯å¯ä»¥çœ‹åˆ°ï¼Œ ç„¶è€Œåœ¨flutterä¸­ æ¸²æŸ“ Display P3æ ¼å¼çš„å›¾ç‰‡ bitmapé¢œè‰²å¤±çœŸ,ä¸äº†è§£è‰²åŸŸçš„å‚è€ƒä¸‹å‰é¢HDRç›¸å…³çš„æ–‡ç«  å¤±çœŸæ•ˆæžœï¼š ä¿®å¤æ•ˆæžœï¼š åŽŸå› å°±æ˜¯Flutter ç›´æŽ¥æŠŠDisplay P3ç¤¾åŒºçš„å½“åšsRGBè‰²åŸŸçš„å›¾åƒå¤„ç†äº†ï¼Œè€Œæ²¡æœ‰åšè‰²åŸŸè½¬æ¢ FlutterFlutter è·Ÿ Native å›¾ç‰‡æ‰“é€šï¼Œå¸¸è§æœ‰ä¸¤ç§æ–¹å¼ï¼šbitmapä¼ é€’ &amp;&amp; å¤–æŽ¥çº¹ç†ï¼Œè¿™è¾¹æ–‡ç« é’ˆå¯¹çš„æ˜¯å‰è€…ï¼Œå¤–æŽ¥çº¹ç†ä¹Ÿä¼šæœ‰è¿™ç§é—®é¢˜çš„ï¼Œæ— éžå°±æ˜¯pixelBuffer è½¬çº¹ç†ï¼ŒpixelBufferä¸€æ ·ä¹Ÿæ˜¯æœ‰è‰²åŸŸé—®é¢˜çš„ï¼Œè§£å†³æ–¹æ¡ˆå¯ä»¥å‚è€ƒ Flutter HDR,åŽŸç†æ˜¯ä¸€æ ·çš„ã€‚ é’ˆå¯¹å›¾ç‰‡çš„bitmapåšè‰²åŸŸè½¬æ¢ï¼Œæ–¹æ¡ˆæœ‰å¾ˆå¤šï¼Œè¿™é‡Œåˆ—å‡ºå¸¸è§çš„ä¸¤ç§ï¼š ImageIO123456789101112131415161718192021222324252627282930CGImageSourceRef src = CGImageSourceCreateWithData((__bridge CFDataRef) imageData, NULL); NSUInteger frameCount = CGImageSourceGetCount(src); if (frameCount &gt; 0) &#123; NSDictionary *options = @&#123;(__bridge NSString *)kCGImageSourceShouldCache : @YES, (__bridge NSString *)kCGImageSourceShouldCacheImmediately : @NO &#125;; NSDictionary *props = (NSDictionary *) CFBridgingRelease(CGImageSourceCopyPropertiesAtIndex(src, (size_t) 0, (__bridge CFDictionaryRef)options)); NSString *profileName = [props objectForKey:(NSString *) kCGImagePropertyProfileName]; if ([profileName isEqualToString:@"Display P3"]) &#123; NSMutableData *data = [NSMutableData data]; CGImageDestinationRef destRef = CGImageDestinationCreateWithData((__bridge CFMutableDataRef)data, kUTTypePNG, 1, NULL); NSMutableDictionary *properties = [NSMutableDictionary dictionary]; properties[(__bridge NSString *)kCGImageDestinationLossyCompressionQuality] = @(1); properties[(__bridge NSString *)kCGImageDestinationEmbedThumbnail] = @(0); properties[(__bridge NSString *)kCGImagePropertyNamedColorSpace] = (__bridge id _Nullable)(kCGColorSpaceSRGB); properties[(__bridge NSString *)kCGImageDestinationOptimizeColorForSharing] = @(YES); CGImageDestinationAddImageFromSource(destRef, src, 0, (__bridge CFDictionaryRef)properties); CGImageDestinationFinalize(destRef); CFRelease(destRef); return data; &#125; &#125; return imageData; æ ¸å¿ƒå°±æ˜¯è¿™ä¸ªå±žæ€§ï¼Œå¾ˆå¥½ç†è§£å§ 12345/* Create an image using a colorspace, that has is compatible with older devices * The value should be kCFBooleanTrue or kCFBooleanFalse * Defaults to kCFBooleanFalse = don&apos;t do any color conversion */IMAGEIO_EXTERN const CFStringRef kCGImageDestinationOptimizeColorForSharing IMAGEIO_AVAILABLE_STARTING(10.12, 9.3); é‡æ–°Renderä¸€å¼ å›¾1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980CGImageSourceRef src = CGImageSourceCreateWithData((__bridge CFDataRef) imageData, NULL); NSUInteger frameCount = CGImageSourceGetCount(src); if (frameCount &gt; 0) &#123; NSDictionary *frameProperties = (NSDictionary *) CFBridgingRelease(CGImageSourceCopyPropertiesAtIndex(src, (size_t) 0, NULL)); NSString *profileName = [frameProperties objectForKey:(NSString *) kCGImagePropertyProfileName]; if ([profileName isEqualToString:@"Display P3"]) &#123; CGImageRef imageRef = CGImageSourceCreateImageAtIndex(src, (size_t) 0, NULL); CIImage *image = [CIImage imageWithCGImage:imageRef]; CIContext *context = [[CIContext alloc] init]; float w = image.extent.size.width; float h = image.extent.size.height; unsigned char *bitmap = malloc(w * h * 4); CIRenderDestination *destination = [[CIRenderDestination alloc] initWithBitmapData:bitmap width:w height:h bytesPerRow:w * 4 format:kCIFormatBGRA8]; NSError *error = nil; [context startTaskToRender:image toDestination:destination error:&amp;error]; if (error) &#123; CFRelease(src); return imageData; &#125; CFRelease(src); UIImage *newImage = [FlutterImagePlugin imageFromBRGABytes:bitmap imageSize:image.extent.size]; free(bitmap); CGImageRelease(imageRef); if (newImage == nil) &#123; return imageData; &#125; return UIImagePNGRepresentation(newImage); &#125; &#125;+ (UIImage *)imageFromBRGABytes:(unsigned char *)imageBytes imageSize:(CGSize)imageSize &#123; CGImageRef imageRef = [self imageRefFromBGRABytes:imageBytes imageSize:imageSize]; if (imageRef == NULL) &#123; return nil; &#125; UIImage *image = [UIImage imageWithCGImage:imageRef]; CGImageRelease(imageRef); return image;&#125;+ (CGImageRef)imageRefFromBGRABytes:(unsigned char *)imageBytes imageSize:(CGSize)imageSize &#123; CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB(); CGContextRef context = CGBitmapContextCreate(imageBytes, imageSize.width, imageSize.height, 8, imageSize.width * 4, colorSpaceSDImage, kCGBitmapByteOrder32Little | kCGImageAlphaPremultipliedFirst); if (context == NULL) &#123; return NULL; &#125; CGImageRef imageRef = CGBitmapContextCreateImage(context); if (imageRef == NULL) &#123; CGContextRelease(context); return NULL; &#125; CGContextRelease(context); return imageRef;&#125; ä»Žä»£ç é‡è·Ÿæ€§èƒ½è€ƒé‡ï¼Œæ— è„‘é€‰å‰è€… ðŸ˜]]></content>
      <categories>
        <category>flutter</category>
      </categories>
      <tags>
        <tag>flutter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flutter-hdr]]></title>
    <url>%2F2022%2F08%2F24%2Fflutter-hdr%2F</url>
    <content type="text"><![CDATA[flutterflutter æ’­æ”¾ HDR è§†é¢‘ï¼Œè‰²å½©è·Ÿäº®åº¦éƒ½æœ‰é—®é¢˜ ï¼Œgithub ä¹Ÿæœ‰åé¦ˆè¿™ä¸ªissue Video Player HDR Problem è·ŸåŽŸç”Ÿçš„å¯¹æ¯”å¯ä»¥å¾ˆæ˜Žæ˜¾çœ‹åˆ°å·®è·ï¼Œå®˜æ–¹çœ‹èµ·æ¥å¥½åƒä¹Ÿä¸é‡è§†è¿™ä¸ªé—®é¢˜ ðŸ˜• å…³äºŽ HDR æ ¼å¼ï¼Œå¯ä»¥çœ‹ä¸‹å‰é¢çš„æ–‡ç«  HDRç¬”è®° è¿™é‡Œè®°å½•ä¸‹Flutter video player plugin ä¸­å¤„ç†è§†é¢‘è‰²å½©çš„æ–¹æ³•ï¼Œäº®åº¦æå‡éœ€è¦é€šè¿‡ç¡¬ä»¶æ¿€æ´»ï¼ŒFlutterä¸­å¥½åƒæ²¡æ³•å¤„ç†ã€‚ é¢œè‰²çš„å¤„ç†æ ¸å¿ƒå°±æ˜¯åšäº†ä¸€ä¸ªHDR-&gt;SDRçš„tonemap,æ°å¥½CIImageä¸­æä¾›äº†è¿™æ ·çš„Filterï¼Œå¤„ç†å°±æ–¹ä¾¿å¤šäº†ï¼Œçœ‹è¿‡HDRç¬”è®° è¿™ç¯‡æ–‡ç« çš„è¯ï¼Œåº”è¯¥ä¹Ÿå¯ä»¥è‡ªå·±é€šè¿‡ EOTF + è‰²åŸŸæ˜ å°„ æ¥å¤„ç†ã€‚æš‚æ—¶ä¸çŸ¥é“ CIImageä¸­æ˜¯æ€Žä¹ˆå¤„ç†çš„ï¼ŒçŒœæµ‹æ˜¯å·®ä¸å¤šçš„ã€‚ 12345678910111213141516171819202122232425262728293031323334353637383940- (CVPixelBufferRef)pixelBufferFormCIImage:(CIImage *)image &#123; NSDictionary *options = [NSDictionary dictionaryWithObjectsAndKeys: @&#123;&#125;, kCVPixelBufferIOSurfacePropertiesKey, @YES, kCVPixelBufferCGImageCompatibilityKey, @YES, kCVPixelBufferCGBitmapContextCompatibilityKey, nil]; CVPixelBufferRef pixelBufferCopy = NULL; CVReturn status = CVPixelBufferCreate(kCFAllocatorDefault, image.extent.size.width, image.extent.size.height, kCVPixelFormatType_32BGRA, (__bridge CFDictionaryRef) options, &amp;pixelBufferCopy); if (status == kCVReturnSuccess) &#123; CIRenderDestination *destination = [[CIRenderDestination alloc] initWithPixelBuffer:pixelBufferCopy]; [self.mContext startTaskToRender:image toDestination:destination error:nil]; &#125; return pixelBufferCopy;&#125;- (CVPixelBufferRef)copyPixelBuffer &#123; CMTime outputItemTime = [_videoOutput itemTimeForHostTime:CACurrentMediaTime()]; if ([_videoOutput hasNewPixelBufferForItemTime:outputItemTime]) &#123; CVPixelBufferRef p = [_videoOutput copyPixelBufferForItemTime:outputItemTime itemTimeForDisplay:NULL]; CFTypeRef colorPrimaries = CVBufferGetAttachment(p, kCVImageBufferTransferFunctionKey, NULL); if (colorPrimaries &amp;&amp; CFEqual(colorPrimaries, kCVImageBufferTransferFunction_ITU_R_2100_HLG)) &#123; if (@available(iOS 14.1, *)) &#123; CIImage *image = [CIImage imageWithCVPixelBuffer:p options:@&#123;kCIImageToneMapHDRtoSDR : @(YES)&#125;]; CVPixelBufferRef newP = [self pixelBufferFormCIImage:image]; CVPixelBufferRelease(p); return newP; &#125; &#125; return p; &#125; else &#123; return NULL; &#125;&#125;]]></content>
      <categories>
        <category>flutter</category>
      </categories>
      <tags>
        <tag>flutter</tag>
        <tag>HDR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDRç¬”è®°]]></title>
    <url>%2F2022%2F08%2F18%2FHDR%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Noun explanationITUï¼šå›½é™…ç”µä¿¡è”ç›Ÿ International Telecommunication UnionITU-Rï¼šå›½é™…ç”µä¿¡è”ç›Ÿæ— çº¿ç”µé€šä¿¡éƒ¨é—¨ ITU Radiocommunication Sector CIE :å›½é™…ç…§æ˜Žåä¼š ï¼ˆè‹±æ–‡ï¼šInternational Commission on Illumination ï¼Œæ³•æ–‡ï¼šCommission internationale de l&#39;Ã©clairage ï¼Œé‡‡ç”¨æ³•æ–‡ç¼©å†™ï¼šCIE ï¼‰ SMPTEï¼šç”µå½±ç”µè§†å·¥ç¨‹å¸ˆåä¼š Society of Motion Picture and Television Engineers Hueï¼šè‰²è°ƒ è‰²å½© è‰²ç›¸Chromaï¼šè‰²è°ƒé¥±å’Œåº¦ æµ“åº¦Luminanceï¼šäº®åº¦ æ˜Žåº¦ HDR ConceptHDR:High Dynamic Range å­—é¢ä¸Šæ˜¯åŠ¨æ€èŒƒå›´ï¼Œä¸€èˆ¬æŒ‡äº®åº¦ä¸Šå¯ä»¥è¡¨è¾¾æ›´å¤§çš„äº®åº¦èŒƒå›´ï¼Œå‘ˆçŽ°æ›´å¤§çš„äº®åº¦å¯¹æ¯”åº¦ã€‚ä½†æ˜¯å®žé™…å®žé™…ä¸ŠHDRçš„æŠ€æœ¯å’Œæ ‡å‡†æ¶‰åŠè‰²å½©ç›¸å…³çš„ä¸€ç»„å±žæ€§çš„æ”¹å–„ï¼Œå¯ä»¥å¸¦æ¥æ›´å¤šçš„é¢œè‰²ã€æ›´å¤§çš„äº®åº¦å¯¹æ¯”åº¦ã€æ›´é«˜ç²¾åº¦çš„é‡åŒ–ã€‚ OETF/EOTF: Optical-Electro/Electro-Optical Transfer Function å…‰ç”µ/ç”µå…‰è½¬æ¢å‡½æ•° äººå¯¹äº®åº¦çš„æ„ŸçŸ¥æ˜¯éžçº¿æ€§çš„ï¼Œå¯¹æš—éƒ¨ç»†èŠ‚æ•æ„Ÿï¼Œå¯¹äº®éƒ¨ç»†èŠ‚ä¸æ•æ„Ÿï¼Œåˆ©ç”¨è¿™ä¸ªç‰¹ç‚¹è®¾è®¡äº†éžçº¿æ€§çš„å…‰ç”µè½¬æ¢å’Œç”µå…‰è½¬æ¢çš„å‡½æ•°ã€‚è¿™æ ·çš„å¤„ç†ä¸ä»…å¯ä»¥èŠ‚çœå¸¦å®½ï¼Œä¹Ÿå¯ä»¥åŸºæœ¬æ»¡è¶³ç”¨æˆ·ä½“éªŒéœ€æ±‚ã€‚å…‰ç”µè½¬æ¢çš„æ—¶å€™åšäº†ç‰¹æ®Šçš„éžçº¿æ€§ç¼–ç ï¼Œä¸ºæš—éƒ¨ç»†èŠ‚åˆ†é…æ›´å¤šçš„ç çŽ‡ï¼Œäº®éƒ¨ç»†èŠ‚è¿›è¡Œäº†åŽ‹ç¼©æˆ–è€…æˆªæ–­å‡å°‘ç çŽ‡çš„åˆ†é…ã€‚ç”µå…‰è½¬æ¢è¿›è¡Œæ˜¾ç¤ºè¿˜åŽŸçš„æ—¶å€™ï¼Œé€šè¿‡åº”ç”¨ä¸€ä¸ªé€†çš„éžçº¿æ€§å˜åŒ–ï¼Œè¿˜åŽŸå‡ºçº¿æ€§å…‰ã€‚ Infoé€šè¿‡mediainfo æŸ¥çœ‹ä¸€ä¸ªHDRè§†é¢‘ä¿¡æ¯ Video ID 1 Format HEVC Format/Info High Efficiency Video Coding Format profile Main 10@L5@High Codec ID hvc1 Codec ID/Info High Efficiency Video Coding Duration 14 s 0 ms Bit rate 123 kb/s Width 3 840 pixels Height 2 160 pixels Display aspect ratio 16:9 Frame rate mode Constant Frame rate 30.000 FPS Color space YUV Chroma subsampling 4:2:0 Bit depth 10 bits Scan type Progressive Bits/(PixelFrame)* 0.000 Stream size 211 KiB (98%) Title Core Media Video Encoded date UTC 2020-06-14 21:45:40 Tagged date UTC 2020-06-14 21:47:33 Color range Limited Color primaries BT.2020 Transfer characteristics HLG Matrix coefficients BT.2020 non-constant Codec configuration box hvcC ä¸‹é¢å‡ ä¸ªå‚æ•°å±žäºŽå…ƒæ•°æ® ï¼Œå¯èƒ½æ²¡æœ‰ åŽæ–‡ä¼šè®²åˆ° Video Mastering display color primaries Display P3 / R: x=0.677980 y=0.321980, G: x=0.245000 y=0.703000, B: x=0.137980 y=0.052000, White point: x=0.312680 y=0.328980 Mastering display luminance min: 0.0001 cd/m2, max: 1000 cd/m2 Maximum Content Light Level 1000 cd/m2 Maximum Frame-Average Light Level 400 cd/m2 é‡ç‚¹å…³æ³¨ ï¼š Color range ï¼šè‰²å½©èŒƒå›´ Color primaries ï¼šè‰²å½©åŽŸè‰² Transfer characteristics ï¼šä¼ è¾“ç‰¹æ€§ Matrix coefficients ï¼šçŸ©é˜µç³»æ•° å…ƒæ•°æ®å­—æ®µ Mastering display color primaries Mastering display luminance Maximum Content Light Level Maximum Frame-Average Light Level éƒ¨åˆ†å‚æ•°å¯ä»¥é€šè¿‡ffprobeæŸ¥çœ‹å¯¹åº”çš„é€‰é¡¹ ffprobe -h &gt;&gt; ffprobe.txt Color rangeè‰²å½©èŒƒå›´ä¸»è¦æ˜¯ä¸¤ä¸ªï¼š Full range ï¼ˆPC range ï¼‰ Video rangeï¼ˆlimited rangeï¼Œtv rangeï¼‰ Full Range å°±æ˜¯æˆ‘ä»¬æ‰€ç†Ÿæ‚‰çš„ [0, 255]ï¼Œè€Œåœ¨ Limited Range ä¸­ï¼ŒYâ€™ çš„å€¼è¢«é™åˆ¶åœ¨ [16, 235]ï¼ŒCb å’Œ Cr çš„å€¼è¢«é™åˆ¶åœ¨ [16, 240] ï¼ˆé’ˆå¯¹8bitçš„ï¼‰ã€‚ HDRä¸€ä¸ªé‡è¦å±žæ€§å°±æ˜¯é‡åŒ–ç²¾åº¦ã€‚ SDRæŠ€æœ¯ä½¿ç”¨8bitè¿›è¡Œé¢œè‰²çš„è¡¨è¾¾ï¼Œè€ŒHDRä½¿ç”¨10bit/12bitè¿›è¡Œé¢œè‰²çš„è¡¨ç¤ºï¼Œä»Žè€Œå‡å°‘äº†8bitå®¹æ˜“å‡ºçŽ°çš„äººä¸ºæ¡å¸¦æ•ˆåº”ã€‚ ios ä¸­çš„ç²¾åº¦ &amp; è‰²å½©èŒƒå›´ ï¼š 123kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange = &apos;420v&apos;, /* Bi-Planar Component Y&apos;CbCr 8-bit 4:2:0, video-range (luma=[16,235] chroma=[16,240]). baseAddr points to a big-endian CVPlanarPixelBufferInfo_YCbCrBiPlanar struct */kCVPixelFormatType_420YpCbCr10BiPlanarVideoRange = &apos;x420&apos;, /* 2 plane YCbCr10 4:2:0, each 10 bits in the MSBs of 16bits, video-range (luma=[64,940] chroma=[64,960]) */ 123kCVPixelFormatType_420YpCbCr8BiPlanarFullRange = &apos;420f&apos;, /* Bi-Planar Component Y&apos;CbCr 8-bit 4:2:0, full-range (luma=[0,255] chroma=[1,255]). baseAddr points to a big-endian CVPlanarPixelBufferInfo_YCbCrBiPlanar struct */ kCVPixelFormatType_420YpCbCr10BiPlanarFullRange = &apos;xf20&apos;, /* 2 plane YCbCr10 4:2:0, each 10 bits in the MSBs of 16bits, full-range (Y range 0-1023) */ å…³äºŽä¸ºä»€ä¹ˆè¦å°†YUVé‡åŒ–ä¸ºtv range 16-235 ï¼Ÿ ä»¥ä¸‹æ˜¯ç»´åŸºç™¾ç§‘æ‘˜æŠ„çš„ä¸€æ®µï¼Œ æ„æ€æ˜¯tv rangeæ˜¯ä¸ºäº†è§£å†³æ»¤æ³¢ï¼ˆæ¨¡æ•°è½¬æ¢ï¼‰åŽçš„è¿‡å†²çŽ°è±¡ï¼Œ Yâ€² values are conventionally shifted and scaled to the range [16, 235] (referred to as studio swing or â€œTV levelsâ€) rather than using the full range of [0, 255] (referred to as full swing or â€œPC levelsâ€). This practice was standardized in SMPTE-125M in order to accommodate signal overshoots (â€œringingâ€) due to filtering. The value 235 accommodates a maximal black-to-white overshoot of 255 âˆ’ 235 = 20, or 20 / (235 âˆ’ 16) = 9.1%, which is slightly larger than the theoretical maximal overshoot (Gibbs phenomenon) of about 8.9% of the maximal step. The toe-room is smaller, allowing only 16 / 219 = 7.3% overshoot, which is less than the theoretical maximal overshoot of 8.9%. This is why 16 is added to Yâ€² and why the Yâ€² coefficients in the basic transform sum to 220 instead of 255.^[9]^ U and V values, which may be positive or negative, are summed with 128 to make them always positive, giving a studio range of 16â€“240 for U and V. (These ranges are important in video editing and production, since using the wrong range will result either in an image with â€œclippedâ€ blacks and whites, or a low-contrast image.) Color primariesä¸€èˆ¬ç†è§£ä¸ºè‰²åŸŸï¼Œè‰²åŸŸæŒ‡å¯ä»¥æ˜¾ç¤ºçš„æ‰€æœ‰é¢œè‰²çš„èŒƒå›´ï¼Œå¸¸è§çš„æœ‰Rec.709ï¼ˆå…¨é«˜æ¸…å¹¿æ’­æ ‡å‡†ï¼‰ã€Rec.2020ï¼ˆ4K/8Kå¹¿æ’­æ ‡å‡†BT.2020ï¼‰ã€Adobe RGBã€P3ç­‰ã€‚ bt709 unknown reserved bt470m bt470bg smpte170m smpte240m film bt2020 smpte428 smpte431 smpte432 ä¸‹å›¾æ˜¾ç¤ºäº†äººçœ¼èƒ½å¤Ÿæ„ŸçŸ¥çš„æ‰€æœ‰RGBå€¼çš„èŒƒå›´ã€‚ä¸‰è§’å½¢è¡¨ç¤ºè‰²åŸŸï¼šä¸‰è§’å½¢è¶Šå¤§ï¼Œå¯ä»¥æ˜¾ç¤ºçš„é¢œè‰²è¶Šå¤šã€‚ è¿™å¼ é©¬è¹„å½¢çš„å›¾ä¸Šé¢å¯ä»¥çœ‹åˆ°HDRä½¿ç”¨çš„è‰²åŸŸæ˜¯BT2020ï¼Œ SDRä½¿ç”¨çš„æ˜¯BT709ï¼Œå¯ä»¥æ˜Žæ˜¾çœ‹åˆ°HDRçš„è‰²åŸŸå¤§äºŽSDRã€‚ ç†è§£é¢œè‰²ç©ºé—´ï¼š é¢œè‰²ç©ºé—´ ç”± é¢œè‰²æ¨¡åž‹ è·Ÿ è‰²åŸŸ å…±åŒå®šä¹‰ã€‚é¢œè‰²æ¨¡åž‹çš„æ¦‚å¿µä¸ºï¼šä¸€ç§æŠ½è±¡æ•°å­¦æ¨¡åž‹ï¼Œé€šè¿‡ä¸€ç»„æ•°å­—æ¥æè¿°é¢œè‰²ï¼ˆä¾‹å¦‚RGBä½¿ç”¨ä¸‰å…ƒç»„ã€CMYKä½¿ç”¨å››å…ƒç»„ï¼‰ä¾‹å¦‚Adobe RGBå’ŒsRGBéƒ½åŸºäºŽRGBé¢œè‰²æ¨¡åž‹ï¼Œä½†å®ƒä»¬æ˜¯ä¸¤ä¸ªä¸åŒçš„é¢œè‰²ç©ºé—´ï¼Œå› ä¸ºè‰²åŸŸä¸ä¸€æ · Color Transferæè¿°å…‰ç”µè½¬æ¢è¿‡ç¨‹çš„è§†é¢‘å±žæ€§ä¹Ÿå«é¢œè‰²ä¼ è¾“å‡½æ•°Color Transfer å°±æ˜¯ä¸Šé¢è¡¨æ ¼é‡Œé¢çš„ Transfer characteristics å¸¸è§çš„hdrè½¬æ¢æ›²çº¿ä¸ºHLGå’ŒPQï¼Œå…¶ä¸­ï¼Œsmpte2084ä¸ºPQæ›²çº¿ï¼ˆæ„ŸçŸ¥é‡åŒ–ï¼‰ï¼Œarib-std-b67ä¸ºHLGæ›²çº¿ï¼ˆæ··åˆå¯¹æ•°ä¼½çŽ›ï¼‰ bt709 unknown reserved bt470m bt470bg smpte170m smpte240m linear log100 log316 iec61966-2-4 bt1361e iec61966-2-1 bt2020-10 bt2020-12 smpte2084 smpte428 arib-std-b67 ä¼ ç»Ÿçš„SDRè§†é¢‘ä½¿ç”¨çš„BT709çš„å…‰ç”µè½¬æ¢å‡½æ•°ï¼Œå¯¹é«˜äº®éƒ¨åˆ†è¿›è¡Œäº†æˆªæ–­ï¼Œå¯ä»¥è¡¨è¾¾çš„äº®åº¦åŠ¨æ€èŒƒå›´æœ‰é™ï¼Œæœ€å¤§äº®åº¦åªæœ‰100nitã€‚è€ŒHDRè§†é¢‘ï¼Œå¢žåŠ äº†é«˜äº®éƒ¨åˆ†ç»†èŠ‚çš„è¡¨è¾¾ï¼Œå¾ˆå¤§çš„æ‰©å±•äº®åº¦çš„åŠ¨æ€èŒƒå›´ã€‚ ä¸åŒHDRçš„è®¾è®¡åˆè¡·ä¸åŒï¼Œå…¶ä¸­PQçš„è®¾è®¡æ›´æŽ¥è¿‘äººçœ¼çš„ç‰¹ç‚¹ï¼Œäº®åº¦è¡¨è¾¾æ›´å‡†ç¡®ï¼Œå¯ä»¥è¡¨ç¤ºé«˜è¾¾10000nitçš„äº®åº¦ã€‚è€ŒHLGçš„è®¾è®¡è€ƒè™‘äº†è€è®¾å¤‡çš„å…¼å®¹æ€§ï¼Œå’Œä¼ ç»Ÿbt709çš„ä¼ è¾“å‡½æ•°æœ‰éƒ¨åˆ†æ˜¯é‡åˆçš„ï¼Œå¤©ç„¶çš„å¯¹è€è®¾å¤‡å…·æœ‰ä¸€å®šå…¼å®¹æ€§ MetadataHDRå…ƒæ•°æ®åˆ†ä¸ºä¸¤ç§ï¼Œé™æ€å…ƒæ•°æ® å’ŒåŠ¨æ€å…ƒæ•°æ® ï¼› ä½¿ç”¨PQæ›²çº¿çš„HDR10æ˜¯é‡‡ç”¨é™æ€å…ƒæ•°æ®çš„ï¼Œä½†æ˜¯æœæ¯”å…¬å¸æå‡ºæ¥çš„æœæ¯”è§†ç•Œå’Œä¸‰æ˜Ÿçš„HDR10+ï¼Œå°½ç®¡ä½¿ç”¨äº†PQæ›²çº¿ï¼Œä½†æ˜¯ä»–ä»¬ä½¿ç”¨çš„æ˜¯åŠ¨æ€å…ƒæ•°æ®ï¼ŒHLGæ²¡æœ‰å…ƒæ•°æ®ã€‚ å…¶ä¸­ DolbyVision ç­‰ä»·äºŽSMPTE ST 2094-10, HDR10+ ç­‰ä»·äºŽ SMPTE ST 2094-40 é™æ€å…ƒæ•°æ®è§„å®šäº†æ•´ä¸ªç‰‡å­åƒç´ çº§åˆ«æœ€å¤§äº®åº¦ä¸Šé™ï¼Œåœ¨ST 2086ä¸­æœ‰æ ‡å‡†åŒ–çš„å®šä¹‰ã€‚é™æ€å…ƒæ•°æ®çš„ç¼ºç‚¹æ˜¯å¿…é¡»åšå…¨å±€çš„è‰²è°ƒæ˜ å°„ï¼Œæ²¡æœ‰è¶³å¤Ÿçš„è°ƒèŠ‚ç©ºé—´ï¼Œå…¼å®¹æ€§ä¸å¥½ã€‚ åŠ¨æ€å…ƒæ•°æ®å¯ä»¥å¾ˆå¥½åœ°è§£å†³è¿™ä¸ªé—®é¢˜ã€‚åŠ¨æ€å…ƒæ•°æ®ä¸»è¦æœ‰ä¸¤ä¸ªæ–¹é¢çš„ä½œç”¨ï¼šä¸Žé™æ€å…ƒæ•°æ®ç›¸æ¯”ï¼Œå®ƒå¯ä»¥åœ¨æ¯ä¸€ä¸ªåœºæ™¯æˆ–è€…æ¯ä¸€å¸§ç”»é¢ï¼Œç»™è°ƒè‰²å¸ˆä¸€ä¸ªå‘æŒ¥çš„ç©ºé—´ï¼Œä»¥å±•çŽ°æ›´ä¸°å¯Œçš„ç»†èŠ‚ï¼›å¦ä¸€ä¸ªæ–¹é¢ï¼Œé€šè¿‡åŠ¨æ€å…ƒæ•°æ®ï¼Œåœ¨ç›®æ ‡æ˜¾ç¤ºäº®åº¦ä¸Šåšè‰²è°ƒæ˜ å°„ï¼Œå¯ä»¥æœ€å¤§ç¨‹åº¦åœ¨ç›®æ ‡æ˜¾ç¤ºå™¨ä¸Šå‘ˆçŽ°ä½œè€…çš„åˆ›ä½œæ„å›¾ã€‚ æœ€å¤§å†…å®¹äº®åº¦ï¼ˆMaxCLLï¼‰ï¼šæ•´ä¸ªè§†é¢‘æµä¸­æœ€äº®åƒç´ çš„äº®åº¦ã€‚ æœ€å¤§å¸§å¹³å‡äº®åº¦ï¼ˆMaxFALLï¼‰ï¼šæ•´ä¸ªè§†é¢‘æµä¸­æœ€äº®å¸§çš„å¹³å‡äº®åº¦ å¦å¤–è§£é‡Šä¸€ä¸‹å¤šå‡ºçŽ°çš„å‡ ä¸ªå‚æ•°:progressive,SAR,DAR. progressive,å…¶å®žå°±æ˜¯æ‰«ææ–¹å¼,é€è¡Œæ‰«æ.å¦å¤–çš„ä¸€ç§æ–¹å¼å°±æ˜¯éš”è¡Œæ‰«æ:interlaced.æˆ‘ä»¬å¹³æ—¶æ‰€è°“çš„1080p,è¿™ä¸ªpå°±æ˜¯progressive,è¡¨ç¤ºçš„æ˜¯1080å°ºå¯¸çš„é€è¡Œæ‰«æè§†é¢‘.DAR - display aspect ratioå°±æ˜¯è§†é¢‘æ’­æ”¾æ—¶ï¼Œæˆ‘ä»¬çœ‹åˆ°çš„å›¾åƒå®½é«˜çš„æ¯”ä¾‹ï¼Œç¼©æ”¾è§†é¢‘ä¹Ÿè¦æŒ‰è¿™ä¸ªæ¯”ä¾‹æ¥ï¼Œå¦åˆ™ä¼šä½¿å›¾åƒçœ‹èµ·æ¥è¢«åŽ‹æ‰æˆ–è€…æ‹‰é•¿äº†ä¼¼çš„ã€‚ SAR - storage aspect ratioå°±æ˜¯å¯¹å›¾åƒé‡‡é›†æ—¶ï¼Œæ¨ªå‘é‡‡é›†ä¸Žçºµå‘é‡‡é›†æž„æˆçš„ç‚¹é˜µï¼Œæ¨ªå‘ç‚¹æ•°ä¸Žçºµå‘ç‚¹æ•°çš„æ¯”å€¼ã€‚æ¯”å¦‚VGAå›¾åƒ640/480 = 4:3ï¼ŒD-1 PALå›¾åƒ720/576 = 5:4 PAR - pixel aspect ratioå¤§å¤šæ•°æƒ…å†µä¸º1:1,å°±æ˜¯ä¸€ä¸ªæ­£æ–¹å½¢åƒç´ ï¼Œå¦åˆ™ä¸ºé•¿æ–¹å½¢åƒç´ è¿™ä¸‰è€…çš„å…³ç³»PAR x SAR = DARæˆ–è€…PAR = DAR/SAR Tone Mappingè‰²è°ƒæ˜ å°„çš„ç›®çš„æ˜¯ä½¿é«˜åŠ¨æ€èŒƒå›´HDRå›¾åƒèƒ½å¤Ÿé€‚åº”ä½ŽåŠ¨æ€èŒƒå›´LDRæ˜¾ç¤ºå™¨ã€‚ è‰²è°ƒæ˜ å°„ç®—æ³•çš„ç›®çš„åœ¨äºŽå°†HDRå›¾åƒçš„äº®åº¦è¿›è¡ŒåŽ‹ç¼©ï¼Œè¿›è€Œæ˜ å°„åˆ°LDRæ˜¾ç¤ºè®¾å¤‡çš„æ˜¾ç¤ºèŒƒå›´ä¹‹å†…ï¼ŒåŒæ—¶ï¼Œåœ¨æ˜ å°„çš„è¿‡ç¨‹ä¸­è¦å°½é‡ä¿æŒåŽŸHDRå›¾åƒçš„ç»†èŠ‚ä¸Žé¢œè‰²ç­‰é‡è¦ä¿¡æ¯ã€‚ æ‰€ä»¥è‰²è°ƒæ˜ å°„ç®—æ³•éœ€è¦å…·æœ‰ä¸¤æ–¹é¢çš„æ€§è´¨ï¼š èƒ½å¤Ÿå°†å›¾åƒäº®åº¦è¿›è¡ŒåŽ‹ç¼©ã€‚ èƒ½å¤Ÿä¿æŒå›¾åƒç»†èŠ‚ä¸Žé¢œè‰²ã€‚ EOTF/OETF HLG 1234567891011121314151617181920212223242526272829float ARIB_B67_A = 0.17883277;float ARIB_B67_B = 0.28466892;float ARIB_B67_C = 0.55991073;highp float arib_b67_inverse_oetf(highp float x)&#123; x = max(x, 0.0); if (x &lt;= (1.0/2.0)) x = (x * x) * (1.0 / 3.0); else x = (exp((x - ARIB_B67_C) / ARIB_B67_A) + ARIB_B67_B) / 12.0; return x;&#125;highp float arib_b67_ootf(highp float x)&#123; return x &lt; 0.0 ? x : pow(x, 1.2);&#125;highp float arib_b67_eotf(highp float x)&#123; return arib_b67_ootf(arib_b67_inverse_oetf(x));&#125;highp float arib_b67_oetf(highp float x)&#123; x = max(x, 0.0); if (x &lt;= (1.0 / 12.0)) x = sqrt(3.0 * x); else x = ARIB_B67_A * log(12.0 * x - ARIB_B67_B) + ARIB_B67_C; return x;&#125; PQ 12345678910111213highp float ST2084_M1 = 0.1593017578125;const float ST2084_M2 = 78.84375;const float ST2084_C1 = 0.8359375;const float ST2084_C2 = 18.8515625;const float ST2084_C3 = 18.6875;highp float FLT_MIN = 1.17549435082228750797e-38;highp float st_2084_eotf(highp float x)&#123; highp float xpow = pow(x, float(1.0 / ST2084_M2)); highp float num = max(xpow - ST2084_C1, 0.0); highp float den = max(ST2084_C2 - ST2084_C3 * xpow, FLT_MIN); return pow(num/den, 1.0 / ST2084_M1);&#125; BT.709 1234567891011const float REC709_ALPHA = 1.09929682680944;const float REC709_BETA = 0.018053968510807;highp float rec_709_oetf(highp float x)&#123; x = max(x, 0.0); if (x &lt; REC709_BETA ) x = x * 4.5; else x = REC709_ALPHA * pow(x, 0.45) - (REC709_ALPHA - 1.0); return x;&#125; bt2020 -&gt; bt709 1231.6605, -0.5876, -0.0728-0.1246, 1.1329, -0.0083-0.0182, -0.1006, 1.1187 bt709 -&gt; bt2020 1230.6274, 0.3293, 0.04330.0691, 0.9195, 0.01140.0164, 0.0880, 0.8956 Matrix coefficientsYCbCr-&gt;RGB Video Range 1234567891011121314151617181920// BT.601, which is the standard for SDTV.static const GLfloat kColorConversion601[] = &#123; 1.164, 1.164, 1.164, 0.0, -0.392, 2.017, 1.596, -0.813, 0.0,&#125;;// BT.709, which is the standard for HDTV.static const GLfloat kColorConversion709[] = &#123; 1.164, 1.164, 1.164, 0.0, -0.213, 2.112, 1.793, -0.533, 0.0,&#125;;// BT.2020 (which is the standard for UHDTV, ITU_R_2020 )static const GLfloat kColorConversion2020[] = &#123; 1.1644f, 1.1644f, 1.1644f, 0.0f, -0.1881, 2.1501, 1.6853, -0.6529, 0.0f,&#125;; Full Range 1234567891011121314151617181920// BT.601 full range static const GLfloat kColorConversion601FullRange[] = &#123;1.0, 1.0, 1.0,0.0, -0.343, 1.765,1.4, -0.711, 0.0,&#125;;// BT.709 full range static const GLfloat kColorConversion709FullRange[] = &#123;1.0, 1.0, 1.0,0.0, -0.187, 1.855,1.574, -0.468, 0.0,&#125;;// BT.2020 full range static const GLfloat kColorConversion2020FullRange[] = &#123;1.0, 1.0, 1.0,0.0, -0.1645, 1.8814,1.4746, -0.5713, 0.0,&#125;; OpenGL Video Range 1234567891011121314151617precision mediump float; varying mediump vec2 textureCoordinate; uniform sampler2D luminanceTexture; uniform sampler2D chrominanceTexture; uniform highp mat3 colorConversionMatrix; void main() &#123; mediump vec3 yuv; highp vec3 rgb; yuv.x = texture2D(luminanceTexture, textureCoordinate).r - (16.0/255.0); yuv.yz = texture2D(chrominanceTexture, textureCoordinate).ra - vec2(0.5, 0.5); rgb = colorConversionMatrix * yuv; gl_FragColor = vec4(rgb, 1.); &#125; Full Range 12345678910111213141516precision mediump float; varying mediump vec2 textureCoordinate; uniform sampler2D luminanceTexture; uniform sampler2D chrominanceTexture; uniform highp mat3 colorConversionMatrix; void main() &#123; mediump vec3 yuv; highp vec3 rgb; yuv.x = texture2D(luminanceTexture, textureCoordinate).r; yuv.yz = texture2D(chrominanceTexture, textureCoordinate).ra - vec2(0.5, 0.5); rgb = colorConversionMatrix * yuv; gl_FragColor = vec4(rgb, 1.); &#125; RGB-YUV123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687// FULL RANGE static void bt2020_rgb2yuv10bit_PC(uint8_t R, uint8_t G, uint8_t B, uint16_t &amp;Y, uint16_t &amp;U, uint16_t &amp;V) &#123; Y = 0.2627 * R + 0.6780 * G + 0.0593 * B; U = -0.1396 * R - 0.3604 * G + 0.5000 * B + 128; V = 0.5000 * R - 0.4598 * G - 0.0402 * B + 128; Y = Y &lt;&lt; 8; U = U &lt;&lt; 8; V = V &lt;&lt; 8; &#125; // VIDEO RANGE static void bt2020_rgb2yuv10bit_TV(uint8_t R, uint8_t G, uint8_t B, uint16_t &amp;Y, uint16_t &amp;U, uint16_t &amp;V) &#123; Y = 0.2256 * R + 0.5823 * G + 0.0509 * B + 16; U = -0.1222 * R - 0.3154 * G + 0.4375 * B + 128; V = 0.4375 * R - 0.4023 * G - 0.0352 * B + 128; /// 8 åˆ†è§£ä¸º2 + 6 /// &lt;&lt;2 ï¼šå¯¹åº” æŠŠ yuv ä»Ž (luma=[16,235] chroma=[16,240]) æ‹‰åˆ° (luma=[64,940] chroma=[64,960]) /// &lt;&lt;6 ï¼š10bit æŒ‰å­—èŠ‚ä¸ºå•ä½éœ€è¦ä¸¤ä¸ªå­—èŠ‚ï¼Œå› ä¸ºæŒ‰ç…§å¤§ç«¯æ¨¡å¼å­˜å‚¨ï¼ˆä½Žåœ°å€åˆ°é«˜åœ°å€çš„é¡ºåºå­˜æ”¾æ•°æ®çš„é«˜ä½å­—èŠ‚åˆ°ä½Žä½å­—èŠ‚ï¼‰åŽé¢6ä¸ªbitæ˜¯padding è¡¥0 Y = Y &lt;&lt; 8; U = U &lt;&lt; 8; V = V &lt;&lt; 8; &#125; // FULL RANGE static void bt709_rgb2yuv10bit_PC(uint8_t R, uint8_t G, uint8_t B, uint16_t &amp;Y, uint16_t &amp;U, uint16_t &amp;V) &#123; Y = 0.2126 * R + 0.7152 * G + 0.0722 * B; U = -0.1146 * R - 0.3854 * G + 0.5000 * B + 128; V = 0.5000 * R - 0.4542 * G - 0.0458 * B + 128; Y = Y &lt;&lt; 8; U = U &lt;&lt; 8; V = V &lt;&lt; 8; &#125; // VIDEO RANGE static void bt709_rgb2yuv10bit_TV(uint8_t R, uint8_t G, uint8_t B, uint16_t &amp;Y, uint16_t &amp;U, uint16_t &amp;V) &#123; Y = 0.183 * R + 0.614 * G + 0.062 * B + 16; U = -0.101 * R - 0.339 * G + 0.439 * B + 128; V = 0.439 * R - 0.399 * G - 0.040 * B + 128; Y = Y &lt;&lt; 8; U = U &lt;&lt; 8; V = V &lt;&lt; 8; &#125; // FULL RANGE static void bt601_rgb2yuv10bit_PC(uint8_t R, uint8_t G, uint8_t B, uint16_t &amp;Y, uint16_t &amp;U, uint16_t &amp;V) &#123; Y = 0.299 * R + 0.587 * G + 0.114 * B; U = -0.169 * R - 0.331 * G + 0.500 * B + 128; V = 0.500 * R - 0.419 * G - 0.081 * B + 128; Y = Y &lt;&lt; 8; U = U &lt;&lt; 8; V = V &lt;&lt; 8; &#125; // VIDEO RANGE static void bt601_rgb2yuv10bit_TV(uint8_t R, uint8_t G, uint8_t B, uint16_t &amp;Y, uint16_t &amp;U, uint16_t &amp;V) &#123; Y = 0.257 * R + 0.504 * G + 0.098 * B + 16; U = -0.148 * R - 0.291 * G + 0.439 * B + 128; V = 0.439 * R - 0.368 * G - 0.071 * B + 128; Y = Y &lt;&lt; 8; U = U &lt;&lt; 8; V = V &lt;&lt; 8; &#125; // FULL RANGE static void bt601_rgb2yuv_PC(uint8_t R, uint8_t G, uint8_t B, uint8_t &amp;Y, uint8_t &amp;U, uint8_t &amp;V) &#123; Y = 0.299 * R + 0.587 * G + 0.114 * B; U = -0.169 * R - 0.331 * G + 0.500 * B + 128; V = 0.500 * R - 0.419 * G - 0.081 * B + 128; &#125; // VIDEO RANGE static void bt601_rgb2yuv_TV(uint8_t R, uint8_t G, uint8_t B, uint8_t &amp;Y, uint8_t &amp;U, uint8_t &amp;V) &#123; Y = 0.257 * R + 0.504 * G + 0.098 * B + 16; U = -0.148 * R - 0.291 * G + 0.439 * B + 128; V = 0.439 * R - 0.368 * G - 0.071 * B + 128; &#125; 12345678910111213141516171819202122inline CFDictionaryRef HDRAttachmentsOfMedium(void) &#123; const size_t attributes_size = 6; CFTypeRef keys[attributes_size] = &#123; kCVImageBufferFieldCountKey, kCVImageBufferChromaLocationBottomFieldKey, kCVImageBufferChromaLocationTopFieldKey, kCVImageBufferTransferFunctionKey, kCVImageBufferColorPrimariesKey, kCVImageBufferYCbCrMatrixKey &#125;; CFTypeRef values[attributes_size] = &#123; kCFBooleanTrue, kCVImageBufferChromaLocation_Left, kCVImageBufferChromaLocation_Left, kCVImageBufferTransferFunction_ITU_R_2100_HLG, kCVImageBufferColorPrimaries_ITU_R_2020, kCVImageBufferYCbCrMatrix_ITU_R_2020 &#125;; return CreateCFDictionary(keys, values, attributes_size); &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495CVPixelBufferRef RGB2YCbCr10Bit(CVPixelBufferRef pixelBuffer, CFDictionaryRef dic) &#123; CVPixelBufferLockBaseAddress(pixelBuffer, 0); uint8_t *baseAddress = (uint8_t *)CVPixelBufferGetBaseAddress(pixelBuffer); int w = (int) CVPixelBufferGetWidth(pixelBuffer); int h = (int) CVPixelBufferGetHeight(pixelBuffer); //int stride = (int) CVPixelBufferGetBytesPerRow(pixelBuffer) / 4; OSType pixelFormat = kCVPixelFormatType_420YpCbCr10BiPlanarVideoRange; CVPixelBufferRef pixelBufferCopy = NULL; const size_t attributes_size = 5; CFTypeRef keys[attributes_size] = &#123; kCVPixelBufferIOSurfacePropertiesKey, kCVPixelBufferExtendedPixelsBottomKey, kCVPixelBufferExtendedPixelsTopKey, kCVPixelBufferExtendedPixelsRightKey, kCVPixelBufferExtendedPixelsLeftKey &#125;; CFDictionaryRef io_surface_value = vtc::CreateCFDictionary(nullptr, nullptr, 0); CFTypeRef values[attributes_size] = &#123;io_surface_value, kCFBooleanFalse, kCFBooleanFalse, kCFBooleanFalse, kCFBooleanFalse&#125;; CFDictionaryRef attributes = vtc::CreateCFDictionary(keys, values, attributes_size); CVReturn status = CVPixelBufferCreate(kCFAllocatorDefault, w, h, pixelFormat, attributes, &amp;pixelBufferCopy); if (status != kCVReturnSuccess) &#123; std::cout &lt;&lt; "YUVBufferCopyWithPixelBuffer :: failed" &lt;&lt; std::endl; return nullptr; &#125; if (attributes) &#123; CFRelease(attributes); attributes = nullptr; &#125; int plane_h1 = (int) CVPixelBufferGetHeightOfPlane(pixelBufferCopy, 0); int plane_h2 = (int) CVPixelBufferGetHeightOfPlane(pixelBufferCopy, 1); CVPixelBufferLockBaseAddress(pixelBufferCopy, 0); if (dic == nullptr || CFDictionaryGetCount(dic) &lt;= 0) &#123; dic = HDRAttachmentsOfMedium(); &#125; CVBufferSetAttachments(pixelBufferCopy, dic, kCVAttachmentMode_ShouldPropagate); size_t y_stride = CVPixelBufferGetBytesPerRowOfPlane(pixelBufferCopy, 0); //size_t uv_stride = CVPixelBufferGetBytesPerRowOfPlane(pixelBufferCopy, 1); unsigned long y_bufferSize = w * h; unsigned long uv_bufferSize = w * h / 4; uint16_t *y_planeData = (uint16_t *) malloc(y_bufferSize * sizeof(uint16_t)); uint16_t *u_planeData = (uint16_t *) malloc(uv_bufferSize * sizeof(uint16_t)); uint16_t *v_planeData = (uint16_t *) malloc(uv_bufferSize * sizeof(uint16_t)); uint16_t *y = (uint16_t *) CVPixelBufferGetBaseAddressOfPlane(pixelBufferCopy, 0); uint16_t *uv = (uint16_t *) CVPixelBufferGetBaseAddressOfPlane(pixelBufferCopy, 1); int u_offset = 0; int v_offset = 0; uint8_t R, G, B; uint16_t Y, U, V; for (int i = 0; i &lt; h; i ++) &#123; for (int j = 0; j &lt; w; j ++) &#123; int offset = i * w + j; B = baseAddress[offset * 4]; G = baseAddress[offset * 4 + 1]; R = baseAddress[offset * 4 + 2]; bt2020_rgb2yuv10bit_TV(R, G, B, Y, U, V); y_planeData[offset] = Y; //éš”è¡Œæ‰«æ å¶æ•°è¡Œçš„å¶æ•°åˆ—å–U å¥‡æ•°è¡Œçš„å¶æ•°åˆ—å–V if (j % 2 == 0) &#123; (i % 2 == 0) ? u_planeData[++u_offset] = U : v_planeData[++v_offset] = V; &#125; &#125; &#125; for (int i = 0; i &lt; plane_h1; i ++) &#123; memcpy(y + i * y_stride / 2, y_planeData + i * w, 2 * w); if (i &lt; plane_h2) &#123; for (int j = 0 ; j &lt; w ; j ++) &#123; //NV12 å’Œ NV21 æ ¼å¼éƒ½å±žäºŽ YUV420SP ç±»åž‹ã€‚å®ƒä¹Ÿæ˜¯å…ˆå­˜å‚¨äº† Y åˆ†é‡ï¼Œä½†æŽ¥ä¸‹æ¥å¹¶ä¸æ˜¯å†å­˜å‚¨æ‰€æœ‰çš„ U æˆ–è€… V åˆ†é‡ï¼Œè€Œæ˜¯æŠŠ UV åˆ†é‡äº¤æ›¿è¿žç»­å­˜å‚¨ã€‚ //NV12 æ˜¯ IOS ä¸­æœ‰çš„æ¨¡å¼ï¼Œå®ƒçš„å­˜å‚¨é¡ºåºæ˜¯å…ˆå­˜ Y åˆ†é‡ï¼Œå† UV è¿›è¡Œäº¤æ›¿å­˜å‚¨ã€‚ memcpy(uv + i * y_stride / 2 + 2*j, u_planeData + i * w/2 + j, 2); memcpy(uv + i * y_stride / 2 + 2*j + 1, v_planeData + i * w/2 + j, 2); &#125; &#125; &#125; free(y_planeData); free(u_planeData); free(v_planeData); CVPixelBufferUnlockBaseAddress(pixelBuffer, 0); CVPixelBufferUnlockBaseAddress(pixelBufferCopy, 0); return pixelBufferCopy; &#125; Formula BT.601 BT.709 BT.2020 a 0.299 0.2126 0.2627 b 0.587 0.7152 0.6780 c 0.114 0.0722 0.0593 d 1.772 1.8556 1.8814 e 1.402 1.5748 1.4747 123Y = a * R + b * G + c * BCb = (B - Y) / dCr = (R - Y) / e 123R = Y + e * CrG = Y - (a * e / b) * Cr - (c * d / b) * CbB = Y + d * Cb 123a+b+c = 1e = 2 * (1 - a)d = 2* (a + b) https://www.itu.int/rec/R-REC-BT.601 https://www.itu.int/rec/R-REC-BT.709 https://www.itu.int/rec/R-REC-BT.2020 Range Deduce1234567891011121314[16/255, 16/255, 16/255, 1.0][235/255, 240/255, 240/255, 1.0]x[255/219, 0, 0, 0][0, 255/224, 0, 0][0, 0, 255/224, 0][-16/219, -128/224, -128/224, 1]=[0, -0.5, -0.5, 1.0][1, 0.5, 0.5, 1.0] å°† videorange é€šè¿‡ é½æ¬¡çŸ©é˜µ è½¬æ¢ä¸º fullrange Otherå¤§éƒ¨åˆ†å›¾åƒæ•æ‰è®¾å¤‡åœ¨ä¿å­˜å›¾åƒæ—¶ä¼šè‡ªåŠ¨åŠ ä¸Šä¼½é©¬æ ¡æ­£ï¼Œä¹Ÿå°±æ˜¯è¯´å›¾åƒä¸­å­˜å‚¨çš„æ˜¯éžçº¿æ€§ç©ºé—´ä¸­çš„é¢œè‰² éžçº¿æ€§çš„RGBè½¬æ¢ä¸ºYUVä¹Ÿæ˜¯éžçº¿æ€§ OpenGL æ— æ³•ç›´æŽ¥å¯¹ 10bit YUV è¿›è¡Œå¤„ç†ï¼Œéœ€è¦å…ˆè½¬æ¢ä¸º 8bit YUV tone mapping éœ€è¦åœ¨çº¿æ€§RGBç©ºé—´è¿›è¡Œ Referencesæžæ¸…æ¥šç¼–ç¨‹ä¸­YUVå’ŒRGBé—´çš„ç›¸äº’è½¬æ¢YUV - RGB colorconversionæŽ¨å¯¼è§†é¢‘YUVè½¬RGBçŸ©é˜µé½æ¬¡åæ ‡# Gammaæ ¡æ­£# æˆ‘ç†è§£çš„ä¼½é©¬æ ¡æ­£Colour gamut conversion from Recommendation ITU-R BT.2020 to Recommendation ITU-R BT.709Colour conversion from Recommendation ITU-R BT.709 to Recommendation ITU-R BT.2020]]></content>
      <categories>
        <category>HDR</category>
      </categories>
      <tags>
        <tag>HDR</tag>
        <tag>YUV</tag>
        <tag>OPENGL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[coreimage with metal ç¬”è®°]]></title>
    <url>%2F2022%2F08%2F08%2Fcoreimage-with-metal-%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[xcodeè¿‘æœŸæœ‰è‡ªå®šä¹‰CoreImageçš„CIFilterçš„éœ€æ±‚ï¼Œå‰æœŸé€šè¿‡CIKL å®šä¹‰ CIKernelå®Œæˆäº†ä»»åŠ¡ï¼ŒåŽé¢äº†è§£åˆ°CoreImageæ–°ç‰¹æ€§æ”¯æŒmetalçš„æ–¹å¼ç›´æŽ¥è‡ªå®šä¹‰ CIKernelï¼Œæé«˜æ•ˆçŽ‡ã€‚ CIKLçš„æ–¹å¼ï¼Œå­˜åœ¨ä¸¤ä¸ªé—®é¢˜ï¼š ç¼–å†™ kernel çš„æ—¶å€™ï¼Œæ²¡æœ‰æŠ¥é”™æç¤ºï¼Œå“ªæ€•æ˜¯å‚æ•°åé”™è¯¯éƒ½æ— æ³•æ£€æŸ¥å¤„ç†ã€‚æ•ˆçŽ‡æžä½Žã€‚ ç¿»è¯‘è½¬æ¢ï¼Œç¼–è¯‘ï¼Œéƒ½æ˜¯å‘ç”Ÿåˆ°è¿è¡Œæ—¶ï¼Œå¯¼è‡´ç¬¬ä¸€æ¬¡ä½¿ç”¨æ»¤é•œçš„æ—¶å€™ï¼Œè€—æ—¶è¾ƒä¹…ã€‚ Metal: åœ¨buildé˜¶æ®µ å°±å¯ä»¥ç¼–è¯‘ é“¾æŽ¥ .metalæ–‡ä»¶ å‚è€ƒè‹¹æžœçš„å®˜æ–¹æ–‡æ¡£ Metal Shading Language for CoreImage Kernels ,åœ¨xcode integration éƒ¨åˆ†æåˆ°åœ¨build setting è®¾ç½® Other Metal Compiler Flags, æ–‡æ¡£å·²ç»å¾ˆè€äº†ï¼ˆ2018å¹´çš„ï¼‰ï¼Œæ–°ç‰ˆçš„xcodeå·²ç»æ²¡æœ‰è¿™ä¸ªé€‰é¡¹äº†ï¼Œå¦‚æžœä¸åšå¤„ç†ï¼Œä¼šæœ‰æŠ¥é”™ &quot;/air-lld:1:1: symbol(s) not found for target &#39;air64-apple-ios12.0.0&#39;&quot; and &quot;air-lld command failed with exit code 1 (use -v to see invocation)&quot; build rulesæ–°ç‰ˆxcodeä¸­å¯ä»¥é€šè¿‡é…ç½®build rulesè§£å†³ä¸Šé¢çš„æŠ¥é”™ *.metal 1xcrun metal -c $MTL_HEADER_SEARCH_PATHS -fcikernel &quot;$&#123;INPUT_FILE_PATH&#125;&quot; -o &quot;$&#123;SCRIPT_OUTPUT_FILE_0&#125;&quot; output files : $(METAL_LIBRARY_OUTPUT_DIR)/$(INPUT_FILE_BASE).metallib *.air 1xcrun metallib -cikernel &quot;$&#123;INPUT_FILE_PATH&#125;&quot; -o &quot;$&#123;SCRIPT_OUTPUT_FILE_0&#125;&quot; output files : $(DERIVED_FILE_DIR)/$(INPUT_FILE_BASE).air å¦‚å›¾ï¼š cocoapodsbuild rules çš„æ–¹å¼å­˜åœ¨ä¸€ä¸ªé—®é¢˜ï¼Œå¦‚æžœmetal shaderæ–‡ä»¶åœ¨podåº“ä¸­ï¼Œåœ¨ä¸»å·¥ç¨‹ä»Žé…ç½®build rulesæ— æ³•é’ˆå¯¹podä¸­çš„resouce ç”Ÿæ•ˆï¼Œè™½ç„¶å¯ä»¥æ‰‹åŠ¨é’ˆå¯¹pod target é…ç½®build rulesè§£å†³é—®é¢˜ï¼Œä½†æ˜¯è¿™æ ·é…ç½®æ˜¯ä¸€æ¬¡æ€§çš„ï¼Œæ— æ³•æäº¤ä¿å­˜ï¼Œä¸‹ä¸€æ¬¡pod updateå°±æ¸…ç©ºäº†ï¼Œæ‰€ä»¥åˆ°äº†è¿™é‡Œå°±å¾ˆè‡ªç„¶çš„èƒ½æƒ³åˆ°é€šè¿‡pod çš„post hook æ¥è§£å†³é—®é¢˜ï¼ŒæŽ¥ä¸‹æ¥å°±æ˜¯æ€Žä¹ˆç”¨ruby æ¥å†™ pod hook è„šæœ¬äº† é€šè¿‡ä¹‹å‰åœ¨ä¸»å·¥ç¨‹é…ç½®build rules, å¯ä»¥çœ‹åˆ°project.pbxprojæ–‡ä»¶çš„å˜æ›´æƒ…å†µ 123456789101112131415161718192021222324252627282930/* Begin PBXBuildRule section */ BF25E98B28A0A91A00188AE3 /* PBXBuildRule */ = &#123; isa = PBXBuildRule; compilerSpec = com.apple.compilers.proxy.script; filePatterns = &quot;*.metal&quot;; fileType = pattern.proxy; inputFiles = ( ); isEditable = 1; outputFiles = ( &quot;$(DERIVED_FILE_DIR)/$(INPUT_FILE_BASE).air&quot;, ); runOncePerArchitecture = 0; script = &quot;# Type a script or drag a script file from your workspace to insert its path.\nxcrun metal -c $MTL_HEADER_SEARCH_PATHS -fcikernel \&quot;$&#123;INPUT_FILE_PATH&#125;\&quot; -o \&quot;$&#123;SCRIPT_OUTPUT_FILE_0&#125;\&quot;\n&quot;; &#125;; BF25E98C28A0A92200188AE3 /* PBXBuildRule */ = &#123; isa = PBXBuildRule; compilerSpec = com.apple.compilers.proxy.script; filePatterns = &quot;*.air&quot;; fileType = pattern.proxy; inputFiles = ( ); isEditable = 1; outputFiles = ( &quot;$(METAL_LIBRARY_OUTPUT_DIR)/$(INPUT_FILE_BASE).metallib&quot;, ); runOncePerArchitecture = 0; script = &quot;# Type a script or drag a script file from your workspace to insert its path.\nxcrun metallib -cikernel \&quot;$&#123;INPUT_FILE_PATH&#125;\&quot; -o \&quot;$&#123;SCRIPT_OUTPUT_FILE_0&#125;\&quot;\n&quot;; &#125;;/* End PBXBuildRule section */ å“ˆå“ˆ ï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬éœ€è¦çš„build ruleçš„å­—æ®µ æœ€ç»ˆçš„ MetalBuildRule.rb æ–‡ä»¶å¦‚ä¸‹ ï¼š 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#!/usr/bin/ruby# -*- coding: UTF-8 -*-def add_build_rule(target_name, project) project.targets.each do |target| if target.name == target_name# puts "#&#123;target.name&#125; has #&#123;target.build_rules.count&#125; build rule." if target.build_rules.count &gt;= 2 puts "#&#123;target.name&#125; already has 2 build rule." return end puts "Updating #&#123;target.name&#125; build rules" metal_rule = project.new(Xcodeproj::Project::Object::PBXBuildRule) metal_rule.name = 'Metal Build Rule' metal_rule.compiler_spec = 'com.apple.compilers.proxy.script' metal_rule.file_patterns = '*.metal' metal_rule.file_type = 'pattern.proxy' metal_rule.is_editable = '1' metal_rule.run_once_per_architecture = '0' metal_rule.output_files = ["$(DERIVED_FILE_DIR)/$(INPUT_FILE_BASE).air"] metal_rule.input_files = [] metal_rule.output_files_compiler_flags = [] metal_rule.script = "xcrun metal -c $MTL_HEADER_SEARCH_PATHS -fcikernel \"$&#123;INPUT_FILE_PATH&#125;\" -o \"$&#123;SCRIPT_OUTPUT_FILE_0&#125;\"" target.build_rules.append(metal_rule) air_rule = project.new(Xcodeproj::Project::Object::PBXBuildRule) air_rule.name = 'Air Build Rule' air_rule.compiler_spec = 'com.apple.compilers.proxy.script' air_rule.file_patterns = '*.air' air_rule.file_type = 'pattern.proxy' air_rule.is_editable = '1' air_rule.run_once_per_architecture = '0' air_rule.output_files = ["$(METAL_LIBRARY_OUTPUT_DIR)/$(INPUT_FILE_BASE).metallib"] air_rule.input_files = [] air_rule.output_files_compiler_flags = [] air_rule.script = "xcrun metallib -cikernel \"$&#123;INPUT_FILE_PATH&#125;\" -o \"$&#123;SCRIPT_OUTPUT_FILE_0&#125;\"" target.build_rules.append(air_rule) project.objects_by_uuid[metal_rule.uuid] = metal_rule project.objects_by_uuid[air_rule.uuid] = air_rule project.save() end endend podfile æ–‡ä»¶é‡ŒåŠ è½½ MetalBuildRule.rb, é…ç½®hook 123post_install do |installer| add_build_rule("your-target-name", installer.pods_project)end frameworkå¦‚æžœpodåº“æ˜¯é€šè¿‡cocoapods-packageræ’ä»¶ æ‰“.a æˆ–è€… .frameworkçš„æ–¹å¼æä¾›ç»™ä¸»å·¥ç¨‹ä½¿ç”¨çš„è¯ï¼Œå‘çŽ°è¿˜æ˜¯ä¼šé‡åˆ°ä¸Šæ–‡æåˆ°çš„é”™è¯¯ &quot;/air-lld:1:1: symbol(s) not found for target &#39;air64-apple-ios12.0.0&#39;&quot; and &quot;air-lld command failed with exit code 1 (use -v to see invocation)&quot; è¿™é‡Œéœ€è¦ç®€å•äº†è§£ä¸‹ cocoapods-packager çš„åŽŸç†ï¼Œæµ…æž Cocoapods-Packager å®žçŽ°.å› ä¸º cocoapods-packager ä¼šé‡æ–°ç”Ÿæˆä¸€ä¸ªpodfile æ¥æž„é€ ä¸€ä¸ªæ‰“åŒ…ç”¨çš„å·¥ç¨‹ï¼Œæ‰€ä»¥è¿™ä¸ªé”™è¯¯çš„å‡ºçŽ°è·Ÿæ–‡ç« æœ€å¼€å§‹æåˆ°çš„æƒ…å†µæ˜¯ä¸€æ¨¡ä¸€æ ·çš„ï¼Œè§£æ³•æ˜¯ä¸æ˜¯ä¹Ÿå¯ä»¥é€šè¿‡é…ç½®build ruleæ¥è§£å‘¢ï¼Œä¸è¿‡æ‰“åŒ…å·¥ç¨‹æˆ‘ä»¬çœ‹èµ·æ¥å¥½åƒæ— æ³•å¹²é¢„ï¼Œæ€Žä¹ˆè§£å‘¢ï¼Ÿ è¿˜æ˜¯è¦å›žåˆ°cocoapods-packageræ’ä»¶æ¥è§£å†³é—®é¢˜ã€‚ 1https://github.com/CocoaPods/cocoapods-packager git ä»£ç æ‹‰ä¸‹æ¥ é€šè¿‡ide(vscode/rubymine) æ‰“å¼€æ’ä»¶å·¥ç¨‹ é…ç½®å¥½å·¥ç¨‹rubyçŽ¯å¢ƒ DEBUG ä»£ç ï¼Œæ‰¾åˆ°å¹²é¢„ç‚¹ è®¾ç½®build rule ç”Ÿæˆpackager gemï¼Œå®‰è£… è¿™é‡Œæ¶‰åŠåˆ°ruby gem bundleç­‰rubyçŽ¯å¢ƒçš„åŸºæœ¬å‘½ä»¤/ç”¨æ³•ï¼Œå¯ä»¥è‡ªè¡Œgoogleä¸€ä¸‹ã€‚ é€šè¿‡åˆšåˆšæåˆ°çš„æ’ä»¶åŽŸç†ï¼Œå¾ˆå®¹æ˜“æ‰¾åˆ°å¹²é¢„ç‚¹ 1234pod_utils.rbdef install_pod(platform_name, sandbox)...end ä¿®æ”¹ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172def install_pod(platform_name, sandbox) # åˆ¤æ–­resource_bundle æ˜¯å¦æœ‰.metalæ–‡ä»¶ metal = false if @spec.attributes_hash["resource_bundle"] metal = @spec.attributes_hash["resource_bundle"][@spec.name].include?("metal") end if @spec.attributes_hash["resource_bundles"] if @spec.attributes_hash["resource_bundles"][@spec.name] @spec.attributes_hash["resource_bundles"][@spec.name].each &#123; |res| metal ||= res.include?("metal") &#125; end end ... unless static_installer.nil? static_installer.pods_project.targets.each do |target| # å¦‚æžœæœ‰.metalæ–‡ä»¶ &amp;&amp; targetåŒ¹é… -&gt; è®¾ç½® build rule if metal &amp;&amp; target.name.start_with?(@spec.name) UI.puts "#&#123;target.name&#125; has #&#123;target.build_rules.count&#125; build rule." if target.build_rules.count &gt;= 2 UI.puts "#&#123;target.name&#125; already has 2 build rule." return end metal_rule = static_installer.pods_project.new(Xcodeproj::Project::Object::PBXBuildRule) UI.puts "Updating #&#123;target.name&#125; rules" metal_rule.name = 'Metal Build Rule' metal_rule.compiler_spec = 'com.apple.compilers.proxy.script' metal_rule.file_patterns = '*.metal' metal_rule.file_type = 'pattern.proxy' metal_rule.is_editable = '1' metal_rule.run_once_per_architecture = '0' metal_rule.output_files = ["$(DERIVED_FILE_DIR)/$(INPUT_FILE_BASE).air"] metal_rule.input_files = [] metal_rule.output_files_compiler_flags = [] metal_rule.script = "xcrun metal -c $MTL_HEADER_SEARCH_PATHS -fcikernel \"$&#123;INPUT_FILE_PATH&#125;\" -o \"$&#123;SCRIPT_OUTPUT_FILE_0&#125;\"" target.build_rules.append(metal_rule) air_rule = static_installer.pods_project.new(Xcodeproj::Project::Object::PBXBuildRule) UI.puts "Updating #&#123;target.name&#125; rules" air_rule.name = 'Air Build Rule' air_rule.compiler_spec = 'com.apple.compilers.proxy.script' air_rule.file_patterns = '*.air' air_rule.file_type = 'pattern.proxy' air_rule.is_editable = '1' air_rule.run_once_per_architecture = '0' air_rule.output_files = ["$(METAL_LIBRARY_OUTPUT_DIR)/$(INPUT_FILE_BASE).metallib"] air_rule.input_files = [] air_rule.output_files_compiler_flags = [] air_rule.script = "xcrun metallib -cikernel \"$&#123;INPUT_FILE_PATH&#125;\" -o \"$&#123;SCRIPT_OUTPUT_FILE_0&#125;\"" target.build_rules.append(air_rule) static_installer.pods_project.objects_by_uuid[metal_rule.uuid] = metal_rule static_installer.pods_project.objects_by_uuid[air_rule.uuid] = air_rule static_installer.pods_project.save end ... end ... end ... end æœ€åŽé‡æ–°ç”Ÿæˆã€å®‰è£…gem 12345#!/bin/bashgem uninstall cocoapods-packagergem build cocoapods-packager.gemspecgem install cocoapods-packager podfileä½¿ç”¨è‡ªå®šä¹‰çš„cocoapods-packageræ‰“å‡ºæ¥çš„äºŒæ–¹åº“ FrameworkåŒ…ï¼ŒåŒ…å†…å®¹é‡Œé¢å·²ç»æ›¿æ¢æˆxxx.metallibæ–‡ä»¶äº†,æ‰€ä»¥ä¸»å·¥ç¨‹çš„podfile pod post hook è¦æ ¹æ®äºŒæ–¹åº“çš„æŽ¥å…¥æ–¹å¼åšä¸‹å¤„ç†ã€‚ æˆ‘è¿™è¾¹ä¸»å·¥ç¨‹æ˜¯ç”¨è¿‡cocoapod-binaryæ’ä»¶ç®¡ç†äºŒæ–¹åº“çš„åŠ å…¥ï¼Œæºç &amp;é™æ€Frameworkï¼Œä¸€èˆ¬Releaseæ¨¡å¼æå‡ç¼–è¯‘é€Ÿåº¦ï¼Œéƒ½æ˜¯ä»¥frameworkæ–¹å¼ï¼ŒDebugæ¨¡å¼æœ‰æ—¶å€™éœ€è¦åœ¨ä¸»å·¥ç¨‹DebugäºŒæ–¹åº“ï¼Œå¯ä»¥é€‰æ‹©æ˜¯æºç æ–¹å¼æŽ¥å…¥ã€‚ æœ€ç»ˆçš„é€»è¾‘å¦‚ä¸‹ï¼š 1234567891011121314151617post_install do |installer| installer.pods_project.targets.each do |target| ... target.build_configurations.each do |config| ... #Release model, no need execute if config.name != 'Release' &amp;&amp; target.name == 'your target name' puts "===================&gt; #&#123;config.name&#125;" eval(File.open('MetalBuildRule.rb').read) if File.exist? 'MetalBuildRule.rb' # metal shader build rule add_build_rule(target, installer.pods_project) end end endend DONE referencesMetalCIKLReferenceAdd custom build rule with Podfile post_install hookxcodeprojxcodeå·¥ç¨‹æ–‡ä»¶è§£æžCocoaPodsæºç ä¸Žæ’ä»¶æ–­ç‚¹è°ƒè¯•]]></content>
      <categories>
        <category>metal</category>
      </categories>
      <tags>
        <tag>metal</tag>
        <tag>coreimage</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flutter 1.17å…±äº«engine]]></title>
    <url>%2F2020%2F06%2F03%2Fflutter-1-17%E5%85%B1%E4%BA%ABengine%2F</url>
    <content type="text"><![CDATA[å‰è¨€flutter å‡çº§åˆ° 1.17ä¹‹åŽï¼Œapp ios çº¿ä¸Šé‡åˆ°ä¸€ä¸ªcrash ,é€šè¿‡å®˜æ–¹çš„ ç¬¦å·è¡¨æ–‡ä»¶ flutter.dsym è¿˜åŽŸå‡ºå †æ ˆå¦‚ä¸‹ 1234560 auto fml::internal::CopyableLambda&lt;flutter::Shell::OnPlatformViewCreated(std::__1::unique_ptr&lt;flutter::Surface, std::__1::default_delete&lt;flutter::Surface&gt; &gt;)::$_8&gt;::operator()&lt;&gt;() const (in Flutter) (make_copyable.h:24)1 auto fml::internal::CopyableLambda&lt;flutter::Shell::OnPlatformViewCreated(std::__1::unique_ptr&lt;flutter::Surface, std::__1::default_delete&lt;flutter::Surface&gt; &gt;)::$_8&gt;::operator()&lt;&gt;() const (in Flutter) (make_copyable.h:24)2 fml::MessageLoopImpl::FlushTasks(fml::FlushType) (in Flutter) (message_loop_impl.cc:129)3 fml::MessageLoopDarwin::OnTimerFire(__CFRunLoopTimer*, fml::MessageLoopDarwin*) (in Flutter) (message_loop_darwin.mm:76)9 fml::MessageLoopDarwin::Run() (in Flutter) (message_loop_darwin.mm:47)10 void* std::__1::__thread_proxy&lt;std::__1::tuple&lt;std::__1::unique_ptr&lt;std::__1::__thread_struct, std::__1::default_delete&lt;std::__1::__thread_struct&gt; &gt;, fml::Thread::Thread(std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)::$_0&gt; &gt;(void*) (in Flutter) (thread:352) è¿™é‡Œè¿˜åªèƒ½çœ‹åˆ°crashåœ¨engineçš„c++ä»£ç ä¸­ï¼Œå…·ä½“åŽŸå› æœªçŸ¥ å®šä½æˆ‘ä»¬æ ¹æ®crash ç”¨æˆ·çš„ åŸ‹ç‚¹æ—¥å¿— åˆ†æžcrashå‰çš„ ä½¿ç”¨è·¯å¾„ï¼ŒåŸºæœ¬éƒ½æ˜¯æ‰“å¼€push è½åœ°åˆ°ä¸€ä¸ªflutteré¡µé¢app çš„ ç¬¬ä¸€ä¸ªtab ä¹Ÿæ˜¯ä¸ª flutter é¡µé¢ï¼Œæ‰€ä»¥æ˜¯push å”¤èµ·appï¼Œè¿žç»­æ‰“å¼€ä¸¤ä¸ªflutteré¡µé¢ã€‚æ‰‹åŠ¨æ‰“å¼€appï¼Œç‚¹å‡»è¿›åˆ°flutteré¡µé¢æ˜¯ä¸ä¼šcrashçš„ï¼ˆè¿™ä¹ˆç®€å•çš„è·¯å¾„ï¼Œå¦‚æžœcrashï¼Œé‚£å°±è¯¥æ­»äº†ï¼‰å¾ˆå¿«æˆ‘ä»¬å°±å¯ä»¥é€šè¿‡è¿™ä¸ª è·¯å¾„ å¤çŽ° crash ï¼Œèƒ½å¤çŽ°å°±å¥½è¯´ã€‚ debug engineæºç ï¼Œå¯ä»¥å®šä½åˆ°æ›´å…·ä½“çš„åœ°æ–¹ surface_ ä¸º null ï¼ŒEXC_BAD_ACCESS é‡ŽæŒ‡é’ˆ åˆ†æžå®šä½åˆ°äº†å…·ä½“çš„ä»£ç ä½ç½®ï¼ŒæŽ¥ä¸‹æ¥åˆ†æžä¸‹é‡ŽæŒ‡é’ˆçš„åŽŸå› xcodeä¸­ crash çš„æ—¶å€™ï¼Œçœ‹åˆ°ä¸»çº¿ç¨‹çš„ å †æ ˆè®°å½• æ˜¯ä»Ž application çš„ didbecomeactive çš„ notificationå‘èµ·çš„ç”±äºŽæ˜¯ push å”¤èµ·app ï¼Œæœ‰è¿™ä¸ªé€šçŸ¥æ˜¯å¯¹çš„ï¼Œcrash æ˜¯åœ¨ å…±äº«engine çš„ raster çº¿ç¨‹ã€‚ çœ‹ä»£ç  1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#pragma mark - Application lifecycle notifications// app çš„ é¦–é¡µ flutter é¡µé¢ä¼š æ‰§è¡Œ surfaceUpdated æ–¹æ³•- (void)applicationBecameActive:(NSNotification*)notification &#123; TRACE_EVENT0("flutter", "applicationBecameActive"); if (_viewportMetrics.physical_width) [self surfaceUpdated:YES]; [self goToApplicationLifecycle:@"AppLifecycleState.resumed"];&#125;#pragma mark - Surface creation and teardown updates- (void)surfaceUpdated:(BOOL)appeared &#123; // NotifyCreated/NotifyDestroyed are synchronous and require hops between the UI and raster // thread. if (appeared) &#123; [self installFirstFrameCallback]; [_engine.get() platformViewsController] -&gt; SetFlutterView(_flutterView.get()); [_engine.get() platformViewsController] -&gt; SetFlutterViewController(self); // è¿™é‡Œ [_engine.get() platformView] -&gt; NotifyCreated(); &#125; else &#123; self.displayingFlutterUI = NO; [_engine.get() platformView] -&gt; NotifyDestroyed(); [_engine.get() platformViewsController] -&gt; SetFlutterView(nullptr); [_engine.get() platformViewsController] -&gt; SetFlutterViewController(nullptr); &#125;&#125;void PlatformView::NotifyCreated() &#123; std::unique_ptr&lt;Surface&gt; surface; // Threading: We want to use the platform view on the non-platform thread. // Using the weak pointer is illegal. But, we are going to introduce a latch // so that the platform view is not collected till the surface is obtained. auto* platform_view = this; fml::ManualResetWaitableEvent latch; fml::TaskRunner::RunNowOrPostTask( task_runners_.GetRasterTaskRunner(), [platform_view, &amp;surface, &amp;latch]() &#123; surface = platform_view-&gt;CreateRenderingSurface(); latch.Signal(); &#125;); latch.Wait(); //è¿™é‡Œ delegate_.OnPlatformViewCreated(std::move(surface));&#125;// |PlatformView::Delegate|void Shell::OnPlatformViewCreated(std::unique_ptr&lt;Surface&gt; surface) &#123; TRACE_EVENT0("flutter", "Shell::OnPlatformViewCreated"); FML_DCHECK(is_setup_); FML_DCHECK(task_runners_.GetPlatformTaskRunner()-&gt;RunsTasksOnCurrentThread()); // Note: // This is a synchronous operation because certain platforms depend on // setup/suspension of all activities that may be interacting with the GPU in // a synchronous fashion. fml::AutoResetWaitableEvent latch; auto raster_task = fml::MakeCopyable([&amp; waiting_for_first_frame = waiting_for_first_frame_, rasterizer = rasterizer_-&gt;GetWeakPtr(), // surface = std::move(surface), // &amp;latch]() mutable &#123; if (rasterizer) &#123; //è¿™é‡Œ rasterizer-&gt;Setup(std::move(surface)); &#125; waiting_for_first_frame.store(true); // Step 3: All done. Signal the latch that the platform thread is // waiting on. latch.Signal(); &#125;); ... &#125;void Rasterizer::Setup(std::unique_ptr&lt;Surface&gt; surface) &#123; surface_ = std::move(surface); if (max_cache_bytes_.has_value()) &#123; SetResourceCacheMaxBytes(max_cache_bytes_.value(), user_override_resource_cache_bytes_); &#125; compositor_context_-&gt;OnGrContextCreated(); // surface_ nullï¼ŒBAD_ACCESS if (surface_-&gt;GetExternalViewEmbedder()) &#123; const auto platform_id = task_runners_.GetPlatformTaskRunner()-&gt;GetTaskQueueId(); const auto gpu_id = task_runners_.GetRasterTaskRunner()-&gt;GetTaskQueueId(); raster_thread_merger_ = fml::MakeRefCounted&lt;fml::RasterThreadMerger&gt;(platform_id, gpu_id); &#125;&#125; è¿™ä¹ˆä¸€è·¯çœ‹ä¸‹æ¥ï¼Œsurface_æ€Žä¹ˆä¼šå˜æˆnullå‘¢ï¼Ÿä¸€èˆ¬æƒ…å†µæ˜¯ï¼Œæ‰§è¡Œ [self surfaceUpdated:NO] çš„æ—¶å€™ä¼šé”€æ¯surfaceï¼Œæ–­ç‚¹æ ¹æœ¬éƒ½æ²¡è¿›åŽ»ã€‚ç»§ç»­çœ‹ä»£ç  123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107// push è½åœ°é¡µ flutter é¡µé¢ init çš„æ—¶å€™ï¼Œä¼šé‡æ–°attach åˆ° engineï¼Œä¼šæ‰§è¡ŒsetViewControlleræ–¹æ³•- (void)setViewController:(FlutterViewController*)viewController &#123; FML_DCHECK(self.iosPlatformView); _viewController = viewController ? [viewController getWeakPtr] : fml::WeakPtr&lt;FlutterViewController&gt;(); //è¿™é‡Œ self.iosPlatformView-&gt;SetOwnerViewController(_viewController); [self maybeSetupPlatformViewChannels]; if (viewController) &#123; __block FlutterEngine* blockSelf = self; self.flutterViewControllerWillDeallocObserver = [[NSNotificationCenter defaultCenter] addObserverForName:FlutterViewControllerWillDealloc object:viewController queue:[NSOperationQueue mainQueue] usingBlock:^(NSNotification* note) &#123; [blockSelf notifyViewControllerDeallocated]; &#125;]; &#125; else &#123; self.flutterViewControllerWillDeallocObserver = nil; &#125;&#125;void PlatformViewIOS::SetOwnerViewController(fml::WeakPtr&lt;FlutterViewController&gt; owner_controller) &#123; FML_DCHECK(task_runners_.GetPlatformTaskRunner()-&gt;RunsTasksOnCurrentThread()); std::lock_guard&lt;std::mutex&gt; guard(ios_surface_mutex_); // é‡ç‚¹æ˜¯è¿™é‡Œ if (ios_surface_ || !owner_controller) &#123; // è¿™é‡Œä¼šé”€æ¯ NotifyDestroyed(); ios_surface_.reset(); accessibility_bridge_.reset(); &#125; owner_controller_ = owner_controller; // Add an observer that will clear out the owner_controller_ ivar and // the accessibility_bridge_ in case the view controller is deleted. dealloc_view_controller_observer_.reset( [[[NSNotificationCenter defaultCenter] addObserverForName:FlutterViewControllerWillDealloc object:owner_controller_.get() queue:[NSOperationQueue mainQueue] usingBlock:^(NSNotification* note) &#123; // Implicit copy of 'this' is fine. accessibility_bridge_.reset(); owner_controller_.reset(); &#125;] retain]); if (owner_controller_ &amp;&amp; [owner_controller_.get() isViewLoaded]) &#123; this-&gt;attachView(); &#125; // Do not call `NotifyCreated()` here - let FlutterViewController take care // of that when its Viewport is sized. If `NotifyCreated()` is called here, // it can occasionally get invoked before the viewport is sized resulting in // a framebuffer that will not be able to completely attach.&#125;void PlatformView::NotifyDestroyed() &#123; delegate_.OnPlatformViewDestroyed();&#125;// |PlatformView::Delegate|void Shell::OnPlatformViewDestroyed() &#123; TRACE_EVENT0("flutter", "Shell::OnPlatformViewDestroyed"); FML_DCHECK(is_setup_); FML_DCHECK(task_runners_.GetPlatformTaskRunner()-&gt;RunsTasksOnCurrentThread()); // Note: // This is a synchronous operation because certain platforms depend on // setup/suspension of all activities that may be interacting with the GPU in // a synchronous fashion. fml::AutoResetWaitableEvent latch; auto io_task = [io_manager = io_manager_.get(), &amp;latch]() &#123; // Execute any pending Skia object deletions while GPU access is still // allowed. io_manager-&gt;GetIsGpuDisabledSyncSwitch()-&gt;Execute( fml::SyncSwitch::Handlers().SetIfFalse( [&amp;] &#123; io_manager-&gt;GetSkiaUnrefQueue()-&gt;Drain(); &#125;)); // Step 3: All done. Signal the latch that the platform thread is waiting // on. latch.Signal(); &#125;; auto raster_task = [rasterizer = rasterizer_-&gt;GetWeakPtr(), io_task_runner = task_runners_.GetIOTaskRunner(), io_task]() &#123; if (rasterizer) &#123; // è¿™é‡Œ rasterizer-&gt;Teardown(); &#125; // Step 2: Next, tell the IO thread to complete its remaining work. fml::TaskRunner::RunNowOrPostTask(io_task_runner, io_task); &#125;; ...void Rasterizer::Teardown() &#123; compositor_context_-&gt;OnGrContextDestroyed(); // è¿™é‡Œ reset surface_.reset(); last_layer_tree_.reset();&#125; æ‰€ä»¥åŽŸå›  å°±æ˜¯ è½åœ°é¡µ init çš„æ—¶å€™ é‡æ–°attach å¼•æ“Žï¼ŒNotifyDestroyed æ–¹æ³• æœ€ç»ˆä¼šé”€æ¯ surfaceï¼Œè¿™æ—¶å€™æ­£å¥½rasterçº¿ç¨‹ä½¿ç”¨ surface_åšæ–¹æ³•è°ƒç”¨ã€‚ ä¿®å¤å®šä½åˆ°åŽŸå› ï¼Œä¿®å¤å°±ç®€å•äº†ï¼Œåšä¸‹ç©ºåˆ¤æ–­å°±å¥½äº†,å¦‚æžœä¸ºç©º å°±ç›´æŽ¥return 123456789101112131415161718192021void Rasterizer::Setup(std::unique_ptr&lt;Surface&gt; surface) &#123; surface_ = std::move(surface); if (!surface_) &#123; FML_DLOG(INFO) &lt;&lt; "Rasterizer::Setup called with no surface."; return; &#125; if (max_cache_bytes_.has_value()) &#123; SetResourceCacheMaxBytes(max_cache_bytes_.value(), user_override_resource_cache_bytes_); &#125; compositor_context_-&gt;OnGrContextCreated(); if (surface_-&gt;GetExternalViewEmbedder()) &#123; const auto platform_id = task_runners_.GetPlatformTaskRunner()-&gt;GetTaskQueueId(); const auto gpu_id = task_runners_.GetRasterTaskRunner()-&gt;GetTaskQueueId(); raster_thread_merger_ = fml::MakeRefCounted&lt;fml::RasterThreadMerger&gt;(platform_id, gpu_id); &#125;&#125; è¿™é‡Œæ˜¯ç›´æŽ¥ä¿®æ”¹äº†å¼•æ“Žçš„ä»£ç ï¼Œæ‰€ä»¥éœ€è¦é‡æ–°ç¼–è¯‘engine äº§ç‰©ï¼Œæ›¿æ¢æŽ‰å°±æžå®šäº† å…¶ä»–1.17ä¹‹å‰çš„ç‰ˆæœ¬ 1.12.13 çš„æ—¶å€™ï¼Œä¸ç¡®å®šengineå­˜ä¸å­˜åœ¨è¿™ä¸ªé—®é¢˜ï¼Œæœ‰ç©ºå†çœ‹çœ‹ã€‚åŽé¢githubæissueã€PRï¼Œçœ‹çœ‹å®˜æ–¹æ€Žä¹ˆçœ‹å¾…è¿™ä¸ªé—®é¢˜ï¼Œä¿®å¤åº”è¯¥è¿˜æœ‰å…¶ä»–åŠžæ³•ã€‚]]></content>
      <categories>
        <category>flutter</category>
      </categories>
      <tags>
        <tag>flutter</tag>
        <tag>dart</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flutter 1.17å‡çº§]]></title>
    <url>%2F2020%2F05%2F21%2Fflutter-1-17%E5%8D%87%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[å‡çº§æœ€è¿‘å®˜æ–¹å‘å¸ƒäº†flutter ç¨³å®šç‰ˆæœ¬1.17.0 ï¼Œè®°å½•ä¸‹å‡çº§1.17 iosä¸Šç¢°åˆ°çš„çš„é—®é¢˜ Appäº§ç‰©åœ¨ 1.12.13 çš„æ—¶å€™ï¼Œä¸ºäº†æ”¯æŒæ¨¡æ‹Ÿå™¨è¿è¡Œï¼Œä¼šè¿›è¡Œ debug äº§ç‰© è·Ÿ release äº§ç‰©çš„merge ï¼ˆlipo create â€¦ï¼‰debug äº§ç‰© x86 ã€release äº§ç‰© arm64 arm7 å‡çº§åˆ°1.17.0 ä¹‹åŽ ï¼ŒmergeæŠ¥é”™ lipo æŸ¥çœ‹ä¸‹ å‘çŽ°é’ˆå¯¹æ¨¡æ‹Ÿå™¨çš„debugäº§ç‰© å«æœ‰arm64 Debug Flutter toolæºç ï¼Œ build é‡Œé¢è¿›è¡Œäº†ä¸¤æ¬¡createStubAppFrameworkï¼ˆiphone &amp;&amp; simulatorï¼‰ç„¶åŽåšäº†mergeï¼Œå®žé™…ä¸Šenvironmentå‚æ•°é‡Œé¢ iosArchsåªæœ‰ arch x86ï¼Œæ‰€ä»¥é—®é¢˜å‡ºåœ¨è¿™é‡Œ DebugUniveralFramework1234567891011121314151617181920212223242526272829303132333435363738394041@overrideFuture&lt;void&gt; build(Environment environment) async &#123; // Generate a trivial App.framework. final Set&lt;DarwinArch&gt; iosArchs = environment.defines[kIosArchs] ?.split(' ') ?.map(getIOSArchForName) ?.toSet() ?? &lt;DarwinArch&gt;&#123;DarwinArch.arm64&#125;; final File iphoneFile = environment.buildDir.childFile('iphone_framework'); final File simulatorFile = environment.buildDir.childFile('simulator_framework'); final File lipoOutputFile = environment.buildDir.childFile('App'); final RunResult iphoneResult = await createStubAppFramework( iphoneFile, SdkType.iPhone, // Only include 32bit if it is contained in the active architectures. include32Bit: iosArchs.contains(DarwinArch.armv7) ); final RunResult simulatorResult = await createStubAppFramework( simulatorFile, SdkType.iPhoneSimulator, ); if (iphoneResult.exitCode != 0 || simulatorResult.exitCode != 0) &#123; throw Exception('Failed to create App.framework.'); &#125; final List&lt;String&gt; lipoCommand = &lt;String&gt;[ 'xcrun', 'lipo', '-create', iphoneFile.path, simulatorFile.path, '-output', lipoOutputFile.path ]; final RunResult lipoResult = await processUtils.run( lipoCommand, ); if (lipoResult.exitCode != 0) &#123; throw Exception('Failed to create App.framework.'); &#125;&#125; è§£å†³åŠžæ³• å¯ä»¥é€šè¿‡archs åˆ¤æ–­ä¸‹å…·ä½“æ‰§è¡Œ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@override Future&lt;void&gt; build(Environment environment) async &#123; // Generate a trivial App.framework. final Set&lt;DarwinArch&gt; iosArchs = environment.defines[kIosArchs] ?.split(' ') ?.map(getIOSArchForName) ?.toSet() ?? &lt;DarwinArch&gt;&#123;DarwinArch.arm64&#125;; final File iphoneFile = environment.buildDir.childFile('iphone_framework'); final File simulatorFile = environment.buildDir.childFile('simulator_framework'); final File lipoOutputFile = environment.buildDir.childFile('App'); RunResult iphoneResult; if(iosArchs.contains(DarwinArch.arm64) || iosArchs.contains(DarwinArch.armv7)) &#123; iphoneResult = await createStubAppFramework( iphoneFile, SdkType.iPhone, // Only include 32bit if it is contained in the active architectures. include32Bit: iosArchs.contains(DarwinArch.armv7) ); if (iphoneResult.exitCode != 0) &#123; throw Exception('(iphoneResult)Failed to create App.framework.'); &#125; &#125; RunResult simulatorResult; if(iosArchs.contains(DarwinArch.x86_64)) &#123; simulatorResult = await createStubAppFramework( simulatorFile, SdkType.iPhoneSimulator, ); if (simulatorResult.exitCode != 0) &#123; throw Exception('(simulatorResult)Failed to create App.framework.'); &#125; &#125; if(simulatorResult == null) &#123; iphoneFile.copySync(lipoOutputFile.path); return; &#125; if(iphoneResult == null) &#123; simulatorFile.copySync(lipoOutputFile.path); return; &#125; final List&lt;String&gt; lipoCommand = &lt;String&gt;[ 'xcrun', 'lipo', '-create', iphoneFile.path, simulatorFile.path, '-output', lipoOutputFile.path ]; final RunResult lipoResult = await processUtils.run( lipoCommand, ); if (lipoResult.exitCode != 0) &#123; throw Exception('Failed to create App.framework.'); &#125; &#125; çªç„¶æƒ³åˆ° æ—¢ç„¶1.17 å¯¹debug äº§ç‰©åšäº†arm64çš„æ”¯æŒï¼Œé‚£æˆ‘ä»¬æ”¶é›†äº§ç‰©æ˜¯ä¸æ˜¯å¯ä»¥ä¸ç”¨è‡ªå·±åšmergeï¼Œå‘çŽ°æ˜¯ä¸å¯ä»¥çš„å› ä¸ºé™¤äº†App.framework,è¿˜æœ‰plugin nativeä»£ç ç”Ÿæˆçš„podé™æ€åº“ libxxx.aã€‚é™æ€åº“ æ˜¯å“ªé‡Œç”Ÿæˆçš„å‘¢ï¼Ÿ è¿™é‡Œ build_ios.dart -&gt; buildXcodeProject 123456789101112131415161718...final List&lt;String&gt; buildCommands = &lt;String&gt;[ &apos;/usr/bin/env&apos;, &apos;xcrun&apos;, &apos;xcodebuild&apos;, &apos;-configuration&apos;, configuration,]; ...if (buildForDevice) &#123; buildCommands.addAll(&lt;String&gt;[&apos;-sdk&apos;, &apos;iphoneos&apos;]);&#125; else &#123; buildCommands.addAll(&lt;String&gt;[&apos;-sdk&apos;, &apos;iphonesimulator&apos;, &apos;-arch&apos;, &apos;x86_64&apos;]);&#125;... è¿™é‡Œåªé’ˆå¯¹x86åšäº†xcode buildï¼Œæ‰€ä»¥è¿˜æ˜¯è¦è‡ªå·±mergeçš„â€¦]]></content>
      <categories>
        <category>flutter</category>
      </categories>
      <tags>
        <tag>flutter</tag>
        <tag>dart</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flutter tool debug]]></title>
    <url>%2F2020%2F03%2F13%2Fflutter-tool-debug%2F</url>
    <content type="text"><![CDATA[Flutterflutter å¼€å‘è¿‡ç¨‹ä¸­ï¼Œå°‘ä¸äº†ä¼šè¿è¡Œä¸€äº› flutter å‘½ä»¤ ï¼Œæ¯”å¦‚ flutter build xxx ã€ flutter run ç­‰ç­‰çœ‹ä¸‹ bin/flutter è„šæœ¬ï¼ŒèƒŒåŽéƒ½æ˜¯ flutter_tool åœ¨æ‰§è¡Œå„ç§æ“ä½œã€‚ 12345678FLUTTER_TOOLS_DIR="$FLUTTER_ROOT/packages/flutter_tools"SNAPSHOT_PATH="$FLUTTER_ROOT/bin/cache/flutter_tools.snapshot"STAMP_PATH="$FLUTTER_ROOT/bin/cache/flutter_tools.stamp"SCRIPT_PATH="$FLUTTER_TOOLS_DIR/bin/flutter_tools.dart"DART_SDK_PATH="$FLUTTER_ROOT/bin/cache/dart-sdk""$DART" --packages="$FLUTTER_TOOLS_DIR/.packages" $FLUTTER_TOOL_ARGS "$SNAPSHOT_PATH" "$@" å…³äºŽ debug flutter_tool,å°±ä¸è¯´çš„äº†ï¼Œè‡ªè¡Œgoogleä¸€ä¸‹ã€‚ã€‚ è¿™é‡Œè®°å½•ä¸‹ debug è¿‡ç¨‹ä¸­é‡åˆ°çš„é—®é¢˜ ExceptionæŒ‡å®šç«¯å£å¯¼å‡ºFLUTTER_TOOL_ARGS çŽ¯å¢ƒå˜é‡ export FLUTTER_TOOL_ARGS=&quot;--pause_isolates_on_start --enable-vm-service:65432&quot; run èµ·æ¥ ä¼šåœåœ¨è¿™é‡Œâ€¦ Observatory listening on http://127.0.0.1:65432/ZbWg3veM6kY=/ IDE ä¸­æ‰“å¼€flutter tool é¡¹ç›®ï¼Œé…ç½® dart remote debug attach å‡ºçŽ°ä»¥ä¸‹é”™è¯¯ä¿¡æ¯ 123Failed to connect to the VM observatory service: java.io.IOException: Failed to connect: ws://127.0.0.1:65432/wsCaused by: de.roderick.weberknecht.WebSocketException: error while creating socket to ws://127.0.0.1:65432/wsCaused by: java.net.ConnectException: Connection refused (Connection refused) åŽŸå›  ï¼š http://127.0.0.1:65432/ZbWg3veM6kY=/ åŽé¢å¤šäº†ä¸ªZbWg3veM6kYï¼Œè¿™æ˜¯ä¸€ç§è®¤è¯ç ï¼Œæ˜¯ä¸ºäº†å®‰å…¨åŽŸå› ï¼Œé˜²æ­¢åº”ç”¨è¢«è¿œç¨‹è°ƒè¯•ã€‚å¯ä»¥é€šè¿‡å‚æ•°â€“disable-service-auth-codesè¿›è¡Œå…³é—­ã€‚ export FLUTTER_TOOL_ARGS=&quot;--pause_isolates_on_start --enable-vm-service:65432 --disable-service-auth-codes&quot;]]></content>
      <categories>
        <category>flutter</category>
      </categories>
      <tags>
        <tag>flutter</tag>
        <tag>dart</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flutterå…±äº«engine]]></title>
    <url>%2F2020%2F03%2F10%2Fflutter%E5%85%B1%E4%BA%ABengine%2F</url>
    <content type="text"><![CDATA[flutter å…±äº«å¼•æ“Ž é—®é¢˜è®°å½•å…±äº«å¼•æ“Žï¼Œå°±æ˜¯åªæœ‰ä¸€ä¸ª flutter engineï¼Œæ¯ä¸ªé¡µé¢ä¸€ä¸ª flutterviewcontrollerã€‚flutteré¡µé¢ åˆ‡æ¢ï¼Œå¼•æ“Žä¼šç›¸åº”çš„ detach atach æœ€è¿‘ å‡çº§ flutter åˆ° v1.12.13 ç‰ˆæœ¬åŽï¼Œè´¡çŒ®å¼•æ“Žé‡åˆ°çš„å‡ ä¸ªé—®é¢˜ è®°å½•ä¸‹ present flutter é¡µé¢è¿™ä¸ªå…¶å®žä¸æ˜¯v1.12.13å‡ºçŽ°çš„é—®é¢˜ flutterPageA present flutterPageB ä¼š å‡ºçŽ° pageAçš„ viewDidDisappear æ¯” pageBçš„ viewDidAppear åŽæ‰§è¡Œ 12345678910- (void)viewDidDisappear:(BOOL)animated &#123; [super viewDidDisappear:animated]; //å¤„ç†ä¸‹present é¡µé¢å¡æ­»çš„æƒ…å†µ if ([WD_FLUTTER_ENGINE flutterViewController] != self) &#123; [WD_FLUTTER_ENGINE resume]; [(WDFlutterViewContainer *)[WD_FLUTTER_ENGINE flutterViewController] surfaceUpdated:YES]; &#125; else &#123; [WD_FLUTTER_ENGINE detach]; &#125;&#125; ä»Žflutter è¿”å›žåˆ° nativeé¡µé¢åœ¨ v.1.12.13ä¹‹å‰ flutter popto native æ— éœ€å¤„ç†v.1.12.13 å‡ºçŽ°crash 123456789101112131415161718192021222324[VERBOSE-2:FlutterObservatoryPublisher.mm(131)] Could not register as server for FlutterObservatoryPublisher. Check your network settings and relaunch the application.SCNetworkReachabilitySetDispatchQueue() failed: Invalid argumentSCNetworkReachabilitySetDispatchQueue() failed: Invalid argumentlocalConnectionInitializedStatus:2localConnectionInitializedStatus:2SCNetworkReachabilitySetDispatchQueue() failed: Invalid argument[Bugly] Fatal signal(11) raised.[Bugly] Trapped fatal signal &apos;SIGSEGV(11)&apos; ( &quot;0 Flutter 0x000000010516f92c _ZNK3fml8internal14CopyableLambdaIZN7flutter5Shell21OnPlatformViewCreatedENSt3__110unique_ptrINS2_7SurfaceENS4_14default_deleteIS6_EEEEE3$_8EclIJEEEDaDpOT_ + 236&quot;, &quot;1 Flutter 0x000000010516f928 _ZNK3fml8internal14CopyableLambdaIZN7flutter5Shell21OnPlatformViewCreatedENSt3__110unique_ptrINS2_7SurfaceENS4_14default_deleteIS6_EEEEE3$_8EclIJEEEDaDpOT_ + 232&quot;, &quot;2 Flutter 0x0000000105123cf4 _ZN3fml15MessageLoopImpl10FlushTasksENS_9FlushTypeE + 1700&quot;, &quot;3 Flutter 0x0000000105126000 _ZN3fml17MessageLoopDarwin11OnTimerFireEP16__CFRunLoopTimerPS0_ + 32&quot;, &quot;4 CoreFoundation 0x0000000184cd3aa8 0x0000000184be5000 + 977576&quot;, &quot;5 CoreFoundation 0x0000000184cd376c 0x0000000184be5000 + 976748&quot;, &quot;6 CoreFoundation 0x0000000184cd3010 0x0000000184be5000 + 974864&quot;, &quot;7 CoreFoundation 0x0000000184cd0b60 0x0000000184be5000 + 965472&quot;, &quot;8 CoreFoundation 0x0000000184bf0da8 CFRunLoopRunSpecific + 552&quot;, &quot;9 Flutter 0x0000000105125edc _ZN3fml17MessageLoopDarwin3RunEv + 88&quot;, &quot;10 Flutter 0x0000000105125684 _ZNSt3__114__thread_proxyINS_5tupleIJNS_10unique_ptrINS_15__thread_structENS_14default_deleteIS3_EEEEZN3fml6ThreadC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE3$_0EEEEEPvSJ_ + 200&quot;, &quot;11 libsystem_pthread.dylib 0x0000000184951220 0x000000018494f000 + 8736&quot;, &quot;12 libsystem_pthread.dylib 0x0000000184951110 0x000000018494f000 + 8464&quot;)Application finished. å¤„ç†åŠžæ³•ï¼š flutterVc dealloc æˆ–è€… disappear çš„æ—¶å€™ æ‰§è¡Œ flutterEngine detach]]></content>
      <categories>
        <category>flutter</category>
      </categories>
      <tags>
        <tag>flutter</tag>
        <tag>dart</tag>
        <tag>ios</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flutter engine å®šåˆ¶]]></title>
    <url>%2F2020%2F03%2F05%2Fflutter-engine-%E5%AE%9A%E5%88%B6%2F</url>
    <content type="text"><![CDATA[â€¦ä½¿ç”¨Flutterå¼€å‘çš„æ—¶å€™æœ€ç›´æŽ¥æŽ¥è§¦çš„å¹¶ä¸æ˜¯ Flutter Engine è€Œæ˜¯ Flutter Framework(https://github.com/flutter/flutter)åœ¨flutter framework çš„ ç›®å½•é‡Œé¢ æœ‰ç¼–è¯‘å¥½çš„engine äº§ç‰© ç®€å•è¯´å°±æ˜¯ï¼Œ ç¼–è¯‘å¼•æ“Ž æ›¿æ¢ äº§ç‰©æ–‡ä»¶å°±å¥½äº† è·¯å¾„ flutter_path/bin/cache/artifacts/engine/ios å‚è€ƒFlutter Engineå®šåˆ¶æµç¨‹Flutter Engine ç¼–è¯‘æŒ‡åŒ—]]></content>
      <categories>
        <category>flutter</category>
      </categories>
      <tags>
        <tag>flutter</tag>
        <tag>dart</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flutter eventChannel crash on ios]]></title>
    <url>%2F2019%2F10%2F21%2Fflutter-eventChannel-crash-on-ios%2F</url>
    <content type="text"><![CDATA[flutter issuecrash è®°å½•ä¸€æ¬¡å›°æ‰°äº†å¾ˆä¹…çš„ flutter event channel crash EventChannel dart1234567891011121314151617181920212223242526272829303132333435363738394041Stream&lt;dynamic&gt; receiveBroadcastStream([ dynamic arguments ]) &#123; final MethodChannel methodChannel = MethodChannel(name, codec); StreamController&lt;dynamic&gt; controller; controller = StreamController&lt;dynamic&gt;.broadcast(onListen: () async &#123; defaultBinaryMessenger.setMessageHandler(name, (ByteData reply) async &#123; if (reply == null) &#123; controller.close(); &#125; else &#123; try &#123; controller.add(codec.decodeEnvelope(reply)); &#125; on PlatformException catch (e) &#123; controller.addError(e); &#125; &#125; return null; &#125;); try &#123; await methodChannel.invokeMethod&lt;void&gt;('listen', arguments); &#125; catch (exception, stack) &#123; FlutterError.reportError(FlutterErrorDetails( exception: exception, stack: stack, library: 'services library', context: ErrorDescription('while activating platform stream on channel $name'), )); &#125; &#125;, onCancel: () async &#123; defaultBinaryMessenger.setMessageHandler(name, null); try &#123; await methodChannel.invokeMethod&lt;void&gt;('cancel', arguments); &#125; catch (exception, stack) &#123; FlutterError.reportError(FlutterErrorDetails( exception: exception, stack: stack, library: 'services library', context: ErrorDescription('while de-activating platform stream on channel $name'), )); &#125; &#125;); return controller.stream; &#125; FlutterChannel.mm1234567891011121314151617181920212223242526272829303132333435363738394041424344454647static void SetStreamHandlerMessageHandlerOnChannel(NSObject&lt;FlutterStreamHandler&gt;* handler, NSString* name, NSObject&lt;FlutterBinaryMessenger&gt;* messenger, NSObject&lt;FlutterMethodCodec&gt;* codec) &#123; __block FlutterEventSink currentSink = nil; FlutterBinaryMessageHandler messageHandler = ^(NSData* message, FlutterBinaryReply callback) &#123; FlutterMethodCall* call = [codec decodeMethodCall:message]; if ([call.method isEqual:@"listen"]) &#123; if (currentSink) &#123; FlutterError* error = [handler onCancelWithArguments:nil]; if (error) NSLog(@"Failed to cancel existing stream: %@. %@ (%@)", error.code, error.message, error.details); &#125; currentSink = ^(id event) &#123; if (event == FlutterEndOfEventStream) [messenger sendOnChannel:name message:nil]; else if ([event isKindOfClass:[FlutterError class]]) [messenger sendOnChannel:name message:[codec encodeErrorEnvelope:(FlutterError*)event]]; else [messenger sendOnChannel:name message:[codec encodeSuccessEnvelope:event]]; &#125;; FlutterError* error = [handler onListenWithArguments:call.arguments eventSink:currentSink]; if (error) callback([codec encodeErrorEnvelope:error]); else callback([codec encodeSuccessEnvelope:nil]); &#125; else if ([call.method isEqual:@"cancel"]) &#123; if (!currentSink) &#123; callback( [codec encodeErrorEnvelope:[FlutterError errorWithCode:@"error" message:@"No active stream to cancel" details:nil]]); return; &#125; currentSink = nil; FlutterError* error = [handler onCancelWithArguments:call.arguments]; if (error) callback([codec encodeErrorEnvelope:error]); else callback([codec encodeSuccessEnvelope:nil]); &#125; else &#123; callback(nil); &#125; &#125;; [messenger setMessageHandlerOnChannel:name binaryMessageHandler:messageHandler];&#125; EventSinkæ­£å¸¸ç»“æŸstreamæµ eventSink(FlutterEndOfEventStream) ï¼Œå¼‚å¸¸ç»“æŸstreamæµ eventSink(FlutterError) éƒ½ä¼šå›žè°ƒæ‰§è¡Œ onCancel å‚è€ƒFlutter ä¸Ž Native(iOS) é€šä¿¡åŽŸç†æ·±å…¥FlutteræŠ€æœ¯å†…å¹•:Platform Channelè®¾è®¡ä¸Žå®žçŽ°]]></content>
      <categories>
        <category>flutter</category>
      </categories>
      <tags>
        <tag>flutter</tag>
        <tag>dart</tag>
        <tag>ios</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flutter ios 13 dark mode]]></title>
    <url>%2F2019%2F10%2F14%2Fflutter-ios-13-dark-mode%2F</url>
    <content type="text"><![CDATA[å‰è¨€ios 13 å¼€å¯ dark model,flutteré¡µé¢status baræ–‡å­—ä¸€ç›´æ˜¯ç™½è‰² flutter issues 1SystemChrome.setSystemUIOverlayStyle(SystemUiOverlayStyle.dark); è®¾ç½®dark style å¹¶æ²¡æœ‰ç”¨ SystemChrome12345678910111213141516171819202122232425static void setSystemUIOverlayStyle(SystemUiOverlayStyle style) &#123; assert(style != null); if (_pendingStyle != null) &#123; // The microtask has already been queued; just update the pending value. _pendingStyle = style; return; &#125; if (style == _latestStyle) &#123; // Trivial success: no microtask has been queued and the given style is // already in effect, so no need to queue a microtask. return; &#125; _pendingStyle = style; scheduleMicrotask(() &#123; assert(_pendingStyle != null); if (_pendingStyle != _latestStyle) &#123; SystemChannels.platform.invokeMethod&lt;void&gt;( 'SystemChrome.setSystemUIOverlayStyle', _pendingStyle._toMap(), ); _latestStyle = _pendingStyle; &#125; _pendingStyle = null; &#125;); &#125; FlutterPlatformPlugin1234567891011121314151617181920212223242526272829- (void)setSystemChromeSystemUIOverlayStyle:(NSDictionary*)message &#123; NSString* style = message[@"statusBarBrightness"]; if (style == (id)[NSNull null]) return; UIStatusBarStyle statusBarStyle; if ([style isEqualToString:@"Brightness.dark"]) statusBarStyle = UIStatusBarStyleLightContent; else if ([style isEqualToString:@"Brightness.light"]) statusBarStyle = UIStatusBarStyleDefault; else return; NSNumber* infoValue = [[NSBundle mainBundle] objectForInfoDictionaryKey:@"UIViewControllerBasedStatusBarAppearance"]; Boolean delegateToViewController = (infoValue == nil || [infoValue boolValue]); if (delegateToViewController) &#123; // This notification is respected by the iOS embedder [[NSNotificationCenter defaultCenter] postNotificationName:@(kOverlayStyleUpdateNotificationName) object:nil userInfo:@&#123;@(kOverlayStyleUpdateNotificationKey) : @(statusBarStyle)&#125;]; &#125; else &#123; // Note: -[UIApplication setStatusBarStyle] is deprecated in iOS9 // in favor of delegating to the view controller [[UIApplication sharedApplication] setStatusBarStyle:statusBarStyle]; &#125;&#125; engine æºç ä¸­ å¯ä»¥çœ‹åˆ° æ²¡æœ‰ UIStatusBarStyleDarkContent å°è¯• åŽ»æŽ‰ info.plist ä¸­çš„ UIViewControllerBasedStatusBarAppearance ç„¶åŽ ç›‘å¬ é€šçŸ¥ 1234567[[NSNotificationCenter defaultCenter] addObserver:self selector:@selector(appStatusBar:) name:@"io.flutter.plugin.platform.SystemChromeOverlayNotificationName" object:nil];- (void)appStatusBar:(id)notification &#123; if (@available(iOS 13.0, *)) &#123; [UIApplication sharedApplication].statusBarStyle = UIStatusBarStyleDarkContent; &#125;&#125;]]></content>
      <categories>
        <category>flutter</category>
      </categories>
      <tags>
        <tag>flutter</tag>
        <tag>dart</tag>
        <tag>ios</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mustacheä¹‹dart]]></title>
    <url>%2F2019%2F05%2F31%2Fmustache%E4%B9%8Bdart%2F</url>
    <content type="text"><![CDATA[å‰è¨€Mustache æ˜¯ä¸€ä¸ª logic-less ï¼ˆè½»é€»è¾‘ï¼‰æ¨¡æ¿è§£æžå¼•æ“Žï¼Œå¯ä»¥åº”ç”¨åœ¨ jsã€PHPã€Pythonã€Perl ç­‰å¤šç§ç¼–ç¨‹è¯­è¨€ä¸­ã€‚è¿™é‡Œä¸»è¦æ˜¯çœ‹dartä¸­çš„åº”ç”¨ã€‚ æ¨¡æ¿è¯­æ³•å¾ˆç®€å• çœ‹è¿™é‡Œ1234567&#123;&#123;keyName&#125;&#125; &#123;&#123;#keyName&#125;&#125; &#123;&#123;/keyName&#125;&#125;&#123;&#123;^keyName&#125;&#125; &#123;&#123;/keyName&#125;&#125;&#123;&#123;.&#125;&#125;&#123;&#123;&gt;partials&#125;&#125;&#123;&#123;&#123;keyName&#125;&#125;&#125;&#123;&#123;!comments&#125;&#125; ä½¿ç”¨åœ¨flutteré¡¹ç›®ä¸­ï¼Œä½¿ç”¨annation routeræ³¨è§£çš„æ–¹å¼ç”Ÿæˆè·¯ç”±è¡¨ç®¡ç†ç±» RouterManager ï¼Œä»¥åŠä¸šåŠ¡ç›¸å…³çš„ç±»æ–‡ä»¶ï¼ˆios androidï¼‰åœ¨ä½¿ç”¨mustacheä¹‹å‰ï¼Œæ˜¯é€šè¿‡stringbuff çš„æ–¹å¼æ‹¼æŽ¥å­—ç¬¦ä¸²ï¼Œä¹Ÿå¯ä»¥å®Œæˆï¼Œä½†æ˜¯é˜…è¯»æ€§æ¯”è¾ƒå·®ã€‚ ä¹‹å‰123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/// ç”Ÿæˆè·¯ç”±è¡¨ç±» StringBuffer sb = new StringBuffer(); sb..write(_createImport())..write(_createClazz(element.name)); return sb.toString();/// ç”Ÿæˆè·¯ç”±è¡¨ç±»çš„ import ä¿¡æ¯ String _createImport() &#123; StringBuffer sb = new StringBuffer(); sb ..writeln("import 'package:flutter/material.dart';") ..writeln("import 'package:hybrid_router/hybrid_router.dart';"); /// import page collector.importClazzList.forEach((clazz) &#123; sb.writeln("import '$clazz';"); &#125;); return sb.toString(); &#125; /// ç”Ÿæˆè·¯ç”±è¡¨ç±»çš„ clazz ä¿¡æ¯ String _createClazz(String className) &#123; StringBuffer sb = new StringBuffer(); /// start class sb.writeln("class \$$className &#123;"); /// generateRoute function sb ..writeln(" Map&lt;String, HybridWidgetBuilder&gt; generateRoutes()&#123;") ..writeln(" return &#123;"); collector.routeMap.forEach((key, value) &#123; String flutterPath = value.flutterPath; sb ..writeln(" '$flutterPath': (BuildContext context, Object args) &#123;") ..writeln(" $&#123;_createInstance(value)&#125;") ..writeln(" &#125;,"); &#125;); sb..writeln(" &#125;;")..writeln(" &#125;"); /// generateSpm function sb ..writeln(" Map&lt;String, String&gt; generateSpm() &#123;") ..writeln(" return &#123;"); collector.routeMap.forEach((key, value) &#123; String flutterSpm = value.flutterSpm; String flutterPath = value.flutterPath; if (flutterSpm?.isNotEmpty == true) &#123; sb.writeln(" '$flutterPath': '$flutterSpm',"); &#125; &#125;); sb..writeln(" &#125;;")..writeln(" &#125;"); /// end class sb.writeln("&#125;"); return sb.toString(); &#125; ä¹‹åŽ1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/// ç”Ÿæˆè·¯ç”±è¡¨ç±» _createRouteManager(element.name); String _createRouteManager(String className) &#123; return VDTemplate.routerManagerTemplate().renderString(&#123; 'classname':className, 'classes':collector.importClazzList, 'routes':collector.routeMap.values, 'createInstance':(LambdaContext ctx) &#123; CollectorItem item = ctx.lookup('.'); return _createInstance(item); &#125; &#125;); &#125; static Template routerManagerTemplate() &#123; var source = '''&#123;&#123;&gt; import&#125;&#125;&#123;&#123;&gt; clazz&#125;&#125; '''; Map&lt;String,Template&gt; map = &#123; "import":VDTemplate.importTemplate(), "clazz":VDTemplate.claszzTemplate() &#125;; return new Template(source,partialResolver: (String name) =&gt; map[name]); &#125; static Template importTemplate() &#123; var source = '''import 'package:flutter/material.dart';import 'package:hybrid_router/hybrid_router.dart';&#123;&#123;# classes &#125;&#125;import '&#123;&#123;&#123;.&#125;&#125;&#125;';&#123;&#123;/ classes &#125;&#125; '''; return new Template(source); &#125; static Template claszzTemplate() &#123; var source = '''class \$&#123;&#123;classname&#125;&#125; &#123; Map&lt;String, HybridWidgetBuilder&gt; generateRoutes()&#123; return &#123; &#123;&#123;#routes&#125;&#125; '&#123;&#123;flutterPath&#125;&#125;': (BuildContext context, Object args) &#123; &#123;&#123;createInstance&#125;&#125; &#125;, &#123;&#123;/routes&#125;&#125; &#125;; &#125; Map&lt;String, String&gt; generateSpm() &#123; return &#123; &#123;&#123;#routes&#125;&#125; &#123;&#123;# flutterSpm&#125;&#125; '&#123;&#123;flutterPath&#125;&#125;': '&#123;&#123;flutterSpm&#125;&#125;', &#123;&#123;/ flutterSpm&#125;&#125; &#123;&#123;/routes&#125;&#125; &#125;; &#125; &#125; '''; return new Template(source); &#125; å¯¹æ¯”çœ‹ä¸‹ï¼Œä½¿ç”¨mustacheä¹‹åŽï¼Œå¯è¯»æ€§å¥½å¾ˆå¤šï¼ŒåŸºæœ¬ä¿æŒäº†ä»£ç ç»“æž„ æ€»ç»“ å­—ç¬¦ä¸²æ•°ç»„ï¼Œå¯ä»¥ä½¿ç”¨{{.}} å¯¹è±¡æ•°æ®ï¼Œå¯ä»¥è·Ÿæ™®é€šçš„hashä¸€æ ·ï¼Œç›´æŽ¥ç”¨{{å¯¹è±¡çš„å±žæ€§}}ï¼Œmustacheå†…éƒ¨é€šè¿‡dartåå°„æ‹¿åˆ°å±žæ€§å€¼ ä½¿ç”¨partials æ‹†åˆ†template å¢žåŠ å¯è¯»æ€§ é€šè¿‡lambdaå‡½æ•°æ‰§è¡Œdartæ–¹æ³•ï¼Œä¹Ÿå¯ä»¥åšåˆ°æ‹†åˆ†çš„ä½œç”¨ lambdaContext.loopup(&quot;.&quot;) å¯ä»¥èŽ·å–å¯¹è±¡å®žä¾‹ï¼Œè¿›è€Œå¯ä»¥å‚æ•°ä¼ é€’ mustacheå†…éƒ¨renderstringä¹Ÿæ˜¯é€šè¿‡stringbuffçš„æ–¹å¼å®žçŽ° å‚è€ƒé“¾æŽ¥mustache 1.1.1Flutterè·¯ç”±ç®¡ç†]]></content>
      <categories>
        <category>flutter</category>
      </categories>
      <tags>
        <tag>flutter</tag>
        <tag>dart</tag>
        <tag>mustache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvmè°ƒä¼˜]]></title>
    <url>%2F2019%2F05%2F23%2Fjvm%E8%B0%83%E4%BC%98%2F</url>
    <content type="text"><![CDATA[jpsè¾“å‡ºJVMä¸­è¿è¡Œçš„è¿›ç¨‹çŠ¶æ€ä¿¡æ¯ 1234-q ä¸è¾“å‡ºç±»åã€Jaråå’Œä¼ å…¥mainæ–¹æ³•çš„å‚æ•°-m è¾“å‡ºä¼ å…¥mainæ–¹æ³•çš„å‚æ•°-l è¾“å‡ºmainç±»æˆ–Jarçš„å…¨é™å-v è¾“å‡ºä¼ å…¥JVMçš„å‚æ•° jps -mlvæ‰¾åˆ°javaåº”ç”¨çš„pid jstackæ ¹æ®javaåº”ç”¨pid ,æŸ¥çœ‹è¿›ç¨‹ä¸­çº¿ç¨‹å †æ ˆä¿¡æ¯ jstack pid topæ‰¾å‡ºè¯¥è¿›ç¨‹å†…æœ€è€—è´¹CPUçš„çº¿ç¨‹ top -Hp pid è½¬ä¸ºåå…­è¿›åˆ¶printf &quot;%x\n&quot; çº¿ç¨‹id è¾“å‡ºè¿›ç¨‹çš„å †æ ˆä¿¡æ¯ï¼Œç„¶åŽæ ¹æ®çº¿ç¨‹IDçš„åå…­è¿›åˆ¶å€¼grepjstack pid | grep åå…­è¿›åˆ¶çº¿ç¨‹id jmapæŸ¥çœ‹å †å†…å­˜ä½¿ç”¨çŠ¶å†µjmap -heap pid è¿›ç¨‹å†…å­˜ä½¿ç”¨æƒ…å†µdumpåˆ°æ–‡ä»¶ä¸­ ç»“åˆMATå·¥å…·åˆ†æžjmap -dump:format=b,file=dumpFileName pid jhatjhat -port 9998 /tmp/dump.datlocalhost:9998 æŸ¥çœ‹å†…å­˜å¯¹è±¡æƒ…å†µ ï¼ˆä¸å¦‚MATç›´è§‚ï¼‰]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vmstatu]]></title>
    <url>%2F2019%2F05%2F22%2Fvmstatus%2F</url>
    <content type="text"><![CDATA[vmstatuvmstatå‘½ä»¤æ˜¯æœ€å¸¸è§çš„Linux/Unixç›‘æŽ§å·¥å…·ï¼Œå¯ä»¥å±•çŽ°ç»™å®šæ—¶é—´é—´éš”çš„æœåŠ¡å™¨çš„çŠ¶æ€å€¼,åŒ…æ‹¬æœåŠ¡å™¨çš„CPUä½¿ç”¨çŽ‡ï¼Œå†…å­˜ä½¿ç”¨ï¼Œè™šæ‹Ÿå†…å­˜äº¤æ¢æƒ…å†µ,IOè¯»å†™æƒ…å†µã€‚ç›¸æ¯”topï¼Œå¯ä»¥çœ‹åˆ°æ•´ä¸ªæœºå™¨çš„CPU,å†…å­˜,IOçš„ä½¿ç”¨æƒ…å†µï¼Œè€Œä¸æ˜¯å•å•çœ‹åˆ°å„ä¸ªè¿›ç¨‹çš„CPUä½¿ç”¨çŽ‡å’Œå†…å­˜ä½¿ç”¨çŽ‡(ä½¿ç”¨åœºæ™¯ä¸ä¸€æ ·)ã€‚ 1234$vmstatprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 215220 0 771404 0 0 2 15 0 1 0 0 100 0 0 ä¸€èˆ¬vmstatå·¥å…·çš„ä½¿ç”¨æ˜¯é€šè¿‡ä¸¤ä¸ªæ•°å­—å‚æ•°æ¥å®Œæˆçš„ï¼Œç¬¬ä¸€ä¸ªå‚æ•°æ˜¯é‡‡æ ·çš„æ—¶é—´é—´éš”æ•°ï¼Œå•ä½æ˜¯ç§’ï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯é‡‡æ ·çš„æ¬¡æ•° 12345$vmstat 2 2procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 202924 0 785780 0 0 2 15 0 1 0 0 100 0 0 0 0 0 203032 0 785812 0 0 0 155 748 1382 0 0 100 0 0 ç¬¬äºŒä¸ªå‚æ•°å¦‚æžœæ²¡æœ‰ï¼Œå°±ä¼šä¸€ç›´é‡‡é›†ï¼ˆctrl+c ç»“æŸï¼‰ 12345678$vmstat 2procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 194712 0 794728 0 0 2 15 0 1 0 0 100 0 0 0 0 0 194696 0 794768 0 0 0 50 782 1368 0 0 100 0 0 0 0 0 193828 0 794776 0 0 0 108 752 1156 0 0 100 0 0 0 0 0 193952 0 794804 0 0 0 4 601 997 0 0 100 0 0^C å­—æ®µprocs r ç­‰å¾…è¿è¡Œçš„è¿›ç¨‹æ•° b å¤„åœ¨éžä¸­æ–­ç¡çœ çŠ¶æ€çš„è¿›ç¨‹æ•° memory ï¼ˆKBï¼‰ swpd è™šæ‹Ÿå†…å­˜ä½¿ç”¨å¤§å° æ³¨æ„ï¼šå¦‚æžœswpdçš„å€¼ä¸ä¸º0ï¼Œä½†æ˜¯SIï¼ŒSOçš„å€¼é•¿æœŸä¸º0ï¼Œè¿™ç§æƒ…å†µä¸ä¼šå½±å“ç³»ç»Ÿæ€§èƒ½ã€‚ free ç©ºé—²çš„å†…å­˜ buff ç”¨ä½œç¼“å†²çš„å†…å­˜å¤§å° cache ç”¨ä½œç¼“å­˜çš„å†…å­˜å¤§å° æ³¨æ„ï¼šå¦‚æžœcacheçš„å€¼å¤§çš„æ—¶å€™ï¼Œè¯´æ˜Žcacheå¤„çš„æ–‡ä»¶æ•°å¤šï¼Œå¦‚æžœé¢‘ç¹è®¿é—®åˆ°çš„æ–‡ä»¶éƒ½èƒ½è¢«cacheå¤„ï¼Œé‚£ä¹ˆç£ç›˜çš„è¯»IO biä¼šéžå¸¸å°ã€‚ swap si ä»Žäº¤æ¢åŒºå†™åˆ°å†…å­˜çš„å¤§å° so æ¯ç§’å†™å…¥äº¤æ¢åŒºçš„å†…å­˜å¤§å° å†…å­˜å¤Ÿç”¨çš„æ—¶å€™ï¼Œè¿™2ä¸ªå€¼éƒ½æ˜¯0ï¼Œå¦‚æžœè¿™2ä¸ªå€¼é•¿æœŸå¤§äºŽ0æ—¶ï¼Œç³»ç»Ÿæ€§èƒ½ä¼šå—åˆ°å½±å“ï¼Œç£ç›˜IOå’ŒCPUèµ„æºéƒ½ä¼šè¢«æ¶ˆè€—ã€‚æœ‰äº›æœ‹å‹çœ‹åˆ°ç©ºé—²å†…å­˜ï¼ˆfreeï¼‰å¾ˆå°‘çš„æˆ–æŽ¥è¿‘äºŽ0æ—¶ï¼Œå°±è®¤ä¸ºå†…å­˜ä¸å¤Ÿç”¨äº†ï¼Œä¸èƒ½å…‰çœ‹è¿™ä¸€ç‚¹ï¼Œè¿˜è¦ç»“åˆsiå’Œsoï¼Œå¦‚æžœfreeå¾ˆå°‘ï¼Œä½†æ˜¯siå’Œsoä¹Ÿå¾ˆå°‘ï¼ˆå¤§å¤šæ—¶å€™æ˜¯0ï¼‰ï¼Œé‚£ä¹ˆä¸ç”¨æ‹…å¿ƒï¼Œç³»ç»Ÿæ€§èƒ½è¿™æ—¶ä¸ä¼šå—åˆ°å½±å“çš„ã€‚ io bi æ¯ç§’è¯»å–çš„å—æ•° bo æ¯ç§’å†™å…¥çš„å—æ•° æ³¨æ„ï¼šéšæœºç£ç›˜è¯»å†™çš„æ—¶å€™ï¼Œè¿™2ä¸ªå€¼è¶Šå¤§ï¼ˆå¦‚è¶…å‡º1024k)ï¼Œèƒ½çœ‹åˆ°CPUåœ¨IOç­‰å¾…çš„å€¼ä¹Ÿä¼šè¶Šå¤§ã€‚ system in æ¯ç§’ä¸­æ–­æ•°ï¼ŒåŒ…æ‹¬æ—¶é’Ÿä¸­æ–­ã€‚ cs æ¯ç§’ä¸Šä¸‹æ–‡åˆ‡æ¢æ•°ã€‚ æ³¨æ„ï¼šä¸Šé¢2ä¸ªå€¼è¶Šå¤§ï¼Œä¼šçœ‹åˆ°ç”±å†…æ ¸æ¶ˆè€—çš„CPUæ—¶é—´ä¼šè¶Šå¤§ã€‚ cpu us ç”¨æˆ·è¿›ç¨‹æ‰§è¡Œæ—¶é—´(user time) æ³¨æ„ï¼š usçš„å€¼æ¯”è¾ƒé«˜æ—¶ï¼Œè¯´æ˜Žç”¨æˆ·è¿›ç¨‹æ¶ˆè€—çš„CPUæ—¶é—´å¤šï¼Œä½†æ˜¯å¦‚æžœé•¿æœŸè¶…50%çš„ä½¿ç”¨ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±è¯¥è€ƒè™‘ä¼˜åŒ–ç¨‹åºç®—æ³•æˆ–è€…è¿›è¡ŒåŠ é€Ÿã€‚ sy ç³»ç»Ÿè¿›ç¨‹æ‰§è¡Œæ—¶é—´(system time) æ³¨æ„ï¼šsyçš„å€¼é«˜æ—¶ï¼Œè¯´æ˜Žç³»ç»Ÿå†…æ ¸æ¶ˆè€—çš„CPUèµ„æºå¤šï¼Œè¿™å¹¶ä¸æ˜¯è‰¯æ€§è¡¨çŽ°ï¼Œæˆ‘ä»¬åº”è¯¥æ£€æŸ¥åŽŸå› ã€‚ id ç©ºé—²æ—¶é—´(åŒ…æ‹¬IOç­‰å¾…æ—¶é—´),ä¸­å¤®å¤„ç†å™¨çš„ç©ºé—²æ—¶é—´ ã€‚ä»¥ç™¾åˆ†æ¯”è¡¨ç¤ºã€‚ wa ç­‰å¾…IOæ—¶é—´ç™¾åˆ†æ¯” æ³¨æ„ï¼šwaçš„å€¼é«˜æ—¶ï¼Œè¯´æ˜ŽIOç­‰å¾…æ¯”è¾ƒä¸¥é‡ï¼Œè¿™å¯èƒ½ç”±äºŽç£ç›˜å¤§é‡ä½œéšæœºè®¿é—®é€ æˆï¼Œä¹Ÿæœ‰å¯èƒ½ç£ç›˜å‡ºçŽ°ç“¶é¢ˆï¼ˆå—æ“ä½œï¼‰ã€‚ 1234567891011121314151617181920212223242526Procsr: The number of processes waiting for run time.b: The number of processes in uninterruptible sleep.Memoryswpd: the amount of virtual memory used.free: the amount of idle memory.buff: the amount of memory used as buffers.cache: the amount of memory used as cache.inact: the amount of inactive memory. (-a option)active: the amount of active memory. (-a option)Swapsi: Amount of memory swapped in from disk (/s).so: Amount of memory swapped to disk (/s).IObi: Blocks received from a block device (blocks/s).bo: Blocks sent to a block device (blocks/s).Systemin: The number of interrupts per second, including the clock.cs: The number of context switches per second.CPUThese are percentages of total CPU time.us: Time spent running non-kernel code. (user time, including nice time)sy: Time spent running kernel code. (system time)id: Time spent idle. Prior to Linux 2.5.41, this includes IO-wait time.wa: Time spent waiting for IO. Prior to Linux 2.5.41, included in idle.st: Time stolen from a virtual machine. Prior to Linux 2.6.11, unknown.]]></content>
      <tags>
        <tag>java</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flutter plugin registry]]></title>
    <url>%2F2019%2F05%2F17%2Fflutter-plugin-registry%2F</url>
    <content type="text"><![CDATA[å‰è¨€é¦–å…ˆè¿™é‡Œæœ‰ä¸‰ä¸ªå½¢ä¼¼å¾—è‹±æ–‡å•è¯registry, registrar and registrantåˆ†åˆ«å¯¹åº”æ³¨å†Œå±€ï¼Œæ³¨å†Œå•†å’Œæ³¨å†Œäººã€‚æŠŠå®ƒä»¬ç¿»è¯‘åˆ°çŽ°å®žçš„ç”Ÿæ´»åœºæ™¯ä¸­çš„è§’è‰²å…¶å®žæ˜¯ä¸€ä¸ªâ€œæ³¨å†Œäººé€šè¿‡æ³¨å†Œå•†ï¼Œæ›´æ–°æ³¨å†Œä¿¡æ¯åŽï¼Œæ³¨å†Œå•†æŠŠä¿¡æ¯ä¼ é€’ç»™æ³¨å†Œå±€è¿›è¡Œä¿å­˜â€çš„è¿‡ç¨‹ã€‚ æ³¨å†Œäººï¼šGeneratedPluginRegistrantæ³¨å†Œå±€ï¼š[(FlutterViewController*)rootViewController pluginRegistry] == flutterEngineæ³¨å†Œå•†ï¼šFlutterEngineRegistrar Flutter Applicationflutter create -t plugin my_plugin xcode æ‰“å¼€ my_plugin/example/iosè·¯å¾„ä¸‹çš„ Runnerå·¥ç¨‹ AppDelegate12345678910@implementation AppDelegate- (BOOL)application:(UIApplication *)application didFinishLaunchingWithOptions:(NSDictionary *)launchOptions &#123; [GeneratedPluginRegistrant registerWithRegistry:self]; // Override point for customization after application launch. return [super application:application didFinishLaunchingWithOptions:launchOptions];&#125;@end GeneratedPluginRegistrant1234567@implementation GeneratedPluginRegistrant+ (void)registerWithRegistry:(NSObject&lt;FlutterPluginRegistry&gt;*)registry &#123; [MyPlugin registerWithRegistrar:[registry registrarForPlugin:@"MyPlugin"]];&#125;@end AppDelegateç»§æ‰¿FlutterAppDelegate FlutterAppDelegate123456789#pragma mark - FlutterPluginRegistry methods. All delegating to the rootViewController- (NSObject&lt;FlutterPluginRegistrar&gt;*)registrarForPlugin:(NSString*)pluginKey &#123; UIViewController* rootViewController = _window.rootViewController; if ([rootViewController isKindOfClass:[FlutterViewController class]]) &#123; return [[(FlutterViewController*)rootViewController pluginRegistry] registrarForPlugin:pluginKey]; &#125; return nil;&#125; FlutterViewController123- (id&lt;FlutterPluginRegistry&gt;)pluginRegistry &#123; return _engine;&#125; FlutterEngineRegistrar1234567891011121314151617181920212223@implementation FlutterEngineRegistrar &#123; NSString* _pluginKey; FlutterEngine* _flutterEngine;&#125;- (instancetype)initWithPlugin:(NSString*)pluginKey flutterEngine:(FlutterEngine*)flutterEngine &#123; self = [super init]; NSAssert(self, @"Super init cannot be nil"); _pluginKey = [pluginKey retain]; _flutterEngine = [flutterEngine retain]; return self;&#125;- (void)addMethodCallDelegate:(NSObject&lt;FlutterPlugin&gt;*)delegate channel:(FlutterMethodChannel*)channel &#123; [channel setMethodCallHandler:^(FlutterMethodCall* call, FlutterResult result) &#123; [delegate handleMethodCall:call result:result]; &#125;];&#125;- (NSObject&lt;FlutterBinaryMessenger&gt;*)messenger &#123; return _flutterEngine;&#125; MyPlugin123456789101112131415161718@implementation MyPlugin+ (void)registerWithRegistrar:(NSObject&lt;FlutterPluginRegistrar&gt;*)registrar &#123; FlutterMethodChannel* channel = [FlutterMethodChannel methodChannelWithName:@"my_plugin" binaryMessenger:[registrar messenger]]; MyPlugin* instance = [[MyPlugin alloc] init]; [registrar addMethodCallDelegate:instance channel:channel];&#125;- (void)handleMethodCall:(FlutterMethodCall*)call result:(FlutterResult)result &#123; if ([@"getPlatformVersion" isEqualToString:call.method]) &#123; result([@"iOS " stringByAppendingString:[[UIDevice currentDevice] systemVersion]]); &#125; else &#123; result(FlutterMethodNotImplemented); &#125;&#125;@end FlutterMethodChannel1234567891011121314151617181920212223242526272829- (instancetype)initWithName:(NSString*)name binaryMessenger:(NSObject&lt;FlutterBinaryMessenger&gt;*)messenger codec:(NSObject&lt;FlutterMethodCodec&gt;*)codec &#123; self = [super init]; NSAssert(self, @"Super init cannot be nil"); _name = [name retain]; _messenger = [messenger retain]; //flutterEngine _codec = [codec retain]; return self;&#125;- (void)setMethodCallHandler:(FlutterMethodCallHandler)handler &#123; if (!handler) &#123; [_messenger setMessageHandlerOnChannel:_name binaryMessageHandler:nil]; return; &#125; FlutterBinaryMessageHandler messageHandler = ^(NSData* message, FlutterBinaryReply callback) &#123; FlutterMethodCall* call = [_codec decodeMethodCall:message]; handler(call, ^(id result) &#123; if (result == FlutterMethodNotImplemented) callback(nil); else if ([result isKindOfClass:[FlutterError class]]) callback([_codec encodeErrorEnvelope:(FlutterError*)result]); else callback([_codec encodeSuccessEnvelope:result]); &#125;); &#125;; [_messenger setMessageHandlerOnChannel:_name binaryMessageHandler:messageHandler];&#125; FlutterEngine123456789101112131415#pragma mark - FlutterPluginRegistry- (NSObject&lt;FlutterPluginRegistrar&gt;*)registrarForPlugin:(NSString*)pluginKey &#123; NSAssert(self.pluginPublications[pluginKey] == nil, @"Duplicate plugin key: %@", pluginKey); self.pluginPublications[pluginKey] = [NSNull null]; return [[FlutterEngineRegistrar alloc] initWithPlugin:pluginKey flutterEngine:self];&#125;- (void)setMessageHandlerOnChannel:(NSString*)channel binaryMessageHandler:(FlutterBinaryMessageHandler)handler &#123; NSAssert(channel, @"The channel must not be null"); FML_DCHECK(_shell &amp;&amp; _shell-&gt;IsSetup()); self.iosPlatformView-&gt;GetPlatformMessageRouter().SetMessageHandler(channel.UTF8String, handler);&#125; FlutterBinaryMessage123456789101112131415161718/** * A message reply callback. * * Used for submitting a binary reply back to a Flutter message sender. Also used * in for handling a binary message reply received from Flutter. * * @param reply The reply. */typedef void (^FlutterBinaryReply)(NSData* _Nullable reply);/** * A strategy for handling incoming binary messages from Flutter and to send * asynchronous replies back to Flutter. * * @param message The message. * @param reply A callback for submitting an asynchronous reply to the sender. */typedef void (^FlutterBinaryMessageHandler)(NSData* _Nullable message, FlutterBinaryReply reply);]]></content>
  </entry>
  <entry>
    <title><![CDATA[sublime text 3]]></title>
    <url>%2F2019%2F05%2F14%2Fsublime-text-3%2F</url>
    <content type="text"><![CDATA[sublime text3 install package controlTools -&gt; Install package control æŠ¥é”™ä¿¡æ¯å·¥å…·æ View ç‚¹å‡»show console æˆ–è€…å¿«æ·é”® ctrl+` æ‰“å¼€æŽ§åˆ¶å°çœ‹ä¸‹å¦‚ä¸‹æŠ¥é”™ä¿¡æ¯ 1234Visit https://packagecontrol.io/installation for manual instructionsError installing Package Control: HTTPS error encountered, falling back to HTTP - &lt;urlopen error [Errno 60] Operation timed out&gt;Error installing Package Control: HTTP error encountered, giving up - &lt;urlopen error [Errno 60] Operation timed out&gt;error: An error occurred installing Package Control å¤„ç†åŠžæ³•ç»‘å®šåŸŸå 1250.116.34.243 sublime.wbond.net50.116.34.243 packagecontrol.io install packageæŠ¥é”™ä¿¡æ¯There are no packages available for installation å¤„ç†åŠžæ³•ä¸‹è½½ channel_v3.json æ–‡ä»¶ ï¼ˆgoogleä¸€ä¸‹ï¼‰ ä¿®æ”¹package control.sublime-settings 123&quot;channels&quot;: [ &quot;/path/to/channel_v3.json&quot;]]]></content>
  </entry>
  <entry>
    <title><![CDATA[vim shortcuts]]></title>
    <url>%2F2019%2F05%2F14%2Fvim-shortcuts%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[Flutterä¹‹Dartç¼–è¯‘]]></title>
    <url>%2F2019%2F05%2F10%2FFlutter%E4%B9%8BDart%E7%BC%96%E8%AF%91%2F</url>
    <content type="text"><![CDATA[å‰è¨€Appä¸­ä½¿ç”¨flutterå·²ç»æœ‰æ®µæ—¶é—´äº†ï¼Œæœ€è¿‘é‡åˆ°ä¸€ä¸ªbugè®°å½•ä¸€ä¸‹ã€‚æ›´æ–°flutter moduleå·¥ç¨‹pubspec pluginä¾èµ–ï¼ŒAppå·¥ç¨‹ä¸­pod updateä¹‹åŽï¼Œä»ŽåŠŸèƒ½è¡¨çŽ°ä¸Šçœ‹ä¾ç„¶æ˜¯è€ä»£ç ã€‚ç¬¬ä¸€æ„Ÿè§‰æ˜¯ç¼“å­˜å¯¼è‡´çš„ï¼Œxcode clean ä»¥åŠåˆ é™¤DerivedDataç›®å½•é‡æ–°buildä¾ç„¶ä¸è¡Œï¼Œflutter moduleå·¥ç¨‹ä¸­æ‰§è¡Œflutter cleanç„¶åŽxcode buildæ˜¯æ­£å¸¸çš„ï¼Œæ‰€ä»¥åº”è¯¥æ˜¯dartç¼–è¯‘äº§ç‰©æœ‰ç¼“å­˜å¯¼è‡´çš„ã€‚æŽ¥ä¸‹æ¥çœ‹ä¸‹dartç¼–è¯‘è¿‡ç¨‹ã€‚ ç¼–è¯‘12cd path/to/flutter moduleflutter build ios --debug --simulator è¿›å…¥åˆ°flutter moduleå·¥ç¨‹ç›®å½• æ‰§è¡Œflutter build ioså‘½ä»¤ 12345Running Xcode build... â”œâ”€Assembling Flutter resources... 3.6s â””â”€Compiling, linking and signing... 25.4sXcode build done. 43.9s å¯ä»¥çœ‹åˆ°ä¼šè¿›è¡Œxcode buildï¼Œè¿›åˆ°.iosç›®å½•é€šè¿‡xcodeæ‰“å¼€Runnerå·¥ç¨‹ å¯ä»¥çœ‹åˆ°build phasesä¸­è¿™æ ·ä¸€æ®µè„šæœ¬ï¼Œè¿™é‡Œå°±æ˜¯æ‰§è¡Œdartä»£ç ç¼–è¯‘çš„å…¥å£ã€‚ xcode_backend.shè¿›å…¥åˆ°è„šæœ¬æ‰€åœ¨ç›®å½•ï¼Œçœ‹ä¸‹buildå¯¹åº”çš„æ–¹æ³• BuildApp 12345678910111213if [[ $# == 0 ]]; then # Backwards-compatibility: if no args are provided, build. BuildAppelse case $1 in "build") BuildApp ;; "thin") ThinAppFrameworks ;; "embed") EmbedFlutterFrameworks ;; esacfi 123456789101112131415161718192021222324252627282930BuildApp() &#123; ... StreamOutput " â”œâ”€Assembling Flutter resources..." RunCommand "$&#123;FLUTTER_ROOT&#125;/bin/flutter" --suppress-analytics \ $&#123;verbose_flag&#125; \ build bundle \ --target-platform=ios \ --target="$&#123;target_path&#125;" \ --$&#123;build_mode&#125; \ --depfile="$&#123;build_dir&#125;/snapshot_blob.bin.d" \ --asset-dir="$&#123;derived_dir&#125;/App.framework/$&#123;assets_path&#125;" \ $&#123;precompilation_flag&#125; \ $&#123;flutter_engine_flag&#125; \ $&#123;local_engine_flag&#125; \ $&#123;track_widget_creation_flag&#125; if [[ $? -ne 0 ]]; then EchoError "Failed to package $&#123;project_path&#125;." exit -1 fi StreamOutput "done" StreamOutput " â””â”€Compiling, linking and signing..." RunCommand popd &gt; /dev/null echo "Project $&#123;project_path&#125; built and packaged successfully." return 0&#125; å¯ä»¥çœ‹åˆ° â”œâ”€Assembling Flutter resourcesâ€¦ åœ¨build ios æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºçŽ°è¿‡ï¼Œflutter build bundle å°±ä¼šå¼€å§‹çœŸæ­£çš„dartç¼–è¯‘â€“depfile æŒ‡å®šå‚ä¸Žç¼–è¯‘çš„dartæ–‡ä»¶è·¯å¾„é›†åˆâ€“asset-dir æŒ‡å®šèµ„æºäº§ç‰©çš„ç›®å½• flutterå‘½ä»¤è·¯å¾„ $FLUTTER_ROOT/bin/flutter 123456789101112...FLUTTER_TOOLS_DIR="$FLUTTER_ROOT/packages/flutter_tools"SNAPSHOT_PATH="$FLUTTER_ROOT/bin/cache/flutter_tools.snapshot"STAMP_PATH="$FLUTTER_ROOT/bin/cache/flutter_tools.stamp"SCRIPT_PATH="$FLUTTER_TOOLS_DIR/bin/flutter_tools.dart"DART_SDK_PATH="$FLUTTER_ROOT/bin/cache/dart-sdk"DART="$DART_SDK_PATH/bin/dart"PUB="$DART_SDK_PATH/bin/pub""$DART" $FLUTTER_TOOL_ARGS "$SNAPSHOT_PATH" "$@" flutter_toools.snapshotå®žé™…ä¸Šå°±æ˜¯$FLUTTER_ROOT/packages/flutter_toolsè¿™ä¸ªé¡¹ç›®ç¼–è¯‘ç”Ÿæˆçš„snapshotæ–‡ä»¶ æ‰€ä»¥flutter build bundle å°±æ˜¯ä½¿ç”¨dartæ¥æ‰§è¡Œflutter_toolsé¡¹ç›®çš„mainæ–¹æ³• flutter_toolsè·¯å¾„ $FLUTTER_ROOT/packages/flutter_tools mainæ–¹æ³•å®šä¹‰ $FLUTTER_ROOT/packages/flutter_tools/bin/flutter_tools.dart 123void main(List&lt;String&gt; args) &#123; executable.main(args);&#125; å†çœ‹çœ‹ lib/executable.dart ,åœ¨è¿™é‡Œä¼šé¢„å…ˆåˆ›å»ºå¥½æ¯ä¸€ç§å‘½ä»¤å¯¹åº”çš„å¯¹è±¡commandï¼Œé€šè¿‡è§£æžargså‚æ•°æ‰¾åˆ°å¯¹åº”çš„commandã€‚åœ¨BuildCommandç±»ä¸­ 123456789BuildCommand(&#123;bool verboseHelp = false&#125;) &#123; addSubcommand(BuildApkCommand(verboseHelp: verboseHelp)); addSubcommand(BuildAppBundleCommand(verboseHelp: verboseHelp)); addSubcommand(BuildAotCommand()); addSubcommand(BuildIOSCommand()); addSubcommand(BuildFlxCommand()); addSubcommand(BuildBundleCommand(verboseHelp: verboseHelp)); addSubcommand(BuildWebCommand()); &#125; çœ‹åˆ°BuildIOSCommand ä»¥åŠ BuildBundleCommandçš„åˆ›å»ºã€‚BuildIOSCommand å°±æ˜¯å‰é¢æåˆ°çš„flutter build ios ä¼šæ‰§è¡Œåˆ°çš„ï¼Œè¿™é‡Œæˆ‘ä»¬é‡ç‚¹çœ‹ä¸‹BuildBundleCommandæ˜¯å¦‚ä½•ç¼–è¯‘dartä»£ç çš„ï¼Ÿç¼–è¯‘åŽç”Ÿæˆäº†å“ªäº›èµ„æºï¼Ÿè¿™äº›èµ„æºéƒ½æ˜¯äº›ä»€ä¹ˆï¼Ÿ BuildBundleCommand app.dill : è¿™å°±æ˜¯dartä»£ç ç¼–è¯‘åŽçš„äºŒçº§åˆ¶æ–‡ä»¶ Frontend_server.d : è¿™é‡Œé¢æ”¾çš„æ˜¯frontend_server.dart.snapshotçš„ç»å¯¹è·¯å¾„ï¼Œä½¿ç”¨è¯¥snapshotæ¥ç¼–è¯‘dartä»£ç ç”Ÿæˆä¸Šé¢çš„app.dill snapshot_blob.bin.d : è¿™é‡Œé¢æ”¾çš„æ˜¯æ‰€æœ‰å‚ä¸Žç¼–è¯‘çš„dartæ–‡ä»¶çš„ç»å¯¹è·¯å¾„çš„é›†åˆï¼ŒåŒ…æ‹¬é¡¹ç›®çš„ä»£ç å’ŒflutterSdkçš„ä»£ç ä»¥åŠpubåº“ä¸­çš„ä¸‰æ–¹ä»£ç ã€‚ snapshot_blob.bin.d.fingerprint : è¿™é‡Œé¢æ”¾çš„æ˜¯snapshot_blob.bin.dä¸­çš„æ‰€æœ‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ä»¥åŠæ¯ä¸ªæ–‡ä»¶æ‰€å¯¹åº”çš„md5å€¼ã€‚ä½¿ç”¨è¿™ä¸ªmd5æ¥åˆ¤æ–­è¯¥æ–‡ä»¶æ˜¯å¦æœ‰ä¿®æ”¹ã€‚åœ¨æ¯æ¬¡ç¼–è¯‘çš„æ—¶å€™ä¼šåˆ¤æ–­ï¼Œå¦‚æžœæ²¡æœ‰æ–‡ä»¶ä¿®æ”¹ï¼Œåˆ™ç›´æŽ¥è·³è¿‡ç¼–è¯‘ã€‚ ç¼–è¯‘Dartèµ„æº123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127Future&lt;void&gt; build(&#123; TargetPlatform platform, BuildMode buildMode, String mainPath = defaultMainPath, String manifestPath = defaultManifestPath, String applicationKernelFilePath, String depfilePath, String privateKeyPath = defaultPrivateKeyPath, String assetDirPath, String packagesPath, bool precompiledSnapshot = false, bool reportLicensedPackages = false, bool trackWidgetCreation = false, String compilationTraceFilePath, bool createPatch = false, String buildNumber, String baselineDir, List&lt;String&gt; extraFrontEndOptions = const &lt;String&gt;[], List&lt;String&gt; extraGenSnapshotOptions = const &lt;String&gt;[], List&lt;String&gt; fileSystemRoots, String fileSystemScheme,&#125;) async &#123; // xcode_backend.shä¸­é€šè¿‡--depfileä¼ å…¥è¿›æ¥çš„ // é»˜è®¤æ˜¯build/snapshot_blob.bin.dæ–‡ä»¶ depfilePath ??= defaultDepfilePath; // é€šè¿‡--asset-dirä¼ å…¥ // è¯¥ç›®å½•ä¸­æ–‡ä»¶å°±æ˜¯flutterçš„äº§ç‰©ï¼Œæœ€ç»ˆåˆå¹¶åˆ°app.frameworkä¸­çš„flutter_assetsç›®å½• assetDirPath ??= getAssetBuildDirectory(); packagesPath ??= fs.path.absolute(PackageMap.globalPackagesPath); // app.dill dartä»£ç ç¼–è¯‘åŽçš„äºŒçº§åˆ¶æ–‡ä»¶ applicationKernelFilePath ??= getDefaultApplicationKernelPath(trackWidgetCreation: trackWidgetCreation); final FlutterProject flutterProject = await FlutterProject.current(); if (compilationTraceFilePath != null) &#123; if (buildMode != BuildMode.dynamicProfile &amp;&amp; buildMode != BuildMode.dynamicRelease) &#123; compilationTraceFilePath = null; &#125; else if (compilationTraceFilePath.isEmpty) &#123; // Disable JIT snapshotting if flag is empty. printStatus('Code snapshot will be disabled for this build.'); compilationTraceFilePath = null; &#125; else if (!fs.file(compilationTraceFilePath).existsSync()) &#123; // Be forgiving if compilation trace file is missing. printStatus('No compilation trace available. To optimize performance, consider using --train.'); final File tmp = fs.systemTempDirectory.childFile('flutterEmptyCompilationTrace.txt'); compilationTraceFilePath = (tmp..createSync(recursive: true)).path; &#125; else &#123; printStatus('Code snapshot will use compilation training file $compilationTraceFilePath.'); &#125; &#125; DevFSContent kernelContent; if (!precompiledSnapshot) &#123; if ((extraFrontEndOptions != null) &amp;&amp; extraFrontEndOptions.isNotEmpty) printTrace('Extra front-end options: $extraFrontEndOptions'); ensureDirectoryExists(applicationKernelFilePath); final KernelCompiler kernelCompiler = await kernelCompilerFactory.create(flutterProject); // ç¼–è¯‘dartä»£ç ï¼Œç”Ÿæˆapp.dill å’Œ snapshot_blob.bin.d ä»¥åŠ snapshot_blob.bin.d.fingerprint final CompilerOutput compilerOutput = await kernelCompiler.compile( sdkRoot: artifacts.getArtifactPath(Artifact.flutterPatchedSdkPath), incrementalCompilerByteStorePath: compilationTraceFilePath != null ? null : fs.path.absolute(getIncrementalCompilerByteStoreDirectory()), mainPath: fs.file(mainPath).absolute.path, outputFilePath: applicationKernelFilePath, depFilePath: depfilePath, trackWidgetCreation: trackWidgetCreation, extraFrontEndOptions: extraFrontEndOptions, fileSystemRoots: fileSystemRoots, fileSystemScheme: fileSystemScheme, packagesPath: packagesPath, linkPlatformKernelIn: compilationTraceFilePath != null, ); if (compilerOutput?.outputFilename == null) &#123; throwToolExit('Compiler failed on $mainPath'); &#125; kernelContent = DevFSFileContent(fs.file(compilerOutput.outputFilename)); // ç”Ÿæˆ frontend_server.dæ–‡ä»¶ï¼Œå‘æ–‡ä»¶ä¸­å†™å…¥frontendServerSnapshotForEngineDartSdkçš„è·¯å¾„ await fs.directory(getBuildDirectory()).childFile('frontend_server.d') .writeAsString('frontend_server.d: $&#123;artifacts.getArtifactPath(Artifact.frontendServerSnapshotForEngineDartSdk)&#125;\n'); if (compilationTraceFilePath != null) &#123; final JITSnapshotter snapshotter = JITSnapshotter(); final int snapshotExitCode = await snapshotter.build( platform: platform, buildMode: buildMode, mainPath: applicationKernelFilePath, outputPath: getBuildDirectory(), packagesPath: packagesPath, compilationTraceFilePath: compilationTraceFilePath, extraGenSnapshotOptions: extraGenSnapshotOptions, createPatch: createPatch, buildNumber: buildNumber, baselineDir: baselineDir, ); if (snapshotExitCode != 0) &#123; throwToolExit('Snapshotting exited with non-zero exit code: $snapshotExitCode'); &#125; &#125; &#125; // ç”Ÿæˆ flutter_assets final AssetBundle assets = await buildAssets( manifestPath: manifestPath, assetDirPath: assetDirPath, packagesPath: packagesPath, reportLicensedPackages: reportLicensedPackages, ); if (assets == null) throwToolExit('Error building assets', exitCode: 1); await assemble( buildMode: buildMode, assetBundle: assets, kernelContent: kernelContent, privateKeyPath: privateKeyPath, assetDirPath: assetDirPath, compilationTraceFilePath: compilationTraceFilePath, );&#125; ç¼–è¯‘Dartä»£ç 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596class KernelCompiler &#123; const KernelCompiler(); Future&lt;CompilerOutput&gt; compile(&#123; String sdkRoot, String mainPath, String outputFilePath, String depFilePath, TargetModel targetModel = TargetModel.flutter, bool linkPlatformKernelIn = false, bool aot = false, @required bool trackWidgetCreation, List&lt;String&gt; extraFrontEndOptions, String incrementalCompilerByteStorePath, String packagesPath, List&lt;String&gt; fileSystemRoots, String fileSystemScheme, bool targetProductVm = false, String initializeFromDill, &#125;) async &#123; final String frontendServer = artifacts.getArtifactPath( Artifact.frontendServerSnapshotForEngineDartSdk ); FlutterProject flutterProject; if (fs.file('pubspec.yaml').existsSync()) &#123; flutterProject = await FlutterProject.current(); &#125; // TODO(cbracken): eliminate pathFilter. // Currently the compiler emits buildbot paths for the core libs in the // depfile. None of these are available on the local host. Fingerprinter fingerprinter; // å¦‚æžœsnapshot_blob.bin.dæ–‡ä»¶ä¸ä¸ºç©ºï¼Œåˆ™è¯´æ˜Žæœ‰ç¼–è¯‘ç¼“å­˜ if (depFilePath != null) &#123; // åˆ¤æ–­ä¸Žä¸Šæ¬¡ç¼–è¯‘å¯¹æ¯”ï¼Œæ˜¯å¦æœ‰æ–‡ä»¶çš„md5æ”¹å˜ fingerprinter = Fingerprinter( // snapshot_blob.bin.d.fingerprintæ–‡ä»¶ fingerprintPath: '$depFilePath.fingerprint', paths: &lt;String&gt;[mainPath], properties: &lt;String, String&gt;&#123; 'entryPoint': mainPath, 'trackWidgetCreation': trackWidgetCreation.toString(), 'linkPlatformKernelIn': linkPlatformKernelIn.toString(), 'engineHash': Cache.instance.engineRevision, 'buildersUsed': '$&#123;flutterProject != null ? flutterProject.hasBuilders : false&#125;', &#125;, depfilePaths: &lt;String&gt;[depFilePath], pathFilter: (String path) =&gt; !path.startsWith('/b/build/slave/'), ); // åˆ¤æ–­æ˜¯å¦æœ‰æ–‡ä»¶æ”¹åŠ¨ï¼Œå¦‚æžœæ²¡æœ‰ï¼Œåˆ™ç›´æŽ¥è¿”å›žã€‚ if (await fingerprinter.doesFingerprintMatch()) &#123; printTrace('Skipping kernel compilation. Fingerprint match.'); return CompilerOutput(outputFilePath, 0, /* sources */ null); &#125; &#125; ... // å¦‚æžœæ²¡æœ‰ä¸Šæ¬¡ç¼–è¯‘ç¼“å­˜ï¼Œæˆ–è€…æ–‡ä»¶æœ‰æ”¹å˜ï¼ŒFingerprinterä¸åŒ¹é…ï¼Œåˆ™ä½¿ç”¨darté‡æ–°ç¼–è¯‘ final List&lt;String&gt; command = &lt;String&gt;[ engineDartPath, frontendServer, '--sdk-root', sdkRoot, '--strong', '--target=$targetModel', ]; ... //å‚æ•°æ‹¼æŽ¥ final Process server = await processManager .start(command) .catchError((dynamic error, StackTrace stack) &#123; printError('Failed to start frontend server $error, $stack'); &#125;); final StdoutHandler _stdoutHandler = StdoutHandler(); server.stderr .transform&lt;String&gt;(utf8.decoder) .listen(printError); server.stdout .transform&lt;String&gt;(utf8.decoder) .transform&lt;String&gt;(const LineSplitter()) .listen(_stdoutHandler.handler); final int exitCode = await server.exitCode; if (exitCode == 0) &#123; if (fingerprinter != null) &#123; await fingerprinter.writeFingerprint(); &#125; return _stdoutHandler.compilerOutput.future; &#125; return null; &#125;&#125; Fingerprintå¯¹æ¯”1234567891011121314151617181920212223242526Future&lt;bool&gt; doesFingerprintMatch() async &#123; try &#123; // èŽ·å–åˆ°å½“å‰çš„ snapshot_blob.bin.d.fingerprintæ–‡ä»¶ final File fingerprintFile = fs.file(fingerprintPath); if (!fingerprintFile.existsSync()) return false; if (!_depfilePaths.every(fs.isFileSync)) return false; final List&lt;String&gt; paths = await _getPaths(); if (!paths.every(fs.isFileSync)) return false; // è¯»å–ç¼“å­˜çš„çš„snapshot_blob.bin.d.fingerprintæ–‡ä»¶ï¼Œæž„å»ºä¸€ä¸ªè€çš„Fingerprintå¯¹è±¡ final Fingerprint oldFingerprint = Fingerprint.fromJson(await fingerprintFile.readAsString()); // æž„å»ºä¸€ä¸ªæ–°çš„Fingerprintå¯¹è±¡ final Fingerprint newFingerprint = await buildFingerprint(); // å¯¹æ¯”ä¸¤æ¬¡çš„æ–‡ä»¶é›†åˆä¸­çš„æ¯ä¸ªæ–‡ä»¶çš„md5æ˜¯å¦ä¸€æ · return oldFingerprint == newFingerprint; &#125; catch (e) &#123; // Log exception and continue, fingerprinting is only a performance improvement. printTrace('Fingerprint check error: $e'); &#125; return false; &#125; é‡ç‚¹ çœ‹çœ‹ newFingerprint 12345678910111213Future&lt;Fingerprint&gt; buildFingerprint() async &#123; final List&lt;String&gt; paths = await _getPaths(); return Fingerprint.fromBuildInputs(_properties, paths);&#125;Future&lt;List&lt;String&gt;&gt; _getPaths() async &#123; final Set&lt;String&gt; paths = _paths.toSet(); // ä½¿ç”¨ç¼“å­˜çš„snapshot_blob.bin.dæ–‡ä»¶ä¸­çš„æ–‡ä»¶é›†åˆ for (String depfilePath in _depfilePaths) paths.addAll(await readDepfile(depfilePath)); final FingerprintPathFilter filter = _pathFilter ?? (String path) =&gt; true; return paths.where(filter).toList()..sort();&#125; å¯ä»¥çœ‹åˆ°newFingerprint è·¯å¾„ä¾æ—§æ˜¯ä½¿ç”¨ç¼“å­˜çš„è·¯å¾„ï¼Œä¾æ¬¡è®¡ç®—è·¯å¾„å¯¹åº”æ–‡ä»¶çš„md5ï¼Œæ‰€ä»¥é—®é¢˜å°±åœ¨è¿™é‡Œäº† æ‰§è¡Œflutter packages upgradeæ›´æ–°pubä¾èµ–çš„æ—¶å€™ï¼Œbuildç›®å½•ä¸‹çš„ç¼“å­˜äº§ç‰©å¹¶ä¸ä¼šæœ‰ä»»ä½•å˜åŠ¨ï¼Œè·¯å¾„ä¾ç„¶æ˜¯è€çš„è·¯å¾„ã€‚æœ‰ä¸€ç§æƒ…å†µå°±æ˜¯moduleå·¥ç¨‹ lib ç›®å½•ä¸‹çš„datæ–‡ä»¶æœ‰æ”¹åŠ¨ï¼ŒnewFingerprintå°±ä¼šè·Ÿoldä¸ä¸€æ ·ï¼Œè¿™ä¼šé‡æ–°ç¼–è¯‘dartï¼Œè¿™é‡Œåˆæœ‰ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯å¦‚æžœlibç›®å½•ä¸‹æ˜¯æ–°å¢ždartæ–‡ä»¶ åˆ™ä¸ä¼šè¢«ç¼–è¯‘è¿›åŽ»ã€‚ æœ€åŽç»¼ä¸Šï¼Œæ‰§è¡Œflutter cleanå‘½ä»¤ï¼Œæ¸…ç©ºbuildç›®å½•ç¼“å­˜æ–‡ä»¶ï¼Œbuild ios å°±ä¼šé‡æ–°ç¼–è¯‘æ•´ä¸ªdartæ–‡ä»¶ï¼ŒåŒ…æ‹¬pubä¾èµ–ä¸­çš„ã€‚ å‚è€ƒé“¾æŽ¥Flutteræ·±å…¥ä¹‹flutter-build-bundleå‘½ä»¤å¦‚ä½•ç¼–è¯‘Dart?]]></content>
      <categories>
        <category>flutter</category>
      </categories>
      <tags>
        <tag>flutter</tag>
        <tag>dart</tag>
      </tags>
  </entry>
</search>
